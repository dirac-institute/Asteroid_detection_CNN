{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-01T11:27:32.025148Z",
     "start_time": "2025-06-01T11:23:46.075178Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) CBAM (Channel + Spatial Attention)\n",
    "# ------------------------------------------------------------\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // ratio, kernel_size=1, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(in_channels // ratio, in_channels, kernel_size=1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.constant_(self.fc1.bias, 0)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, mode='fan_out', nonlinearity='linear')\n",
    "        nn.init.constant_(self.fc2.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.avg_pool(x)        # (B, C, 1, 1)\n",
    "        avg_out = self.fc1(avg_out)       # (B, C//ratio, 1, 1)\n",
    "        avg_out = self.relu(avg_out)\n",
    "        avg_out = self.fc2(avg_out)       # (B, C, 1, 1)\n",
    "\n",
    "        max_out = self.max_pool(x)        # (B, C, 1, 1)\n",
    "        max_out = self.fc1(max_out)       # (B, C//ratio, 1, 1)\n",
    "        max_out = self.relu(max_out)\n",
    "        max_out = self.fc2(max_out)       # (B, C, 1, 1)\n",
    "\n",
    "        out = avg_out + max_out           # (B, C, 1, 1)\n",
    "        scale = self.sigmoid(out)         # (B, C, 1, 1)\n",
    "        return x * scale                  # broadcast along H, W\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        assert kernel_size in (3, 7)\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        nn.init.kaiming_normal_(self.conv.weight, mode='fan_in', nonlinearity='sigmoid')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)     # (B, 1, H, W)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)   # (B, 1, H, W)\n",
    "        concat = torch.cat([avg_out, max_out], dim=1)    # (B, 2, H, W)\n",
    "        attn = self.conv(concat)                         # (B, 1, H, W)\n",
    "        attn = self.sigmoid(attn)\n",
    "        return x * attn                                  # broadcast across C\n",
    "\n",
    "class CBAMBlock(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=8, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.channel_att = ChannelAttention(in_channels, ratio)\n",
    "        self.spatial_att = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.channel_att(x)\n",
    "        x = self.spatial_att(x)\n",
    "        return x\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) DoubleConv: two 3×3 convs → BatchNorm → Activation\n",
    "# ------------------------------------------------------------\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation,\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation\n",
    "        )\n",
    "        for m in self.block.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) AttentionGate for skip‐connection fusion\n",
    "# ------------------------------------------------------------\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        # W_g projects gating signal\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # W_x projects skip connection\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # psi computes 1‐channel attention map\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.W_g[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.W_x[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.psi[0].weight, mode='fan_out', nonlinearity='sigmoid')\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        \"\"\"\n",
    "        g: gating signal from decoder, shape (B, F_g, H, W)\n",
    "        x: skip connection from encoder, shape (B, F_l, H, W)\n",
    "        \"\"\"\n",
    "        g1 = self.W_g(g)   # (B, F_int, H, W)\n",
    "        x1 = self.W_x(x)   # (B, F_int, H, W)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)   # (B, 1, H, W)\n",
    "        return x * psi        # broadcast along channel\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Encoder Block: DoubleConv → CBAM → Dropout → Optional MaxPool\n",
    "# ------------------------------------------------------------\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation, dropout_prob=0.0, attention=True, pool=True):\n",
    "        super().__init__()\n",
    "        self.double_conv = DoubleConv(in_ch, out_ch, activation)\n",
    "        self.cbam        = CBAMBlock(out_ch, ratio=8, kernel_size=7) if attention else nn.Identity()\n",
    "        self.dropout     = nn.Dropout2d(dropout_prob) if dropout_prob > 0 else nn.Identity()\n",
    "        self.pool        = pool\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.double_conv(x)\n",
    "        x = self.cbam(x)\n",
    "        x = self.dropout(x)\n",
    "        skip = x.clone()\n",
    "        if self.pool:\n",
    "            x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        return x, skip\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Decoder Block:\n",
    "#       - Upsample from in_ch → skip_ch\n",
    "#       - AttentionGate on skip\n",
    "#       - DoubleConv(2*skip_ch → out_ch) → CBAM → Dropout\n",
    "# ------------------------------------------------------------\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, skip_ch, out_ch, activation, dropout_prob=0.0, attention=True, upsample=True):\n",
    "        \"\"\"\n",
    "        in_ch:   channels from previous layer (bottleneck or previous decoder)\n",
    "        skip_ch: channels in the corresponding encoder skip\n",
    "        out_ch:  desired output channels for this decoder block\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        self.skip_ch = skip_ch\n",
    "\n",
    "        if self.upsample:\n",
    "            # ConvTranspose2d(in_ch → skip_ch) to match spatial & channel dims\n",
    "            self.up = nn.ConvTranspose2d(in_ch, skip_ch, kernel_size=3,\n",
    "                                         stride=2, padding=1, output_padding=1, bias=False)\n",
    "            nn.init.kaiming_normal_(self.up.weight, mode='fan_out', nonlinearity='relu')\n",
    "            self.bn_up = nn.BatchNorm2d(skip_ch)\n",
    "            self.act_up = activation\n",
    "            self.attention = AttentionGate(F_g=skip_ch, F_l=skip_ch, F_int=skip_ch // 2) if attention else nn.Identity()\n",
    "            in_double = skip_ch * 2\n",
    "        else:\n",
    "            self.up = None\n",
    "            self.bn_up = None\n",
    "            self.act_up = None\n",
    "            self.attention = AttentionGate(F_g=in_ch, F_l=in_ch, F_int=in_ch // 2) if attention else nn.Identity()\n",
    "            in_double = in_ch * 2 if attention else in_ch\n",
    "\n",
    "        self.double_conv = DoubleConv(in_double, out_ch, activation)\n",
    "        self.cbam        = CBAMBlock(out_ch, ratio=8, kernel_size=7) if attention else nn.Identity()\n",
    "        self.dropout     = nn.Dropout2d(dropout_prob) if dropout_prob > 0 else nn.Identity()\n",
    "\n",
    "    def forward(self, x, skip=None):\n",
    "        if self.upsample:\n",
    "            x = self.up(x)       # (B, skip_ch, H*2, W*2)\n",
    "            x = self.bn_up(x)\n",
    "            x = self.act_up(x)\n",
    "        if skip is not None and not isinstance(self.attention, nn.Identity):\n",
    "            skip = self.attention(g=x, x=skip)\n",
    "            x = torch.cat([x, skip], dim=1)  # (B, 2*skip_ch, H*2, W*2)\n",
    "        x = self.double_conv(x)\n",
    "        x = self.cbam(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) UNetTFEquivalent: exactly follows your JSON architecture\n",
    "# ------------------------------------------------------------\n",
    "class UNetTFEquivalent(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=1,\n",
    "                 out_channels=1,\n",
    "                 down_filters=None,\n",
    "                 down_activations=None,\n",
    "                 down_dropouts=None,\n",
    "                 down_pool=None,\n",
    "                 up_filters=None,\n",
    "                 up_activations=None,\n",
    "                 up_dropouts=None):\n",
    "        super().__init__()\n",
    "        assert len(down_filters) == len(down_activations) == len(down_dropouts) == len(down_pool)\n",
    "        assert len(up_filters)   == len(up_activations)  == len(up_dropouts)\n",
    "\n",
    "        # Build Encoder path\n",
    "        self.encoders = nn.ModuleList()\n",
    "        prev_ch = in_channels\n",
    "        for i, out_ch in enumerate(down_filters):\n",
    "            act_str = down_activations[i].lower()\n",
    "            if act_str == 'relu':\n",
    "                act_fn = nn.ReLU(inplace=True)\n",
    "            elif act_str == 'sigmoid':\n",
    "                act_fn = nn.Sigmoid()\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported encoder activation: {act_str}\")\n",
    "\n",
    "            self.encoders.append(\n",
    "                EncoderBlock(in_ch=prev_ch,\n",
    "                             out_ch=out_ch,\n",
    "                             activation=act_fn,\n",
    "                             dropout_prob=down_dropouts[i],\n",
    "                             attention=(i != 0),      # no CBAM in very first block\n",
    "                             pool=down_pool[i])\n",
    "            )\n",
    "            prev_ch = out_ch\n",
    "\n",
    "        # Bottleneck: DoubleConv(down_filters[-1] → down_filters[-1]*2)\n",
    "        self.bottleneck = DoubleConv(down_filters[-1], down_filters[-1] * 2, nn.ReLU(inplace=True))\n",
    "\n",
    "        # Build Decoder path\n",
    "        self.decoders = nn.ModuleList()\n",
    "        N = len(down_filters)\n",
    "        for i, out_ch in enumerate(up_filters):\n",
    "            act_str = up_activations[i].lower()\n",
    "            if act_str == 'relu':\n",
    "                act_fn = nn.ReLU(inplace=True)\n",
    "            elif act_str == 'sigmoid':\n",
    "                act_fn = nn.Sigmoid()\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported decoder activation: {act_str}\")\n",
    "\n",
    "            # Mirror the pooling flags to decide upsampling\n",
    "            do_upsample = down_pool[N - 1 - i]\n",
    "            # Corresponding skip channels from encoder\n",
    "            skip_ch = down_filters[N - 1 - i]\n",
    "            # Input channels for this decoder block\n",
    "            in_ch_dec = (down_filters[-1] * 2) if (i == 0) else up_filters[i - 1]\n",
    "\n",
    "            self.decoders.append(\n",
    "                DecoderBlock(in_ch=in_ch_dec,\n",
    "                             skip_ch=skip_ch,\n",
    "                             out_ch=out_ch,\n",
    "                             activation=act_fn,\n",
    "                             dropout_prob=up_dropouts[i],\n",
    "                             attention=True,\n",
    "                             upsample=do_upsample)\n",
    "            )\n",
    "\n",
    "        # Final 3×3 conv + Sigmoid → 1 channel\n",
    "        self.final_conv = nn.Conv2d(up_filters[-1], out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        nn.init.kaiming_normal_(self.final_conv.weight, mode='fan_out', nonlinearity='sigmoid')\n",
    "        self.final_sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, 128, 128)\n",
    "        skips = []\n",
    "        for enc in self.encoders:\n",
    "            x, skip = enc(x)\n",
    "            skips.append(skip)\n",
    "\n",
    "        x = self.bottleneck(x)          # (B, 1024, 1, 1)\n",
    "        skips = skips[::-1]              # reverse order for decoding\n",
    "\n",
    "        for i, dec in enumerate(self.decoders):\n",
    "            skip_feat = skips[i]\n",
    "            x = dec(x, skip_feat)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "        x = self.final_sigmoid(x)\n",
    "        return x  # (B, 1, 32, 32) in your JSON case\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) Dataset utilities: split_stack, build_datasets, reshape_masks, split_train_val\n",
    "# ------------------------------------------------------------\n",
    "def split_stack(arr, nrows, ncols):\n",
    "    \"\"\"\n",
    "    Split a stack of 2D panels into (nrows × ncols) tiles.\n",
    "    arr: ndarray, shape (P, H, W)\n",
    "    Returns: ndarray, shape (P * (H//nrows)*(W//ncols), nrows, ncols)\n",
    "    \"\"\"\n",
    "    P, H, W = arr.shape\n",
    "    pad_h = (-H) % nrows\n",
    "    pad_w = (-W) % ncols\n",
    "    if pad_h or pad_w:\n",
    "        arr = np.pad(arr,\n",
    "                     ((0, 0),\n",
    "                      (0, pad_h),\n",
    "                      (0, pad_w)),\n",
    "                     mode='constant',\n",
    "                     constant_values=0)\n",
    "    H2, W2 = arr.shape[1], arr.shape[2]\n",
    "    blocks = (arr\n",
    "              .reshape(P,\n",
    "                       H2 // nrows, nrows,\n",
    "                       W2 // ncols, ncols)\n",
    "              .swapaxes(2, 3))\n",
    "    P2, Hb, Wb, nr, nc = blocks.shape\n",
    "    out = blocks.reshape(P2 * Hb * Wb, nr, nc)\n",
    "    return out\n",
    "\n",
    "def build_datasets(npz_file, tile_size=128):\n",
    "    \"\"\"\n",
    "    Load data from .npz, clip exactly as TF did, split into tiles, return PyTorch tensors.\n",
    "      - Clips x to [-166.43, 169.96]\n",
    "      - Splits each large image into (tile_size × tile_size) patches\n",
    "      - Adds a channel dimension (→ shape (N, 1, tile_size, tile_size))\n",
    "    \"\"\"\n",
    "    data = np.load(npz_file)\n",
    "    x = data['x']  # shape (P, H, W)\n",
    "    y = data['y']\n",
    "\n",
    "    # 1) Clip as TF: [-166.43, 169.96]\n",
    "    x = np.clip(x, -166.43, 169.96)\n",
    "\n",
    "    # 2) Split into tiles (tile_size × tile_size)\n",
    "    x_tiles = split_stack(x, tile_size, tile_size)  # (N_tiles, tile_size, tile_size)\n",
    "    y_tiles = split_stack(y, tile_size, tile_size)\n",
    "\n",
    "    # 3) Convert to FloatTensor and add channel dimension\n",
    "    x_tiles = torch.from_numpy(x_tiles).float().unsqueeze(1)  # (N, 1, tile_size, tile_size)\n",
    "    y_tiles = torch.from_numpy(y_tiles).float().unsqueeze(1)  # (N, 1, tile_size, tile_size)\n",
    "\n",
    "    return x_tiles, y_tiles\n",
    "\n",
    "def reshape_masks(masks, new_size):\n",
    "    \"\"\"\n",
    "    Resize binary masks (0/1) to `new_size`:\n",
    "      - Uses bilinear interpolation (same as TF’s tf.image.resize with bilinear)\n",
    "      - Applies torch.ceil(...) to recover {0,1} values exactly.\n",
    "    Input:\n",
    "      - masks: either a Tensor of shape (N, 1, H_orig, W_orig)\n",
    "               or a numpy array of shape (N, H_orig, W_orig)\n",
    "      - new_size: tuple (new_H, new_W)\n",
    "    Returns:\n",
    "      - Tensor of shape (N, 1, new_H, new_W), values in {0,1}\n",
    "    \"\"\"\n",
    "    if isinstance(masks, np.ndarray):\n",
    "        m = torch.from_numpy(masks).float().unsqueeze(1)  # → (N,1,H,W)\n",
    "    else:\n",
    "        m = masks  # assume already FloatTensor (N,1,H,W)\n",
    "    m_resized = F.interpolate(m, size=new_size, mode='bilinear', align_corners=False)\n",
    "    m_resized = torch.ceil(m_resized)\n",
    "    return m_resized.clamp(0, 1)\n",
    "\n",
    "def split_train_val(x_tiles, y_tiles, train_frac=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Shuffle and split x_tiles, y_tiles into two TensorDatasets: train (80%) and val (20%).\n",
    "    \"\"\"\n",
    "    n = x_tiles.shape[0]\n",
    "    idx = torch.randperm(n, generator=torch.Generator().manual_seed(seed))\n",
    "    split = int(train_frac * n)\n",
    "    train_idx = idx[:split]\n",
    "    val_idx   = idx[split:]\n",
    "    x_tr, y_tr = x_tiles[train_idx], y_tiles[train_idx]\n",
    "    x_val, y_val = x_tiles[val_idx], y_tiles[val_idx]\n",
    "    return TensorDataset(x_tr, y_tr), TensorDataset(x_val, y_val)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) Loss: Weighted BCE + Dice (TF used BCE + ceil(targets) for binary masks)\n",
    "# ------------------------------------------------------------\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        \"\"\"\n",
    "        preds:   Tensor (B,1,H,W) after Sigmoid\n",
    "        targets: Tensor (B,1,H,W) binary {0,1}\n",
    "        \"\"\"\n",
    "        p_flat = preds.view(-1)\n",
    "        t_flat = targets.view(-1)\n",
    "        intersection = (p_flat * t_flat).sum()\n",
    "        dice_coeff = (2. * intersection + self.smooth) / (p_flat.sum() + t_flat.sum() + self.smooth)\n",
    "        return 1 - dice_coeff\n",
    "\n",
    "class ComboLossTF(nn.Module):\n",
    "    def __init__(self, bce_weight=0.5, dice_weight=0.5):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.dice = DiceLoss(smooth=1e-6)\n",
    "        self.bw, self.dw = bce_weight, dice_weight\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        # preds, targets both (B,1,H,W)\n",
    "        l_bce = self.bce(preds, targets)\n",
    "        l_dice = self.dice(preds, targets)\n",
    "        return self.bw * l_bce + self.dw * l_dice\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) Training loop (resizes masks to match model’s output)\n",
    "# ------------------------------------------------------------\n",
    "def train_model(model, train_ds, val_ds, epochs=100, batch_size=32, lr=1e-3, device=None):\n",
    "    \"\"\"\n",
    "    Train the model on train_ds, validate on val_ds, and print losses + F1 each epoch.\n",
    "    Resizes all masks to `output_size` so that preds and targets match in spatial dims.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 1) Figure out the model’s output spatial size by pushing a dummy 128×128 patch.\n",
    "    with torch.no_grad():\n",
    "        dummy = torch.randn(1, 1, 128, 128).to(device)\n",
    "        out_dummy = model(dummy)\n",
    "        output_size = (out_dummy.shape[-2], out_dummy.shape[-1])  # e.g. (32,32) for your JSON\n",
    "\n",
    "    criterion = ComboLossTF(bce_weight=0.5, dice_weight=0.5)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=4, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=4, pin_memory=True)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ——— Training ———\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        tp = fp = fn = 0\n",
    "        for imgs, masks in train_loader:\n",
    "            imgs = imgs.to(device)  # (B,1,128,128)\n",
    "\n",
    "            # Resize the ground‐truth masks to output_size (e.g. (32,32))\n",
    "            m_resized = reshape_masks(masks, new_size=output_size).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(imgs)              # (B,1, output_H, output_W)\n",
    "            loss = criterion(preds, m_resized)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_bin = (preds > 0.5).float()\n",
    "                t = m_resized\n",
    "                tp += (pred_bin * t).sum().item()\n",
    "                fp += (pred_bin * (1 - t)).sum().item()\n",
    "                fn += ((1 - pred_bin) * t).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_ds)\n",
    "        prec = tp / (tp + fp + 1e-8)\n",
    "        rec  = tp / (tp + fn + 1e-8)\n",
    "        f1   = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "\n",
    "        # ——— Validation ———\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        tp = fp = fn = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                m_resized = reshape_masks(masks, new_size=output_size).to(device)\n",
    "                preds = model(imgs)\n",
    "                loss = criterion(preds, m_resized)\n",
    "                val_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "                pred_bin = (preds > 0.5).float()\n",
    "                tp += (pred_bin * m_resized).sum().item()\n",
    "                fp += (pred_bin * (1 - m_resized)).sum().item()\n",
    "                fn += ((1 - pred_bin) * m_resized).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_ds)\n",
    "        prec = tp / (tp + fp + 1e-8)\n",
    "        rec  = tp / (tp + fn + 1e-8)\n",
    "        f1_val = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "\n",
    "        print(f\"Epoch {epoch:03d}  \"\n",
    "              f\"Train Loss: {train_loss:.4f}  \"\n",
    "              f\"| Val Loss: {val_loss:.4f}  \"\n",
    "              f\"| Val F1: {f1_val:.4f}  \"\n",
    "              f\"| Prec: {prec:.4f}  \"\n",
    "              f\"| Rec: {rec:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10) Main() – build data, instantiate model, train\n",
    "# ------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 10.1) Build datasets from your .npz (train.npz assumed in ../DATA/)\n",
    "    npz_file = \"../DATA/train.npz\"\n",
    "    x_tiles, y_tiles = build_datasets(npz_file, tile_size=128)\n",
    "    train_ds, val_ds = split_train_val(x_tiles, y_tiles, train_frac=0.8, seed=42)\n",
    "\n",
    "    # 10.2) Use exactly your JSON architecture:\n",
    "    down_filters     = [32, 32, 32, 64, 128, 256]\n",
    "    down_activations = ['relu', 'relu', 'relu', 'relu', 'sigmoid', 'relu']\n",
    "    down_dropouts    = [0, 0, 0, 0, 0, 0]\n",
    "    down_pool        = [True, True, True, True, True, True]\n",
    "\n",
    "    up_filters       = [512, 256, 128, 64]\n",
    "    up_activations   = ['relu', 'sigmoid', 'relu', 'sigmoid']\n",
    "    up_dropouts      = [0, 0, 0, 0]\n",
    "\n",
    "    model = UNetTFEquivalent(\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        down_filters=down_filters,\n",
    "        down_activations=down_activations,\n",
    "        down_dropouts=down_dropouts,\n",
    "        down_pool=down_pool,\n",
    "        up_filters=up_filters,\n",
    "        up_activations=up_activations,\n",
    "        up_dropouts=up_dropouts,\n",
    "    )\n",
    "\n",
    "    # 10.3) Train for 100 epochs with batch_size=32, lr=1e-3\n",
    "    trained_model = train_model(model,\n",
    "                                train_ds, val_ds,\n",
    "                                epochs=20,\n",
    "                                batch_size=32,\n",
    "                                lr=1e-3)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001  Train Loss: 0.5123  | Val Loss: 0.5068  | Val F1: 0.0000  | Prec: 0.0000  | Rec: 0.0000\n",
      "Epoch 002  Train Loss: 0.5061  | Val Loss: 0.5084  | Val F1: 0.0000  | Prec: 0.0000  | Rec: 0.0000\n",
      "Epoch 003  Train Loss: 0.5046  | Val Loss: 0.4981  | Val F1: 0.0733  | Prec: 0.0782  | Rec: 0.0689\n",
      "Epoch 004  Train Loss: 0.5034  | Val Loss: 0.5004  | Val F1: 0.0468  | Prec: 0.0585  | Rec: 0.0390\n",
      "Epoch 005  Train Loss: 0.5038  | Val Loss: 0.4974  | Val F1: 0.0741  | Prec: 0.0729  | Rec: 0.0754\n",
      "Epoch 006  Train Loss: 0.5003  | Val Loss: 0.4949  | Val F1: 0.0672  | Prec: 0.1178  | Rec: 0.0470\n",
      "Epoch 007  Train Loss: 0.4990  | Val Loss: 0.5052  | Val F1: 0.0808  | Prec: 0.0518  | Rec: 0.1835\n",
      "Epoch 008  Train Loss: 0.4986  | Val Loss: 0.4895  | Val F1: 0.1273  | Prec: 0.0989  | Rec: 0.1784\n",
      "Epoch 009  Train Loss: 0.4960  | Val Loss: 0.4896  | Val F1: 0.1118  | Prec: 0.2962  | Rec: 0.0689\n",
      "Epoch 010  Train Loss: 0.4914  | Val Loss: 0.4812  | Val F1: 0.1339  | Prec: 0.1288  | Rec: 0.1394\n",
      "Epoch 011  Train Loss: 0.4934  | Val Loss: 0.4853  | Val F1: 0.1121  | Prec: 0.1361  | Rec: 0.0954\n",
      "Epoch 012  Train Loss: 0.4874  | Val Loss: 0.4844  | Val F1: 0.1225  | Prec: 0.1344  | Rec: 0.1125\n",
      "Epoch 013  Train Loss: 0.4839  | Val Loss: 0.4770  | Val F1: 0.1571  | Prec: 0.2232  | Rec: 0.1212\n",
      "Epoch 014  Train Loss: 0.4823  | Val Loss: 0.4831  | Val F1: 0.1600  | Prec: 0.1449  | Rec: 0.1785\n",
      "Epoch 015  Train Loss: 0.4783  | Val Loss: 0.4738  | Val F1: 0.1939  | Prec: 0.1688  | Rec: 0.2278\n",
      "Epoch 016  Train Loss: 0.4756  | Val Loss: 0.4628  | Val F1: 0.2339  | Prec: 0.3443  | Rec: 0.1772\n",
      "Epoch 017  Train Loss: 0.4709  | Val Loss: 0.4639  | Val F1: 0.2316  | Prec: 0.3689  | Rec: 0.1688\n",
      "Epoch 018  Train Loss: 0.4728  | Val Loss: 0.4801  | Val F1: 0.1725  | Prec: 0.2178  | Rec: 0.1429\n",
      "Epoch 019  Train Loss: 0.4756  | Val Loss: 0.4718  | Val F1: 0.1847  | Prec: 0.1868  | Rec: 0.1826\n",
      "Epoch 020  Train Loss: 0.4694  | Val Loss: 0.4710  | Val F1: 0.1956  | Prec: 0.1735  | Rec: 0.2240\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b2cc4b27409fbd54"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
