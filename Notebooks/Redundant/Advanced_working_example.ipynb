{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c757f4099bf6030e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T18:15:27.032627Z",
     "start_time": "2025-07-15T18:15:24.775279Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0ee8133ceb7c68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T18:15:27.089080Z",
     "start_time": "2025-07-15T18:15:27.074109Z"
    }
   },
   "outputs": [],
   "source": [
    "def activation_parser(activation_str):\n",
    "    \"\"\"\n",
    "    Parse a string to return the corresponding activation function.\n",
    "    Supported strings: 'relu', 'sigmoid', 'tanh', 'leaky_relu'.\n",
    "    \"\"\"\n",
    "    if activation_str.lower() == \"elu\":\n",
    "        return nn.ELU(inplace=True)\n",
    "    elif activation_str.lower() == \"hardshrink\":\n",
    "        return nn.Hardshrink(lambd=0.5)\n",
    "    elif activation_str.lower() == \"hardsigmoid\":\n",
    "        return nn.Hardsigmoid(inplace=True)\n",
    "    elif activation_str.lower() == \"hardtanh\":\n",
    "        return nn.Hardtanh(min_val=-1, max_val=1, inplace=True)\n",
    "    elif activation_str.lower() == \"leakyrelu\":\n",
    "        return nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "    elif activation_str.lower() == \"logsigmoid\":\n",
    "        return nn.LogSigmoid()\n",
    "    elif activation_str.lower() == \"prelu\":\n",
    "        return nn.PReLU(num_parameters=1, init=0.25)\n",
    "    elif activation_str.lower() == \"relu\":\n",
    "        return nn.ReLU(inplace=True)\n",
    "    elif activation_str.lower() == \"relu6\":\n",
    "        return nn.ReLU6(inplace=True)\n",
    "    elif activation_str.lower() == \"selu\":\n",
    "        return nn.SELU(inplace=True)\n",
    "    elif activation_str.lower() == \"celu\":\n",
    "        return nn.CELU(inplace=True)\n",
    "    elif activation_str.lower() == \"gelu\":\n",
    "        return nn.GELU(approximate='none')  # 'tanh' or 'none'\n",
    "    elif activation_str.lower() == \"sigmoid\":\n",
    "        return nn.Sigmoid()\n",
    "    elif activation_str.lower() == \"silu\":\n",
    "        return nn.SiLU(inplace=True)  # also known as Swish\n",
    "    elif activation_str.lower() == \"mish\":\n",
    "        return nn.Mish(inplace=True)\n",
    "    elif activation_str.lower() == \"softplus\":\n",
    "        return nn.Softplus(beta=1, threshold=20, inplace=True)\n",
    "    elif activation_str.lower() == \"softshrink\":\n",
    "        return nn.Softshrink(lambd=0.5, inplace=True)\n",
    "    elif activation_str.lower() == \"softsign\":\n",
    "        return nn.Softsign()\n",
    "    elif activation_str.lower() == \"tanh\":\n",
    "        return nn.Tanh()\n",
    "    elif activation_str.lower() == \"tanhshrink\":\n",
    "        return nn.Tanhshrink()\n",
    "    elif activation_str.lower() == \"threshold\":\n",
    "        return nn.Threshold(threshold=0.25, value=0.0, inplace=True)\n",
    "    elif activation_str.lower() == \"glu\":\n",
    "        return nn.GLU(dim=1)  # assumes input has shape (B, C, H, W)\n",
    "    elif activation_str.lower() == \"softmax\":\n",
    "        return nn.Softmax(dim=1)  # applies softmax across channels\n",
    "    elif activation_str.lower() == \"logsoftmax\":\n",
    "        return nn.LogSoftmax(dim=1)  # applies log softmax across channels\n",
    "    elif activation_str.lower() == \"none\":\n",
    "        return nn.Identity()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported activation: {activation_str}\")\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_channels, in_channels // ratio, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(in_channels // ratio, in_channels, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.norm = nn.BatchNorm1d(in_channels)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.avg_pool(x)        # (B, C, 1, 1)\n",
    "        avg_out = avg_out.view(avg_out.size(0), avg_out.size(1))  # (B, C)\n",
    "        avg_out = self.fc1(avg_out)       # (B, C//ratio)\n",
    "        avg_out = self.relu(avg_out)\n",
    "        avg_out = self.fc2(avg_out)       # (B, C)\n",
    "\n",
    "        max_out = self.max_pool(x)        # (B, C, 1, 1)\n",
    "        max_out = max_out.view(max_out.size(0), max_out.size(1))  # (B, C)\n",
    "        max_out = self.fc1(max_out)       # (B, C//ratio)\n",
    "        max_out = self.relu(max_out)\n",
    "        max_out = self.fc2(max_out)       # (B, C)\n",
    "\n",
    "        out = avg_out + max_out           # (B, C)\n",
    "        out = self.norm(out)              # (B, C)\n",
    "        scale = self.sigmoid(out)         # (B, C)\n",
    "        scale = scale.view(scale.size(0), scale.size(1), 1, 1)  # (B, C, 1, 1)\n",
    "        return x * scale                  # broadcast along H, W\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=5):\n",
    "        super().__init__()\n",
    "        assert kernel_size in (3, 5, 7)\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.norm = nn.BatchNorm2d(1)\n",
    "        nn.init.xavier_uniform_(self.conv.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)     # (B, 1, H, W)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)   # (B, 1, H, W)\n",
    "        concat = torch.cat([avg_out, max_out], dim=1)    # (B, 2, H, W)\n",
    "        attn = self.conv(concat)                         # (B, 1, H, W)\n",
    "        attn = self.norm(attn)                           # (B, 1, H, W)\n",
    "        attn = self.sigmoid(attn)\n",
    "        return x * attn                                  # broadcast across C\n",
    "\n",
    "class CBAMBlock(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=8, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.channel_att = ChannelAttention(in_channels, ratio)\n",
    "        self.spatial_att = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.channel_att(x)\n",
    "        x = self.spatial_att(x)\n",
    "        return x\n",
    "\n",
    "class SepConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation, kernel_size, padding, dilation=1):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_ch, in_ch, kernel_size=kernel_size,\n",
    "            padding=padding, dilation=dilation,\n",
    "            groups=in_ch, bias=True\n",
    "        )\n",
    "        self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=True)\n",
    "        self.norm = nn.BatchNorm2d(out_ch)\n",
    "        self.act = activation_parser(activation)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.depthwise.weight, mode='fan_out', nonlinearity=\"relu\")\n",
    "        nn.init.constant_(self.depthwise.bias, 0)\n",
    "        nn.init.kaiming_normal_(self.pointwise.weight, mode='fan_out', nonlinearity=\"relu\")\n",
    "        nn.init.constant_(self.pointwise.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return self.act(self.norm(x))\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation):\n",
    "        super().__init__()\n",
    "        dilations = [1, 2, 3, 4]\n",
    "        kernels   = [1, 3, 5, 7]\n",
    "        self.branches = nn.ModuleList()\n",
    "        for d, k in zip(dilations, kernels):\n",
    "            pad = (k // 2) * d\n",
    "            self.branches.append(\n",
    "                SepConv(in_ch, out_ch, activation, kernel_size=k, padding=pad, dilation=d)\n",
    "            )\n",
    "        self.merge = nn.Sequential(\n",
    "            nn.Conv2d(len(dilations) * out_ch, out_ch, kernel_size=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation_parser(activation)\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.merge[0].weight, mode='fan_out', nonlinearity=\"relu\")\n",
    "        nn.init.constant_(self.merge[0].bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = [branch(x) for branch in self.branches]\n",
    "        x = torch.cat(outs, dim=1)\n",
    "        return self.merge(x)\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation_parser(activation),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation_parser(activation)\n",
    "        )\n",
    "        for m in self.block.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity=\"relu\")\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        # W_g projects gating signal\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # W_x projects skip connection\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # psi computes 1‐channel attention map\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, F_g, kernel_size=1, bias=True),\n",
    "            nn.BatchNorm2d(F_g),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.W_g[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.constant_(self.W_g[0].bias, 0)\n",
    "        nn.init.kaiming_normal_(self.W_x[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.constant_(self.W_x[0].bias, 0)\n",
    "        nn.init.xavier_uniform_(self.psi[0].weight)\n",
    "        nn.init.constant_(self.psi[0].bias, 0)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        \"\"\"\n",
    "        g: gating signal from decoder, shape (B, F_g, H, W)\n",
    "        x: skip connection from encoder, shape (B, F_l, H, W)\n",
    "        \"\"\"\n",
    "        g1 = self.W_g(g)   # (B, F_int, H, W)\n",
    "        x1 = self.W_x(x)   # (B, F_int, H, W)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)   # (B, 1, H, W)\n",
    "        return x * psi        # broadcast along channel\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation, dropout_prob=0.0, attention=True, pool=True, ASPP_blocks=True):\n",
    "        super().__init__()\n",
    "        if ASPP_blocks:\n",
    "            # Use ASPP instead of DoubleConv\n",
    "            self.conv = ASPP(in_ch, out_ch, activation)\n",
    "        else:\n",
    "            # Use DoubleConv if ASPP_blocks is False\n",
    "            self.conv = DoubleConv(in_ch, out_ch, activation)\n",
    "        self.cbam        = CBAMBlock(out_ch, ratio=8, kernel_size=7) if attention else nn.Identity()\n",
    "        self.dropout     = nn.Dropout2d(dropout_prob) if dropout_prob > 0 else nn.Identity()\n",
    "        self.pool        = pool\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.cbam(x)\n",
    "        x = self.dropout(x)\n",
    "        skip = x.clone()\n",
    "        if self.pool:\n",
    "            x = F.max_pool2d(x, kernel_size=2)\n",
    "        return x, skip\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, skip_ch, out_ch, activation, dropout_prob=0.0, attention=True, upsample=True, ASPP_blocks=True):\n",
    "        \"\"\"\n",
    "        in_ch:   channels from previous layer (bottleneck or previous decoder)\n",
    "        skip_ch: channels in the corresponding encoder skip\n",
    "        out_ch:  desired output channels for this decoder block\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        self.skip_ch = skip_ch\n",
    "\n",
    "        if self.upsample:\n",
    "            # ConvTranspose2d(in_ch → skip_ch) to match spatial & channel dims\n",
    "            self.up = nn.ConvTranspose2d(in_ch, skip_ch, kernel_size=3,\n",
    "                                         stride=2, padding=1, output_padding=1, bias=True)\n",
    "            nn.init.kaiming_normal_(self.up.weight, mode='fan_out', nonlinearity='relu')\n",
    "            self.bn_up = nn.BatchNorm2d(skip_ch)\n",
    "            self.act_up = activation_parser(activation)\n",
    "            self.attention = AttentionGate(F_g=skip_ch, F_l=skip_ch, F_int=skip_ch // 2) if attention else nn.Identity()\n",
    "        else:\n",
    "            self.up = None\n",
    "            self.bn_up = None\n",
    "            self.act_up = None\n",
    "            self.attention = AttentionGate(F_g=in_ch, F_l=in_ch, F_int=in_ch // 2) if attention else nn.Identity()\n",
    "\n",
    "        #self.double_conv = DoubleConv(in_double, out_ch, activation)\n",
    "        if ASPP_blocks:\n",
    "            # Use ASPP instead of DoubleConv\n",
    "            self.conv = ASPP(in_ch, out_ch, activation)\n",
    "        else:\n",
    "            # Use DoubleConv if ASPP_blocks is False\n",
    "            self.conv = DoubleConv(in_ch, out_ch, activation)\n",
    "        self.cbam        = CBAMBlock(out_ch, ratio=8, kernel_size=7) if attention else nn.Identity()\n",
    "        self.dropout     = nn.Dropout2d(dropout_prob) if dropout_prob > 0 else nn.Identity()\n",
    "\n",
    "    def forward(self, x, skip=None):\n",
    "        if self.upsample:\n",
    "            x = self.up(x)       # (B, skip_ch, H*2, W*2)\n",
    "            x = self.bn_up(x)\n",
    "            x = self.act_up(x)\n",
    "        if skip is not None:\n",
    "            skip = self.attention(g=x, x=skip)\n",
    "            x = torch.cat([x, skip], dim=1)  # (B, 2*skip_ch, H*2, W*2)\n",
    "        x = self.conv(x)\n",
    "        x = self.cbam(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleneckTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes a tensor of shape (B, C, H, W), flattens the H×W patches into tokens,\n",
    "    runs a small TransformerEncoder over them, then reshapes back to (B, C, H, W).\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, heads=8, depth=3, mlp_dim=None):\n",
    "        super().__init__()\n",
    "        mlp_dim = mlp_dim or dim * 4\n",
    "        # one TransformerEncoderLayer (or more, if depth>1)\n",
    "        layer_e = nn.TransformerEncoderLayer(\n",
    "            d_model=dim,\n",
    "            nhead=heads,\n",
    "            dim_feedforward=mlp_dim,\n",
    "            activation='relu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        layer_d = nn.TransformerDecoderLayer(\n",
    "            d_model=dim,\n",
    "            nhead=heads,\n",
    "            dim_feedforward=mlp_dim,\n",
    "            activation='relu',\n",
    "            norm_first=True,  # important for TransformerDecoder\n",
    "            #batch_first=True\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(layer_e, num_layers=depth//2 if depth > 1 else depth)\n",
    "        self.norm    = nn.LayerNorm(dim)\n",
    "        if depth > 1:\n",
    "            self.decoder = nn.TransformerDecoder(layer_d, num_layers=depth - depth//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W)\n",
    "        B, C, H, W = x.shape\n",
    "        # flatten spatial dims:\n",
    "        # → (B, C, H*W) then permute to (H*W, B, C) for PyTorch’s MHSA\n",
    "        tokens = x.flatten(2).permute(2, 0, 1)   # (H*W, B, C)\n",
    "        # run through TransformerEncoder\n",
    "        out   = self.encoder(tokens)             # (H*W, B, C)\n",
    "        # run through TransformerDecoder (optional, if depth > 1)\n",
    "        if hasattr(self, 'decoder'):\n",
    "            out = self.decoder(out, out)          # (H*W, B, C)\n",
    "        # put back into (B, C, H, W) after a LayerNorm on each token\n",
    "        out   = out.permute(1, 2, 0).view(B, C, H, W)\n",
    "        return self.norm(out.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
    "        # explanation of the two permutes:\n",
    "        #  - out.permute(1,2,0)→(B, C, H*W) then .view(B, C, H, W)\n",
    "        #  - we want LN over the C‐dimension, so we permute to (B, H, W, C), apply LayerNorm,\n",
    "        #    then back to (B, C, H, W).\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=1,\n",
    "                 out_channels=1,\n",
    "                 down_filters=None,\n",
    "                 down_activations=None,\n",
    "                 up_filters=None,\n",
    "                 up_activations=None,\n",
    "                 bottleneck_transformer=True,\n",
    "                 ASPP_blocks=True,\n",
    "                 output_sigmoid=True):\n",
    "        super().__init__()\n",
    "        assert len(down_filters) == len(down_activations)\n",
    "        assert len(up_filters)   == len(up_activations)\n",
    "\n",
    "        # Build Encoder path\n",
    "        self.output_sigmoid = output_sigmoid\n",
    "        self.input_norm = nn.BatchNorm2d(in_channels)\n",
    "        self.encoders = nn.ModuleList()\n",
    "        self.bottleneck_transformer = bottleneck_transformer\n",
    "        prev_ch = in_channels\n",
    "        for i, out_ch in enumerate(down_filters):\n",
    "            act_str = down_activations[i].lower()\n",
    "            self.encoders.append(\n",
    "                EncoderBlock(in_ch=prev_ch,\n",
    "                             out_ch=out_ch,\n",
    "                             activation=act_str,\n",
    "                             dropout_prob=0.1,\n",
    "                             attention=(i != 0),\n",
    "                             pool=True,\n",
    "                             ASPP_blocks=ASPP_blocks)\n",
    "            )\n",
    "            prev_ch = out_ch\n",
    "\n",
    "        # Bottleneck:\n",
    "        if bottleneck_transformer:\n",
    "            self.bottleneck  = BottleneckTransformer(dim=down_filters[-1],\n",
    "                                                           heads=4,\n",
    "                                                           depth=4)\n",
    "        else:\n",
    "            self.bottleneck = nn.Identity()\n",
    "\n",
    "        # Build Decoder path\n",
    "        self.decoders = nn.ModuleList()\n",
    "        N = len(down_filters)\n",
    "        for i in range(len(up_filters)):\n",
    "            act_str = up_activations[i].lower()\n",
    "            # Corresponding skip channels from encoder\n",
    "            skip_ch = down_filters[N - 1 - i]\n",
    "            # Input channels for this decoder block\n",
    "            out_ch = up_filters[i]\n",
    "            in_ch_dec = (down_filters[-1] * 1) if (i == 0) else up_filters[i - 1]\n",
    "\n",
    "            self.decoders.append(\n",
    "                DecoderBlock(in_ch=in_ch_dec,\n",
    "                             skip_ch=skip_ch,\n",
    "                             out_ch=out_ch,\n",
    "                             activation=act_str,\n",
    "                             dropout_prob=0.1,\n",
    "                             attention= True,\n",
    "                             upsample=True,\n",
    "                             ASPP_blocks=ASPP_blocks)\n",
    "            )\n",
    "\n",
    "        if output_sigmoid:\n",
    "            self.final_conv = nn.Sequential(\n",
    "                nn.Conv2d(up_filters[-1], out_channels, kernel_size=5, padding=2, bias=True),\n",
    "                nn.Sigmoid())\n",
    "            nn.init.kaiming_normal_(self.final_conv[0].weight, mode='fan_out', nonlinearity='sigmoid')\n",
    "            nn.init.constant_(self.final_conv[0].bias, 0)\n",
    "        else:\n",
    "            self.final_conv = nn.Conv2d(up_filters[-1], out_channels, kernel_size=5, padding=2, bias=True)\n",
    "            nn.init.kaiming_normal_(self.final_conv.weight, mode='fan_out', nonlinearity='relu')\n",
    "            nn.init.constant_(self.final_conv.bias, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_norm(x)  # Normalize input\n",
    "        # x: (B, 1, 128, 128)\n",
    "        skips = []\n",
    "        for enc in self.encoders[:-1]:  # skip last encoder (bottleneck)\n",
    "            x, skip = enc(x)\n",
    "            skips.append(skip)\n",
    "\n",
    "        # Bottleneck:\n",
    "        x, _ = self.encoders[-1](x) # last encoder does not return a skip\n",
    "        skips.append(None)\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        x = self.decoders[0](x, skips[-1])  # first decoder uses the last encoder skip\n",
    "\n",
    "        skips = skips[::-1]              # reverse order for decoding\n",
    "\n",
    "        for i in range(1, len(self.decoders)):\n",
    "            skip_feat = skips[i]\n",
    "            x = self.decoders[i](x, skip_feat)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4668bc53416e595c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T18:15:27.140335Z",
     "start_time": "2025-07-15T18:15:27.137356Z"
    }
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        \"\"\"\n",
    "        preds:   Tensor (B,1,H,W) after Sigmoid\n",
    "        targets: Tensor (B,1,H,W) binary {0,1}\n",
    "        \"\"\"\n",
    "        p_flat = preds.view(-1)\n",
    "        t_flat = targets.view(-1)\n",
    "        intersection = (p_flat * t_flat).sum()\n",
    "        dice_coeff = (2. * intersection + self.smooth) / (p_flat.sum() + t_flat.sum() + self.smooth)\n",
    "        return 1 - dice_coeff\n",
    "\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.9, gamma=2.0, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha, self.gamma, self.eps = alpha, gamma, eps\n",
    "        self.beta = 1 - alpha  # Ensure alpha + beta = 1\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        preds = preds.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        TP = (preds * targets).sum()\n",
    "        FP = (preds * (1 - targets)).sum()\n",
    "        FN = ((1 - preds) * targets).sum()\n",
    "        tversky = (TP + self.eps) / (TP + self.alpha*FN + self.beta*FP + self.eps)\n",
    "        return torch.pow((1 - tversky), self.gamma)\n",
    "\n",
    "class ComboLossTF(nn.Module):\n",
    "    def __init__(self, bce_weight=0.33, dice_weight=0.33, focal_twersky_weight=0.33, alpha=0.95, gamma=3.1):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.dice = DiceLoss(smooth=1e-6)\n",
    "        self.FW = FocalTverskyLoss (alpha = alpha, gamma=gamma)\n",
    "        self.bw, self.dw, self.fw = bce_weight, dice_weight, focal_twersky_weight\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        # preds, targets both (B,1,H,W)\n",
    "        total_loss = 0\n",
    "        if self.bw > 0:\n",
    "            l_bce = self.bce(preds, targets)\n",
    "            total_loss += self.bw * l_bce\n",
    "        if self.dw > 0:\n",
    "            l_dice = self.dice(preds, targets)\n",
    "            total_loss += self.dw * l_dice\n",
    "        if self.fw > 0:\n",
    "            l_focal_tversky = self.FW(preds, targets)\n",
    "            total_loss += self.fw * l_focal_tversky\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T18:15:27.187924Z",
     "start_time": "2025-07-15T18:15:27.184527Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigzi(x, axis=None):\n",
    "    \"\"\"\n",
    "Compute the interquartile range (IQR) of x along the specified axis.\n",
    "    Args:\n",
    "        x: array-like, shape (P, H, W) or (H, W) or (N, C, H, W)\n",
    "        axis: axis along which to compute the IQR.\n",
    "              If None, computes over the flattened array.\n",
    "\n",
    "    Returns: float, the IQR of x.\n",
    "\n",
    "    \"\"\"\n",
    "    return 0.741 * (np.percentile(x, 75, axis=axis) - np.percentile(x, 25, axis=axis))\n",
    "\n",
    "def split_stack(arr, nrows, ncols):\n",
    "    \"\"\"\n",
    "    Split a stack of 2D panels into (nrows × ncols) tiles.\n",
    "    arr: ndarray, shape (P, H, W)\n",
    "    Returns: ndarray, shape (P * (H//nrows)*(W//ncols), nrows, ncols)\n",
    "    \"\"\"\n",
    "    P, H, W = arr.shape\n",
    "    pad_h = (-H) % nrows\n",
    "    pad_w = (-W) % ncols\n",
    "    if pad_h or pad_w:\n",
    "        arr = np.pad(arr,\n",
    "                     ((0, 0),\n",
    "                      (0, pad_h),\n",
    "                      (0, pad_w)),\n",
    "                     mode='constant',\n",
    "                     constant_values=0)\n",
    "    H2, W2 = arr.shape[1], arr.shape[2]\n",
    "    blocks = (arr\n",
    "              .reshape(P,\n",
    "                       H2 // nrows, nrows,\n",
    "                       W2 // ncols, ncols)\n",
    "              .swapaxes(2, 3))\n",
    "    P2, Hb, Wb, nr, nc = blocks.shape\n",
    "    out = blocks.reshape(P2 * Hb * Wb, nr, nc)\n",
    "    return out\n",
    "\n",
    "def build_datasets(npz_file, tile_size=128):\n",
    "    \"\"\"\n",
    "    Load data from .npz, clip exactly as TF did, split into tiles, return PyTorch tensors.\n",
    "      - Clips x to [-166.43, 169.96]\n",
    "      - Splits each large image into (tile_size × tile_size) patches\n",
    "      - Adds a channel dimension (→ shape (N, 1, tile_size, tile_size))\n",
    "    \"\"\"\n",
    "    data = np.load(npz_file)\n",
    "    x = data['x']  # shape (P, H, W)\n",
    "    y = data['y']\n",
    "\n",
    "    x = x/sigzi(x)  # normalize by interquartile range\n",
    "    x = np.clip(x, -7, 7) # clip to [-5, 5]\n",
    "\n",
    "    # Split into tiles (tile_size × tile_size)\n",
    "    x_tiles = split_stack(x, tile_size, tile_size)  # (N_tiles, tile_size, tile_size)\n",
    "    y_tiles = split_stack(y, tile_size, tile_size)\n",
    "\n",
    "    # Convert to FloatTensor and add channel dimension\n",
    "    x_tiles = torch.from_numpy(x_tiles).float().unsqueeze(1)  # (N, 1, tile_size, tile_size)\n",
    "    y_tiles = torch.from_numpy(y_tiles).float().unsqueeze(1)  # (N, 1, tile_size, tile_size)\n",
    "\n",
    "    return x_tiles, y_tiles\n",
    "\n",
    "def reshape_masks(masks, new_size):\n",
    "    \"\"\"\n",
    "    Resize binary masks (0/1) to `new_size`:\n",
    "      - Uses bilinear interpolation (same as TF’s tf.image.resize with bilinear)\n",
    "      - Applies torch.ceil(...) to recover {0,1} values exactly.\n",
    "    Input:\n",
    "      - masks: either a Tensor of shape (N, 1, H_orig, W_orig)\n",
    "               or a numpy array of shape (N, H_orig, W_orig)\n",
    "      - new_size: tuple (new_H, new_W)\n",
    "    Returns:\n",
    "      - Tensor of shape (N, 1, new_H, new_W), values in {0,1}\n",
    "    \"\"\"\n",
    "    if isinstance(masks, np.ndarray):\n",
    "        m = torch.from_numpy(masks).float().unsqueeze(1)  # → (N,1,H,W)\n",
    "    else:\n",
    "        m = masks  # assume already FloatTensor (N,1,H,W)\n",
    "    m_resized = F.interpolate(m, size=new_size, mode='bilinear', align_corners=False)\n",
    "    m_resized = torch.ceil(m_resized)\n",
    "    return m_resized.clamp(0, 1)\n",
    "\n",
    "def split_train_val(x_tiles, y_tiles, train_frac=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Shuffle and split x_tiles, y_tiles into two TensorDatasets: train (80%) and val (20%).\n",
    "    \"\"\"\n",
    "    n = x_tiles.shape[0]\n",
    "    idx = torch.randperm(n, generator=torch.Generator().manual_seed(seed))\n",
    "    split = int(train_frac * n)\n",
    "    train_idx = idx[:split]\n",
    "    val_idx   = idx[split:]\n",
    "    train_idx, val_idx = train_idx.sort().values, val_idx.sort().values\n",
    "    x_tr, y_tr = x_tiles[train_idx], y_tiles[train_idx]\n",
    "    x_val, y_val = x_tiles[val_idx], y_tiles[val_idx]\n",
    "    return TensorDataset(x_tr, y_tr), TensorDataset(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42c2e411098d4b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T18:15:27.325401Z",
     "start_time": "2025-07-15T18:15:27.233439Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_ds, val_ds, epochs=100, batch_size=32, lr=1e-3, loss=None, alpha=0.99, gamma=3.1, device=None):\n",
    "    \"\"\"\n",
    "    Train the model on train_ds, validate on val_ds, and print losses + F1 each epoch.\n",
    "    Resizes all masks to `output_size` so that preds and targets match in spatial dims.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 1) Figure out the model’s output spatial size by pushing a dummy 128×128 patch.\n",
    "    model.eval()  # ensure BatchNorm uses running‐stats, not “batch” stats\n",
    "    with torch.no_grad():\n",
    "        dummy = torch.randn(1, 1, 128, 128).to(device)\n",
    "        out_dummy = model(dummy)\n",
    "        output_size = (out_dummy.shape[-2], out_dummy.shape[-1])  # e.g. (32,32) for your JSON\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=4, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=4, pin_memory=True)\n",
    "\n",
    "    if loss is None:\n",
    "        criterion = ComboLossTF(bce_weight=0.0, dice_weight=0.0, focal_twersky_weight=1, alpha=alpha, gamma=gamma)\n",
    "    else:\n",
    "        criterion = loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                max_lr=lr,\n",
    "                                                steps_per_epoch=len(train_loader),\n",
    "                                                epochs=epochs,\n",
    "                                                pct_start=0.1,\n",
    "                                                anneal_strategy='cos')\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ——— Training ———\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        tp = fp = fn = 0\n",
    "        for batch_num, (imgs, masks) in enumerate(train_loader):\n",
    "            imgs = imgs.to(device)  # (B,1,128,128)\n",
    "\n",
    "            # Resize the ground‐truth masks to output_size (e.g. (32,32))\n",
    "            m_resized = reshape_masks(masks, new_size=output_size).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(imgs)              # (B,1, output_H, output_W)\n",
    "            loss = criterion(preds, m_resized)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sched.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            if not model.output_sigmoid:\n",
    "                # If model does not output Sigmoid, apply it here\n",
    "                preds = torch.sigmoid(preds)\n",
    "            with torch.no_grad():\n",
    "                pred_bin = (preds > 0.5).float()\n",
    "                t = m_resized\n",
    "                tp += (pred_bin * t).sum().item()\n",
    "                fp += (pred_bin * (1 - t)).sum().item()\n",
    "                fn += ((1 - pred_bin) * t).sum().item()\n",
    "\n",
    "            prec = tp / (tp + fp + 1e-8)\n",
    "            rec  = tp / (tp + fn + 1e-8)\n",
    "            f1   = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "            print (f\"\\rEpoch {epoch:03d}  \"\n",
    "                   f\"Batch {batch_num+1:03d}/{len(train_loader)}  \"\n",
    "                   f\"Batch Loss: {loss.item():.4f}  \"\n",
    "                   f\"| train F1: {f1:.4f}  | train precision: {prec:.4f}  | train recall: {rec:.4f}\", end='\\r')\n",
    "\n",
    "        train_loss = running_loss / len(train_ds)\n",
    "        prec = tp / (tp + fp + 1e-8)\n",
    "        rec  = tp / (tp + fn + 1e-8)\n",
    "        f1   = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "\n",
    "        # ——— Validation ———\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        tp = fp = fn = 0\n",
    "        val_y = []\n",
    "        pred_val = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                m_resized = reshape_masks(masks, new_size=output_size).to(device)\n",
    "                preds = model(imgs)\n",
    "                loss = criterion(preds, m_resized)\n",
    "                val_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "                if not model.output_sigmoid:\n",
    "                    preds = torch.sigmoid(preds)  # apply Sigmoid if model does not output it\n",
    "                pred_bin = (preds > 0.5).float()\n",
    "                tp += (pred_bin * m_resized).sum().item()\n",
    "                fp += (pred_bin * (1 - m_resized)).sum().item()\n",
    "                fn += ((1 - pred_bin) * m_resized).sum().item()\n",
    "                val_y.append(m_resized.cpu().numpy())\n",
    "                pred_val.append(preds.cpu().numpy())\n",
    "        # Collect all validation masks for AUC calculation\n",
    "        val_y = np.concatenate(val_y, axis=0)\n",
    "        preds_val = np.concatenate(pred_val, axis=0)  # (N, 1, Hout, Wout)\n",
    "        val_loss = val_loss / len(val_ds)\n",
    "        prec = tp / (tp + fp + 1e-8)\n",
    "        rec  = tp / (tp + fn + 1e-8)\n",
    "        f1_val = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "        auc_val = sklearn.metrics.roc_auc_score(val_y.flatten(), preds_val.flatten() )\n",
    "\n",
    "        print(f\"Epoch {epoch:03d}  \"\n",
    "              f\"Train Loss: {train_loss:.4f}  \"\n",
    "              f\"| Val Loss: {val_loss:.4f}  \"\n",
    "              f\"| Train F1: {f1:.4f}  \"\n",
    "              f\"| Val F1: {f1_val:.4f}  \"\n",
    "              f\"| Val Prec: {prec:.4f}  \"\n",
    "              f\"| Val Rec: {rec:.4f}\"\n",
    "              f\"| Val AUC: {auc_val:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdca56a2e5d4e6d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T18:20:15.531528Z",
     "start_time": "2025-06-12T18:18:53.623516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(301.2692)\n"
     ]
    }
   ],
   "source": [
    "npz_file = \"../DATA/train.npz\"\n",
    "x_tiles, y_tiles = build_datasets(npz_file, tile_size=128)\n",
    "pos_weights = (y_tiles==1).sum() / (y_tiles==0).sum()\n",
    "print((y_tiles==0).sum()/(y_tiles==1).sum())\n",
    "train_ds, val_ds = split_train_val(x_tiles, y_tiles, train_frac=0.8, seed=42)\n",
    "del x_tiles, y_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe140c0ff8133fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T18:58:26.473146Z",
     "start_time": "2025-06-12T18:20:15.674872Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50842/1766484567.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weights))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001  Train Loss: 0.8726  | Val Loss: 0.3473  | Train F1: 0.0068  | Val F1: 0.0073  | Val Prec: 0.0037  | Val Rec: 0.1461| Val AUC: 0.5030\n",
      "Epoch 002  Train Loss: 0.2085  | Val Loss: 0.0733  | Train F1: 0.0066  | Val F1: 0.0057  | Val Prec: 0.0037  | Val Rec: 0.0128| Val AUC: 0.5181\n",
      "Epoch 003  Train Loss: 0.0618  | Val Loss: 0.0192  | Train F1: 0.0050  | Val F1: 0.0002  | Val Prec: 0.0063  | Val Rec: 0.0001| Val AUC: 0.5188\n",
      "Epoch 004  Train Loss: 0.0188  | Val Loss: 0.0053  | Train F1: 0.0009  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5002\n",
      "Epoch 005  Train Loss: 0.0067  | Val Loss: 0.0024  | Train F1: 0.0002  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.4972\n",
      "Epoch 006  Train Loss: 0.0031  | Val Loss: 0.0012  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.4982\n",
      "Epoch 007  Train Loss: 0.0017  | Val Loss: 0.0007  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5017\n",
      "Epoch 008  Train Loss: 0.0010  | Val Loss: 0.0004  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5082\n",
      "Epoch 009  Train Loss: 0.0007  | Val Loss: 0.0003  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5136\n",
      "Epoch 010  Train Loss: 0.0004  | Val Loss: 0.0002  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5121\n",
      "Epoch 011  Train Loss: 0.0003  | Val Loss: 0.0002  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5054\n",
      "Epoch 012  Train Loss: 0.0003  | Val Loss: 0.0002  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5138\n",
      "Epoch 013  Train Loss: 0.0002  | Val Loss: 0.0002  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5146\n",
      "Epoch 014  Train Loss: 0.0002  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5237\n",
      "Epoch 015  Train Loss: 0.0002  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5210\n",
      "Epoch 016  Train Loss: 0.0002  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5270\n",
      "Epoch 017  Train Loss: 0.0002  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5501\n",
      "Epoch 018  Train Loss: 0.0002  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5668\n",
      "Epoch 019  Train Loss: 0.0002  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5697\n",
      "Epoch 020  Train Loss: 0.0002  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5896\n",
      "Epoch 021  Train Loss: 0.0002  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.6076\n",
      "Epoch 022  Train Loss: 0.0002  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.5815\n",
      "Epoch 023  Train Loss: 0.0002  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.6157\n",
      "Epoch 024  Train Loss: 0.0001  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.6170\n",
      "Epoch 025  Train Loss: 0.0001  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.6432\n",
      "Epoch 026  Train Loss: 0.0001  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.6139\n",
      "Epoch 027  Train Loss: 0.0001  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.6596\n",
      "Epoch 028  Train Loss: 0.0001  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.6369\n",
      "Epoch 029  Train Loss: 0.0001  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.6731\n",
      "Epoch 030  Train Loss: 0.0001  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.6921\n",
      "Epoch 031  Train Loss: 0.0001  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.6946\n",
      "Epoch 032  Train Loss: 0.0001  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.6890\n",
      "Epoch 033  Train Loss: 0.0001  | Val Loss: 0.0001  | Train F1: 0.0000  | Val F1: 0.0000  | Val Prec: 0.0000  | Val Rec: 0.0000| Val AUC: 0.6786\n",
      "Epoch 034  Batch 078/647  Batch Loss: 0.0001  | train F1: 0.0000  | train precision: 0.0000  | train recall: 0.0000\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      8\u001b[39m loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weights))\n\u001b[32m      9\u001b[39m model = UNet(\n\u001b[32m     10\u001b[39m         down_filters=down_filters,\n\u001b[32m     11\u001b[39m         down_activations=down_activations,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m         ASPP_blocks=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     16\u001b[39m         output_sigmoid=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m trained_model = train_model(model,\n\u001b[32m     20\u001b[39m                             train_ds, val_ds,\n\u001b[32m     21\u001b[39m                             epochs=\u001b[32m150\u001b[39m,\n\u001b[32m     22\u001b[39m                             batch_size=\u001b[32m128\u001b[39m,\n\u001b[32m     23\u001b[39m                             lr=\u001b[32m0.00015\u001b[39m,\n\u001b[32m     24\u001b[39m                             alpha=\u001b[32m0.95\u001b[39m, gamma=\u001b[32m3.1\u001b[39m, loss=loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_ds, val_ds, epochs, batch_size, lr, loss, alpha, gamma, device)\u001b[39m\n\u001b[32m     50\u001b[39m sched.step()\n\u001b[32m     51\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m running_loss += loss.item() * imgs.size(\u001b[32m0\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model.output_sigmoid:\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# If model does not output Sigmoid, apply it here\u001b[39;00m\n\u001b[32m     56\u001b[39m     preds = torch.sigmoid(preds)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#down_filters     = [32, 64, 128, 256, 512]\n",
    "down_filters =  [32, 32, 64, 128, 256, 512, 1024]\n",
    "down_activations = ['relu', 'selu', 'selu', 'selu', 'selu', 'selu', 'selu']\n",
    "\n",
    "up_filters       = [1024, 512, 256, 128, 64]\n",
    "up_activations   = ['selu', 'selu', 'selu', 'selu', 'relu']\n",
    "# BCE loss with logits with\n",
    "loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weights))\n",
    "model = UNet(\n",
    "        down_filters=down_filters,\n",
    "        down_activations=down_activations,\n",
    "        up_filters=up_filters,\n",
    "        up_activations=up_activations,\n",
    "        bottleneck_transformer=False,\n",
    "        ASPP_blocks=False,\n",
    "        output_sigmoid=False)\n",
    "\n",
    "\n",
    "trained_model = train_model(model,\n",
    "                            train_ds, val_ds,\n",
    "                            epochs=150,\n",
    "                            batch_size=128,\n",
    "                            lr=0.00015,\n",
    "                            alpha=0.95, gamma=3.1, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "754226ac719ba211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T11:42:37.213115Z",
     "start_time": "2025-06-12T11:42:37.051583Z"
    }
   },
   "outputs": [],
   "source": [
    "save_path = \"../DATA/unet_model5.pth\"\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4eaf1e38b6330f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T15:13:59.771888Z",
     "start_time": "2025-06-11T15:13:59.666127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (input_norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (encoders): ModuleList(\n",
       "    (0): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): Identity()\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (1): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Sigmoid()\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=64, out_features=8, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=8, out_features=64, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (2): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=128, out_features=16, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (3): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=256, out_features=32, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=32, out_features=256, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (4): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=512, out_features=64, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=64, out_features=512, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): Identity()\n",
       "  (decoders): ModuleList(\n",
       "    (0): DecoderBlock(\n",
       "      (up): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (bn_up): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_up): ReLU(inplace=True)\n",
       "      (attention): AttentionGate(\n",
       "        (W_g): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (W_x): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (psi): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Sigmoid()\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=512, out_features=64, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=64, out_features=512, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (1): DecoderBlock(\n",
       "      (up): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (bn_up): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_up): ReLU(inplace=True)\n",
       "      (attention): AttentionGate(\n",
       "        (W_g): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (W_x): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (psi): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Sigmoid()\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=256, out_features=32, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=32, out_features=256, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (2): DecoderBlock(\n",
       "      (up): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (bn_up): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_up): ReLU(inplace=True)\n",
       "      (attention): AttentionGate(\n",
       "        (W_g): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (W_x): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (psi): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Sigmoid()\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=128, out_features=16, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Sequential(\n",
       "    (0): Conv2d(128, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_filters =  [32, 32, 32, 64, 128, 256, 512]\n",
    "down_activations = ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu']\n",
    "\n",
    "up_filters       = [512, 256, 128, 64, 32]\n",
    "up_activations   = ['relu', 'relu', 'relu', 'relu', 'relu']\n",
    "\n",
    "model_loaded = UNet(\n",
    "    down_filters=down_filters,\n",
    "    down_activations=down_activations,\n",
    "    up_filters=up_filters,\n",
    "    up_activations=up_activations,\n",
    "    bottleneck_transformer=False,\n",
    "    ASPP_blocks=False\n",
    ")\n",
    "\n",
    "# 2) Load the saved state_dict:\n",
    "checkpoint = torch.load(\"../DATA/unet_model3.pth\", map_location=\"cpu\")\n",
    "model_loaded.load_state_dict(checkpoint)\n",
    "\n",
    "# 3) Put into eval mode (if only doing inference):\n",
    "model_loaded.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14d55bcde18116e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T11:42:49.149752Z",
     "start_time": "2025-06-12T11:42:49.146665Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, dataset, batch_size=32, device=None,\n",
    "                  return_probs: bool = True,  # if False, returns binary masks (0/1)\n",
    "                  threshold: float = 0.5      # threshold for binarization if return_probs=False\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Run inference on `dataset` using `model` and return all predictions.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): trained segmentation model (expects input shape (B,1,128,128) → output (B,1,Hout,Wout)).\n",
    "        dataset (torch.utils.data.Dataset): either\n",
    "            - A TensorDataset of (images, masks), or\n",
    "            - A Dataset that returns just `image` (no mask) if you only want predictions.\n",
    "        batch_size (int): batch size for DataLoader.\n",
    "        device (torch.device or str): 'cuda' or 'cpu'. If None, uses CUDA if available.\n",
    "        return_probs (bool):\n",
    "            - If True, returns the raw sigmoid‐probabilities of shape (N, 1, Hout, Wout).\n",
    "            - If False, thresholds those probabilities at `threshold` and returns binary masks (0/1).\n",
    "        threshold (float): cutoff for turning probability → 0/1 when return_probs=False.\n",
    "\n",
    "    Returns:\n",
    "        preds: numpy array of shape\n",
    "            - (N, 1, Hout, Wout) with float32 probs  in [0,1], if return_probs=True;\n",
    "            - (N, 1, Hout, Wout) with uint8 masks {0,1},       if return_probs=False.\n",
    "\n",
    "    Usage:\n",
    "        # 1) If you have (x_val, y_val) as a TensorDataset and want only predictions:\n",
    "        preds = predict_model(model, TensorDataset(torch.from_numpy(x_val).float(), torch.zeros(len(x_val),1,1,1)),\n",
    "                              batch_size=64, device='cuda', return_probs=False)\n",
    "\n",
    "        # 2) If your dataset yields only images (no masks):\n",
    "        preds = predict_model(model, test_dataset, batch_size=64, device='cuda', return_probs=True)\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # We don’t need real masks during inference, so DataLoader can silently ignore them.\n",
    "    # We'll detect whether dataset returns (img, mask) or just img.\n",
    "    def _collate_fn(batch):\n",
    "        # batch is a list of dataset[i] returns.\n",
    "        # If dataset[i] is a tuple (img, mask), take only img.\n",
    "        if isinstance(batch[0], (list, tuple)):\n",
    "            imgs = torch.stack([item[0] for item in batch], dim=0)\n",
    "        else:\n",
    "            imgs = torch.stack(batch, dim=0)\n",
    "        return imgs\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                        collate_fn=_collate_fn,\n",
    "                        num_workers=4, pin_memory=True)\n",
    "\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in loader:\n",
    "            imgs = imgs.to(device)                     # (B, 1, 128, 128) or similar\n",
    "            probs = model(imgs)                        # (B, 1, Hout, Wout), already in [0,1] due to final Sigmoid\n",
    "            if return_probs:\n",
    "                all_preds.append(probs.cpu())\n",
    "            else:\n",
    "                bin_masks = (probs > threshold).float()  # (B, 1, Hout, Wout) of 0.0 or 1.0\n",
    "                all_preds.append(bin_masks.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0)  # (N, 1, Hout, Wout)\n",
    "    if return_probs:\n",
    "        return all_preds.numpy().astype('float32')\n",
    "    else:\n",
    "        # convert to uint8 (0/1) for easier downstream use\n",
    "        return all_preds.numpy().astype('uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9025c0e112346b9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T11:42:49.320190Z",
     "start_time": "2025-06-12T11:42:49.315682Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataset_to_numpy(dataset, batch_size=64, device=None):\n",
    "    \"\"\"\n",
    "    Given a Dataset that returns either:\n",
    "      - (image_tensor, mask_tensor),  or\n",
    "      - just image_tensor\n",
    "    this function will loop once through the dataset, gather everything,\n",
    "    and return NumPy arrays.\n",
    "\n",
    "    Returns:\n",
    "      If dataset[i] returns (img, mask) for each i, then\n",
    "        imgs_np: shape (N, C, H, W) or whatever\n",
    "        masks_np: shape (N, Cm, Hm, Wm) (e.g. (N,1,128,128))\n",
    "      If dataset[i] returns only img, then\n",
    "        imgs_np: shape (N, C, H, W)\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # We won’t actually move data to GPU here, just stack on CPU at the end.\n",
    "    # But if your dataset does expensive preprocessing on CPU, you can pin_memory=True.\n",
    "\n",
    "    def _collate_fn(batch):\n",
    "        # If each element is (img, mask), we stack only imgs and masks separately.\n",
    "        # But DataLoader collate_fn must return a single tensor; we’ll handle masks in the loop.\n",
    "        # Instead, we return the raw batch list and unpack in the loop below.\n",
    "        return batch\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=_collate_fn,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    imgs_list = []\n",
    "    masks_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            # batch is a list of length `batch_size` (or the remainder on the last batch).\n",
    "            # Each element is either (img, mask) or just img.\n",
    "            first_elem = batch[0]\n",
    "            if isinstance(first_elem, (tuple, list)) and len(first_elem) == 2:\n",
    "                # Dataset returns (img, mask)\n",
    "                imgs = torch.stack([item[0] for item in batch], dim=0)   # (B, C, H, W)\n",
    "                masks = torch.stack([item[1] for item in batch], dim=0)  # (B, Cm, Hm, Wm)\n",
    "                imgs_list.append(imgs.cpu().numpy())\n",
    "                masks_list.append(masks.cpu().numpy())\n",
    "            else:\n",
    "                # Dataset returns only img\n",
    "                imgs = torch.stack(batch, dim=0)  # (B, C, H, W)\n",
    "                imgs_list.append(imgs.cpu().numpy())\n",
    "\n",
    "    imgs_np = np.concatenate(imgs_list, axis=0)\n",
    "    if masks_list:\n",
    "        masks_np = np.concatenate(masks_list, axis=0)\n",
    "        return imgs_np, masks_np\n",
    "    else:\n",
    "        return imgs_np\n",
    "\n",
    "def f2_score_numpy(y_true, y_pred, threshold=0.5, eps=1e-8):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: arrays of the same shape, either (N,H,W) or (N,1,H,W).\n",
    "    threshold: cutoff on y_pred if it’s in [0,1]; if y_pred is already binary, set threshold<0 or skip binarize.\n",
    "    Returns one global F2 (scalar).\n",
    "    \"\"\"\n",
    "    # 1) Binarize predictions (if they’re probabilities)\n",
    "    if y_pred.dtype != np.uint8 and threshold >= 0:\n",
    "        p_bin = (y_pred > threshold).astype(np.uint8)\n",
    "    else:\n",
    "        p_bin = y_pred.astype(np.uint8)\n",
    "\n",
    "    # 2) Similarly ensure y_true is 0/1 uint8\n",
    "    y_bin = y_true.astype(np.uint8)\n",
    "\n",
    "    # 3) Flatten to 1D\n",
    "    if p_bin.ndim == 4 and p_bin.shape[1] == 1:\n",
    "        p_flat = p_bin.squeeze(1).ravel()\n",
    "        y_flat = y_bin.squeeze(1).ravel()\n",
    "    else:\n",
    "        p_flat = p_bin.ravel()\n",
    "        y_flat = y_bin.ravel()\n",
    "\n",
    "    # 4) Compute TP, FP, FN\n",
    "    TP = np.sum((p_flat == 1) & (y_flat == 1))\n",
    "    FP = np.sum((p_flat == 1) & (y_flat == 0))\n",
    "    FN = np.sum((p_flat == 0) & (y_flat == 1))\n",
    "\n",
    "    # 5) Precision = TP / (TP + FP), Recall = TP / (TP + FN)\n",
    "    prec = TP / (TP + FP + eps)\n",
    "    rec  = TP / (TP + FN + eps)\n",
    "\n",
    "    # 6) F2 = 5 * (prec * rec) / (4*prec + rec)\n",
    "    f2 = (1 + 2**2) * (prec * rec) / (2**2 * prec + rec + eps)\n",
    "    return f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "603238926fbca032",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T11:43:43.086906Z",
     "start_time": "2025-06-12T11:42:49.916488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score on validation set: 0.2566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karlo/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/IPython/core/events.py:82: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args, **kwargs)\n",
      "/home/karlo/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1700x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = predict(model, val_ds, batch_size=128, device='cuda', return_probs=True)\n",
    "val_x, val_y = dataset_to_numpy(val_ds, batch_size=128)\n",
    "val_y = reshape_masks(torch.from_numpy(val_y).float(), new_size=(32, 32)).numpy()  # resize to match model output size\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(17, 5))\n",
    "\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(val_y.flatten(), p.flatten())\n",
    "auc_score = sklearn.metrics.auc(fpr, tpr)\n",
    "ax[0].plot(fpr, tpr, label=f'AUC = {auc_score:.4f}')\n",
    "ax[0].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax[0].set_xlabel('False positive rate')\n",
    "ax[0].set_ylabel('True positive rate')\n",
    "ax[0].legend()\n",
    "\n",
    "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(val_y.flatten(), p.flatten())\n",
    "ax[1].plot(precision, recall, label='Precision-Recall curve')\n",
    "ax[1].set_xlabel('Precision')\n",
    "ax[1].set_ylabel('Recall')\n",
    "ax[1].legend()\n",
    "ax[2].plot(thresholds, precision[1:], label='Precision')\n",
    "ax[2].plot(thresholds, recall[1:], label='Recall')\n",
    "ax[2].set_xlabel('Threshold')\n",
    "ax[2].set_ylabel('Score')\n",
    "ax[2].legend()\n",
    "print (f\"F2 score on validation set: {f2_score_numpy(val_y, p, threshold=0.5):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e31f80100bf5ab3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T11:50:02.892568Z",
     "start_time": "2025-06-12T11:50:02.863747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score on validation set: 0.2575\n"
     ]
    }
   ],
   "source": [
    "print (f\"F2 score on validation set: {f2_score_numpy(val_y, p, threshold=0.1):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29b3acb1925ba38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T13:50:47.011738Z",
     "start_time": "2025-06-12T13:43:36.789510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001  Train Loss: 0.1726  | Val Loss: 0.6449  | Train F1: 0.4263  | Val F1: 0.2030  | Val Prec: 0.1766  | Val Rec: 0.2386| Val AUC: 0.6038\n",
      "Epoch 002  Train Loss: 0.1680  | Val Loss: 0.6391  | Train F1: 0.3500  | Val F1: 0.2286  | Val Prec: 0.2141  | Val Rec: 0.2452| Val AUC: 0.6093\n",
      "Epoch 003  Train Loss: 0.1791  | Val Loss: 0.6262  | Train F1: 0.3011  | Val F1: 0.1429  | Val Prec: 0.0997  | Val Rec: 0.2525| Val AUC: 0.6026\n",
      "Epoch 004  Train Loss: 0.1944  | Val Loss: 0.6051  | Train F1: 0.2007  | Val F1: 0.1303  | Val Prec: 0.0856  | Val Rec: 0.2727| Val AUC: 0.6161\n",
      "Epoch 005  Train Loss: 0.1597  | Val Loss: 0.5964  | Train F1: 0.2050  | Val F1: 0.0476  | Val Prec: 0.0260  | Val Rec: 0.2839| Val AUC: 0.6122\n",
      "Epoch 006  Train Loss: 0.1766  | Val Loss: 0.6034  | Train F1: 0.1812  | Val F1: 0.0475  | Val Prec: 0.0260  | Val Rec: 0.2771| Val AUC: 0.6080\n",
      "Epoch 007  Batch 280/647  Batch Loss: 0.2595  | train F1: 0.1418  | train precision: 0.0791  | train recall: 0.6869\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trained_model = train_model(model,\n\u001b[32m      2\u001b[39m                             train_ds, val_ds,\n\u001b[32m      3\u001b[39m                             epochs=\u001b[32m100\u001b[39m,\n\u001b[32m      4\u001b[39m                             batch_size=\u001b[32m128\u001b[39m,\n\u001b[32m      5\u001b[39m                             lr=\u001b[32m1e-4\u001b[39m,\n\u001b[32m      6\u001b[39m                             alpha=\u001b[32m0.995\u001b[39m, gamma=\u001b[32m2.5\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_ds, val_ds, epochs, batch_size, lr, alpha, gamma, device)\u001b[39m\n\u001b[32m     40\u001b[39m m_resized = reshape_masks(masks, new_size=output_size).to(device)\n\u001b[32m     42\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m preds = model(imgs)              \u001b[38;5;66;03m# (B,1, output_H, output_W)\u001b[39;00m\n\u001b[32m     44\u001b[39m loss = criterion(preds, m_resized)\n\u001b[32m     45\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 405\u001b[39m, in \u001b[36mUNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    403\u001b[39m skips = []\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m enc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encoders[:-\u001b[32m1\u001b[39m]:  \u001b[38;5;66;03m# skip last encoder (bottleneck)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m     x, skip = enc(x)\n\u001b[32m    406\u001b[39m     skips.append(skip)\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# Bottleneck:\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 223\u001b[39m, in \u001b[36mEncoderBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.conv(x)\n\u001b[32m    224\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.cbam(x)\n\u001b[32m    225\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 167\u001b[39m, in \u001b[36mDoubleConv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.block(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = module(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/conv.py:553\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    538\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m             F.pad(\n\u001b[32m    540\u001b[39m                 \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m             \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m         )\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    550\u001b[39m         \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m.stride, \u001b[38;5;28mself\u001b[39m.padding, \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups\n\u001b[32m    551\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m.weight, \u001b[38;5;28mself\u001b[39m.bias)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model,\n",
    "                            train_ds, val_ds,\n",
    "                            epochs=100,\n",
    "                            batch_size=128,\n",
    "                            lr=1e-4,\n",
    "                            alpha=0.99, gamma=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "660ef874dd4ccc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T18:29:40.141421Z",
     "start_time": "2025-06-11T18:29:39.774490Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model_loaded.state_dict(), \"../DATA/unet_model3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f034104f5508fc2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ead34bf5eaaf1c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================================================================\n",
      "Layer (type:depth-idx)                             Input Shape               Output Shape              Param #                   Trainable\n",
      "======================================================================================================================================================\n",
      "UNet                                               [128, 1, 128, 128]        [128, 1, 32, 32]          --                        True\n",
      "├─BatchNorm2d: 1-1                                 [128, 1, 128, 128]        [128, 1, 128, 128]        2                         True\n",
      "├─ModuleList: 1-2                                  --                        --                        --                        True\n",
      "│    └─EncoderBlock: 2-1                           [128, 1, 128, 128]        [128, 32, 64, 64]         --                        True\n",
      "│    │    └─DoubleConv: 3-1                        [128, 1, 128, 128]        [128, 32, 128, 128]       9,696                     True\n",
      "│    │    └─Identity: 3-2                          [128, 32, 128, 128]       [128, 32, 128, 128]       --                        --\n",
      "│    │    └─Identity: 3-3                          [128, 32, 128, 128]       [128, 32, 128, 128]       --                        --\n",
      "│    └─EncoderBlock: 2-2                           [128, 32, 64, 64]         [128, 64, 32, 32]         --                        True\n",
      "│    │    └─DoubleConv: 3-4                        [128, 32, 64, 64]         [128, 64, 64, 64]         55,680                    True\n",
      "│    │    └─CBAMBlock: 3-5                         [128, 64, 64, 64]         [128, 64, 64, 64]         1,252                     True\n",
      "│    │    └─Identity: 3-6                          [128, 64, 64, 64]         [128, 64, 64, 64]         --                        --\n",
      "│    └─EncoderBlock: 2-3                           [128, 64, 32, 32]         [128, 128, 16, 16]        --                        True\n",
      "│    │    └─DoubleConv: 3-7                        [128, 64, 32, 32]         [128, 128, 32, 32]        221,952                   True\n",
      "│    │    └─CBAMBlock: 3-8                         [128, 128, 32, 32]        [128, 128, 32, 32]        4,452                     True\n",
      "│    │    └─Identity: 3-9                          [128, 128, 32, 32]        [128, 128, 32, 32]        --                        --\n",
      "│    └─EncoderBlock: 2-4                           [128, 128, 16, 16]        [128, 256, 8, 8]          --                        True\n",
      "│    │    └─DoubleConv: 3-10                       [128, 128, 16, 16]        [128, 256, 16, 16]        886,272                   True\n",
      "│    │    └─CBAMBlock: 3-11                        [128, 256, 16, 16]        [128, 256, 16, 16]        16,996                    True\n",
      "│    │    └─Identity: 3-12                         [128, 256, 16, 16]        [128, 256, 16, 16]        --                        --\n",
      "│    └─EncoderBlock: 2-5                           [128, 256, 8, 8]          [128, 512, 4, 4]          --                        True\n",
      "│    │    └─DoubleConv: 3-13                       [128, 256, 8, 8]          [128, 512, 8, 8]          3,542,016                 True\n",
      "│    │    └─CBAMBlock: 3-14                        [128, 512, 8, 8]          [128, 512, 8, 8]          66,660                    True\n",
      "│    │    └─Identity: 3-15                         [128, 512, 8, 8]          [128, 512, 8, 8]          --                        --\n",
      "├─Identity: 1-3                                    [128, 512, 4, 4]          [128, 512, 4, 4]          --                        --\n",
      "├─ModuleList: 1-4                                  --                        --                        --                        True\n",
      "│    └─DecoderBlock: 2-6                           [128, 512, 4, 4]          [128, 512, 8, 8]          396,288                   True\n",
      "│    │    └─ConvTranspose2d: 3-16                  [128, 512, 4, 4]          [128, 512, 8, 8]          2,359,808                 True\n",
      "│    │    └─BatchNorm2d: 3-17                      [128, 512, 8, 8]          [128, 512, 8, 8]          1,024                     True\n",
      "│    │    └─ReLU: 3-18                             [128, 512, 8, 8]          [128, 512, 8, 8]          --                        --\n",
      "│    │    └─DoubleConv: 3-19                       [128, 512, 8, 8]          [128, 512, 8, 8]          4,721,664                 True\n",
      "│    │    └─CBAMBlock: 3-20                        [128, 512, 8, 8]          [128, 512, 8, 8]          66,660                    True\n",
      "│    │    └─Identity: 3-21                         [128, 512, 8, 8]          [128, 512, 8, 8]          --                        --\n",
      "│    └─DecoderBlock: 2-7                           [128, 512, 8, 8]          [128, 256, 16, 16]        --                        True\n",
      "│    │    └─ConvTranspose2d: 3-22                  [128, 512, 8, 8]          [128, 256, 16, 16]        1,179,904                 True\n",
      "│    │    └─BatchNorm2d: 3-23                      [128, 256, 16, 16]        [128, 256, 16, 16]        512                       True\n",
      "│    │    └─ReLU: 3-24                             [128, 256, 16, 16]        [128, 256, 16, 16]        --                        --\n",
      "│    │    └─AttentionGate: 3-25                    --                        [128, 256, 16, 16]        99,840                    True\n",
      "│    │    └─DoubleConv: 3-26                       [128, 512, 16, 16]        [128, 256, 16, 16]        1,771,008                 True\n",
      "│    │    └─CBAMBlock: 3-27                        [128, 256, 16, 16]        [128, 256, 16, 16]        16,996                    True\n",
      "│    │    └─Identity: 3-28                         [128, 256, 16, 16]        [128, 256, 16, 16]        --                        --\n",
      "│    └─DecoderBlock: 2-8                           [128, 256, 16, 16]        [128, 128, 32, 32]        --                        True\n",
      "│    │    └─ConvTranspose2d: 3-29                  [128, 256, 16, 16]        [128, 128, 32, 32]        295,040                   True\n",
      "│    │    └─BatchNorm2d: 3-30                      [128, 128, 32, 32]        [128, 128, 32, 32]        256                       True\n",
      "│    │    └─ReLU: 3-31                             [128, 128, 32, 32]        [128, 128, 32, 32]        --                        --\n",
      "│    │    └─AttentionGate: 3-32                    --                        [128, 128, 32, 32]        25,344                    True\n",
      "│    │    └─DoubleConv: 3-33                       [128, 256, 32, 32]        [128, 128, 32, 32]        443,136                   True\n",
      "│    │    └─CBAMBlock: 3-34                        [128, 128, 32, 32]        [128, 128, 32, 32]        4,452                     True\n",
      "│    │    └─Identity: 3-35                         [128, 128, 32, 32]        [128, 128, 32, 32]        --                        --\n",
      "├─Sequential: 1-5                                  [128, 128, 32, 32]        [128, 1, 32, 32]          --                        True\n",
      "│    └─Conv2d: 2-9                                 [128, 128, 32, 32]        [128, 1, 32, 32]          3,201                     True\n",
      "│    └─Sigmoid: 2-10                               [128, 1, 32, 32]          [128, 1, 32, 32]          --                        --\n",
      "======================================================================================================================================================\n",
      "Total params: 16,190,111\n",
      "Trainable params: 16,190,111\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 394.54\n",
      "======================================================================================================================================================\n",
      "Input size (MB): 8.39\n",
      "Forward/backward pass size (MB): 6413.24\n",
      "Params size (MB): 63.18\n",
      "Estimated Total Size (MB): 6484.80\n",
      "======================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 1) pip install torchinfo\n",
    "#    (if you haven’t already)\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "down_filters     = [32, 64, 128, 256, 512]\n",
    "down_activations = ['relu', 'relu', 'relu', 'relu', 'relu']\n",
    "\n",
    "up_filters       = [512, 256, 128]\n",
    "up_activations   = ['relu', 'relu', 'relu']\n",
    "\n",
    "# 2) Re‐instantiate your UNet exactly as in your training code:\n",
    "model = UNet(\n",
    "        down_filters=down_filters,\n",
    "        down_activations=down_activations,\n",
    "        up_filters=up_filters,\n",
    "        up_activations=up_activations,\n",
    "bottleneck_transformer=False,\n",
    "ASPP_blocks=False)\n",
    "\n",
    "# 3) Ask for a summary on a dummy (1×1×128×128) input:\n",
    "_ = summary(\n",
    "    model,\n",
    "    input_size=(128, 1, 128, 128),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    verbose=1\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
