{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T18:48:33.345896Z",
     "start_time": "2025-05-20T18:48:33.344198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from torch.amp import GradScaler, autocast"
   ],
   "id": "d66af4afd16ccb8c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T18:48:33.947874Z",
     "start_time": "2025-05-20T18:48:33.944476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    A sequence of two 3x3 convolutions each followed by ReLU activation.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A basic U-Net architecture without attention, SE blocks, or deep supervision.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=None):\n",
    "        super(UNet, self).__init__()\n",
    "        if features is None:\n",
    "            features = [128, 256, 512, 1024]\n",
    "\n",
    "        # Encoder path\n",
    "        self.downs = nn.ModuleList()\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "\n",
    "        # Decoder path\n",
    "        self.ups = nn.ModuleList()\n",
    "        rev_features = features[::-1]\n",
    "        for feature in rev_features:\n",
    "            self.ups.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=3, stride=2))\n",
    "            self.ups.append(DoubleConv(feature * 2, feature))\n",
    "\n",
    "        # Final 1x1 conv\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        # Downsampling\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Reverse skip connections for decoding\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        # Upsampling\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)  # ConvTranspose2d\n",
    "            skip = skip_connections[idx // 2]\n",
    "            # In case the inexact sizes due to pooling\n",
    "            if x.shape != skip.shape:\n",
    "                x = F.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=False)\n",
    "            x = torch.cat((skip, x), dim=1)\n",
    "            x = self.ups[idx + 1](x)  # DoubleConv\n",
    "\n",
    "        return self.final_conv(x)\n"
   ],
   "id": "ebf73c5b9a7e7064",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T18:48:34.936126Z",
     "start_time": "2025-05-20T18:48:34.930381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        num   = 2 * (probs * targets).sum(dim=(1,2,3))\n",
    "        den   = probs.sum(dim=(1,2,3)) + targets.sum(dim=(1,2,3)) + self.eps\n",
    "        dice  = num / den\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, bce_weight=0.5):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceLoss()\n",
    "        self.bw = bce_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        return self.bw * self.bce(logits, targets) + (1 - self.bw) * self.dice(logits, targets)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha, self.gamma, self.eps = alpha, gamma, eps\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits).clamp(self.eps, 1 - self.eps)\n",
    "        pt = torch.where(targets==1, probs, 1 - probs)\n",
    "        w  = torch.where(targets==1, self.alpha, 1 - self.alpha)\n",
    "        loss = - w * (1 - pt)**self.gamma * pt.log()\n",
    "        return loss.mean()\n",
    "\n",
    "class TverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, beta=0.3, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha, self.beta, self.eps = alpha, beta, eps\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits)\n",
    "        TP = (probs * targets).sum(dim=(1,2,3))\n",
    "        FP = (probs * (1-targets)).sum(dim=(1,2,3))\n",
    "        FN = ((1-probs) * targets).sum(dim=(1,2,3))\n",
    "        tversky = (TP + self.eps) / (TP + self.alpha*FN + self.beta*FP + self.eps)\n",
    "        return 1 - tversky.mean()\n",
    "\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, beta=0.3, gamma=1.5, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.tversky = TverskyLoss(alpha, beta, eps)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        t = 1 - self.tversky(logits, targets)\n",
    "        return t ** self.gamma\n",
    "\n",
    "class TverskyF2Loss(nn.Module):\n",
    "    def forward(self, preds, targets):\n",
    "        TP = (preds*targets).sum()\n",
    "        FN = ((1-preds)*targets).sum()\n",
    "        FP = (preds*(1-targets)).sum()\n",
    "        return (FN + 1e-6) / (2*TP + FN + 1e-6)\n",
    "\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.9, beta=0.1, gamma=2.0, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha, self.beta, self.gamma, self.eps = alpha, beta, gamma, eps\n",
    "    def forward(self, preds, targets):\n",
    "        preds = preds.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        TP = (preds * targets).sum()\n",
    "        FP = (preds * (1 - targets)).sum()\n",
    "        FN = ((1 - preds) * targets).sum()\n",
    "        tversky = (TP + self.eps) / (TP + self.alpha*FN + self.beta*FP + self.eps)\n",
    "        return torch.pow((1 - tversky), self.gamma)\n",
    "\n",
    "class ComboLoss(nn.Module):\n",
    "    def __init__(self, pos_weight=500.0, bce_weight=0.2, dice_weight=0.4):\n",
    "        super().__init__()\n",
    "        self.bce  = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))\n",
    "        self.ft   = FocalTverskyLoss(alpha=0.7, beta=0.3, gamma=2.0)\n",
    "        self.tf2 = TverskyF2Loss()\n",
    "        self.bw, self.dw= bce_weight, dice_weight\n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss  = self.bce(logits, targets)\n",
    "        dice_loss = self.ft(torch.sigmoid(logits), targets)\n",
    "        return self.bw*bce_loss + self.dw*dice_loss\n",
    "\n",
    "class H5Dataset(Dataset):\n",
    "    def __init__(self,path): self.path=path; self.f=None\n",
    "    def __len__(self): return h5py.File(self.path,'r')['x'].shape[0]\n",
    "    def __getitem__(self,idx):\n",
    "        if self.f is None:\n",
    "            self.f = h5py.File(self.path,'r', swmr=True)\n",
    "        x = torch.from_numpy(self.f['x'][idx]).float()\n",
    "        y = torch.from_numpy(self.f['y'][idx]).float()\n",
    "        return x, y"
   ],
   "id": "821be146107c8f31",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-20T18:49:04.700920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "    bs, max_batches, epochs = 64, 500, 400\n",
    "    train_path = 'train.h5'\n",
    "    val_path   = 'val.h5'\n",
    "\n",
    "    # ─── datasets ───\n",
    "    train_ds = H5Dataset(train_path)\n",
    "    val_ds   = H5Dataset(val_path)\n",
    "\n",
    "    # ─── train loader ───\n",
    "    # pick exactly bs*max_batches random samples from train set\n",
    "    tr_idx = torch.randperm(len(train_ds))[: bs * max_batches]\n",
    "    tr_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=bs,\n",
    "        sampler=SubsetRandomSampler(tr_idx),\n",
    "        num_workers=10,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=8,\n",
    "    )\n",
    "\n",
    "    # ─── val loader ───\n",
    "    # just iterate through val.h5 in order (or set shuffle=True if you like)\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=bs,\n",
    "        shuffle=False,\n",
    "        num_workers=10,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        prefetch_factor=8,\n",
    "    )\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = UNet(in_channels=1, out_channels=1).to(device)\n",
    "    crit  = ComboLoss(pos_weight=500, bce_weight=0.5, dice_weight=0.5)\n",
    "\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(opt, max_lr=1e-4, steps_per_epoch=len(tr_loader), epochs=epochs)\n",
    "\n",
    "    scaler = GradScaler('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_f1s = []\n",
    "    val_precisions = []\n",
    "    val_recalls = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # ——— train ———\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch_num, (imgs, msk) in enumerate(pbar:=tqdm(tr_loader, desc=f\"Epoch {epoch}\")):\n",
    "            imgs = imgs/50\n",
    "            imgs = imgs.to(device)\n",
    "            msk  = msk.to(device)\n",
    "            opt.zero_grad()\n",
    "            with autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                seg_logits = model(imgs)\n",
    "                loss = crit(seg_logits, msk)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(opt)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix(avg_train_loss=total_loss/(bs*(batch_num+1)), batch_loss=loss.item()/bs, lr=sched.get_last_lr()[0])\n",
    "            sched.step()\n",
    "        train_losses.append(total_loss/len(train_ds))\n",
    "\n",
    "        # ——— validate ———\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tp=fp=fn=0\n",
    "            loss = 0\n",
    "            for imgs, msk in val_loader:\n",
    "                imgs = imgs/50\n",
    "                imgs = imgs.to(device)\n",
    "                msk  = msk.to(device)\n",
    "                with autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                    seg_logits = model(imgs)\n",
    "                    loss += crit(seg_logits, msk)\n",
    "                preds = (torch.sigmoid(seg_logits)>0.5).float().view(-1)\n",
    "                t     = msk.view(-1)\n",
    "\n",
    "                tp += (preds * t).sum().item()\n",
    "                fp += (preds * (1-t)).sum().item()\n",
    "                fn += ((1-preds)*t).sum().item()\n",
    "\n",
    "            prec = tp/(tp+fp+1e-8)\n",
    "            rec  = tp/(tp+fn+1e-8)\n",
    "            f1   = 2*prec*rec/(prec+rec+1e-8)\n",
    "            val_losses.append(loss/len(val_ds))\n",
    "            val_f1s.append(f1)\n",
    "            val_precisions.append(prec)\n",
    "            val_recalls.append(rec)\n",
    "            print(f\"Val loss: {loss/len(val_ds):.4f}  Val F1: {f1:.4f}  (P={prec:.4f}, R={rec:.4f})\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 235/235 [01:11<00:00,  3.30it/s, avg_train_loss=0.0175, batch_loss=0.0154, lr=4.02e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0139  Val F1: 0.0005  (P=0.0003, R=0.7252)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 235/235 [01:10<00:00,  3.32it/s, avg_train_loss=0.0167, batch_loss=0.0166, lr=4.07e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0131  Val F1: 0.0007  (P=0.0003, R=0.6203)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 235/235 [01:10<00:00,  3.32it/s, avg_train_loss=0.0164, batch_loss=0.016, lr=4.15e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0127  Val F1: 0.0007  (P=0.0004, R=0.5893)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 235/235 [01:10<00:00,  3.32it/s, avg_train_loss=0.0157, batch_loss=0.0151, lr=4.26e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0122  Val F1: 0.0008  (P=0.0004, R=0.5358)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 235/235 [01:10<00:00,  3.32it/s, avg_train_loss=0.0139, batch_loss=0.0134, lr=4.41e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0120  Val F1: 0.0008  (P=0.0004, R=0.4750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 235/235 [01:10<00:00,  3.32it/s, avg_train_loss=0.0124, batch_loss=0.0126, lr=4.59e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0126  Val F1: 0.0007  (P=0.0003, R=0.4857)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 235/235 [01:10<00:00,  3.31it/s, avg_train_loss=0.0115, batch_loss=0.0122, lr=4.8e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0112  Val F1: 0.0013  (P=0.0006, R=0.3391)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 235/235 [01:10<00:00,  3.32it/s, avg_train_loss=0.0109, batch_loss=0.0116, lr=5.05e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0114  Val F1: 0.0011  (P=0.0006, R=0.3492)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 235/235 [01:10<00:00,  3.31it/s, avg_train_loss=0.0105, batch_loss=0.0106, lr=5.33e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0106  Val F1: 0.0019  (P=0.0010, R=0.2285)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 235/235 [01:10<00:00,  3.32it/s, avg_train_loss=0.0102, batch_loss=0.0123, lr=5.63e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0109  Val F1: 0.0012  (P=0.0006, R=0.2636)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 235/235 [01:10<00:00,  3.32it/s, avg_train_loss=0.0101, batch_loss=0.00983, lr=5.98e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0111  Val F1: 0.0010  (P=0.0005, R=0.2934)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 235/235 [01:10<00:00,  3.32it/s, avg_train_loss=0.00982, batch_loss=0.00975, lr=6.35e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0103  Val F1: 0.0029  (P=0.0014, R=0.2507)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00949, batch_loss=0.00953, lr=6.75e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0103  Val F1: 0.0026  (P=0.0013, R=0.2308)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.0094, batch_loss=0.00932, lr=7.19e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0102  Val F1: 0.0029  (P=0.0014, R=0.2162)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00939, batch_loss=0.0104, lr=7.65e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0105  Val F1: 0.0016  (P=0.0008, R=0.2583)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00928, batch_loss=0.00937, lr=8.15e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0103  Val F1: 0.0020  (P=0.0010, R=0.2322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00903, batch_loss=0.00909, lr=8.67e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0100  Val F1: 0.0031  (P=0.0016, R=0.2157)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00873, batch_loss=0.01, lr=9.23e-6]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0101  Val F1: 0.0024  (P=0.0012, R=0.1666)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00896, batch_loss=0.00916, lr=9.81e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0100  Val F1: 0.0030  (P=0.0015, R=0.2179)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00902, batch_loss=0.00894, lr=1.04e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0100  Val F1: 0.0026  (P=0.0013, R=0.2840)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.0087, batch_loss=0.00847, lr=1.11e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0099  Val F1: 0.0029  (P=0.0015, R=0.2511)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00834, batch_loss=0.00826, lr=1.17e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0098  Val F1: 0.0037  (P=0.0019, R=0.2301)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00804, batch_loss=0.0081, lr=1.24e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0099  Val F1: 0.0028  (P=0.0014, R=0.1866)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00828, batch_loss=0.00842, lr=1.32e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0104  Val F1: 0.0014  (P=0.0007, R=0.2876)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00841, batch_loss=0.00794, lr=1.39e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0098  Val F1: 0.0032  (P=0.0016, R=0.1959)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00805, batch_loss=0.00766, lr=1.47e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0098  Val F1: 0.0031  (P=0.0015, R=0.2071)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00799, batch_loss=0.00729, lr=1.55e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0098  Val F1: 0.0040  (P=0.0020, R=0.2153)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00782, batch_loss=0.00689, lr=1.63e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0098  Val F1: 0.0032  (P=0.0016, R=0.2425)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00771, batch_loss=0.00773, lr=1.72e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0101  Val F1: 0.0020  (P=0.0010, R=0.2190)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00746, batch_loss=0.00677, lr=1.81e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0100  Val F1: 0.0035  (P=0.0017, R=0.1882)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00719, batch_loss=0.00664, lr=1.9e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0099  Val F1: 0.0051  (P=0.0026, R=0.1674)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00724, batch_loss=0.00662, lr=1.99e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0099  Val F1: 0.0044  (P=0.0022, R=0.2327)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00702, batch_loss=0.0111, lr=2.08e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0100  Val F1: 0.0034  (P=0.0017, R=0.1730)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00662, batch_loss=0.00731, lr=2.18e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0104  Val F1: 0.0019  (P=0.0009, R=0.2333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00661, batch_loss=0.00703, lr=2.28e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0101  Val F1: 0.0034  (P=0.0017, R=0.2155)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00606, batch_loss=0.00696, lr=2.38e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0102  Val F1: 0.0047  (P=0.0024, R=0.1819)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00551, batch_loss=0.0047, lr=2.48e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0102  Val F1: 0.0054  (P=0.0028, R=0.1673)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00542, batch_loss=0.0054, lr=2.59e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0103  Val F1: 0.0066  (P=0.0034, R=0.1666)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00522, batch_loss=0.00407, lr=2.69e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0104  Val F1: 0.0049  (P=0.0025, R=0.1751)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00488, batch_loss=0.0066, lr=2.8e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0106  Val F1: 0.0030  (P=0.0015, R=0.1919)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00459, batch_loss=0.00503, lr=2.91e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0105  Val F1: 0.0100  (P=0.0052, R=0.1532)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00426, batch_loss=0.00319, lr=3.02e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0106  Val F1: 0.0045  (P=0.0023, R=0.1933)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00462, batch_loss=0.00426, lr=3.13e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0106  Val F1: 0.0046  (P=0.0023, R=0.2028)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00399, batch_loss=0.00782, lr=3.25e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0106  Val F1: 0.0083  (P=0.0043, R=0.1992)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00427, batch_loss=0.00531, lr=3.36e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0108  Val F1: 0.0141  (P=0.0074, R=0.1537)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00417, batch_loss=0.00527, lr=3.48e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0108  Val F1: 0.0092  (P=0.0047, R=0.1645)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00383, batch_loss=0.00375, lr=3.6e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0109  Val F1: 0.0070  (P=0.0036, R=0.1907)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00315, batch_loss=0.00337, lr=3.72e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0112  Val F1: 0.0089  (P=0.0046, R=0.1287)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00296, batch_loss=0.00276, lr=3.84e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0110  Val F1: 0.0213  (P=0.0116, R=0.1275)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00275, batch_loss=0.0036, lr=3.96e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0110  Val F1: 0.0289  (P=0.0162, R=0.1345)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00406, batch_loss=0.0156, lr=4.08e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0111  Val F1: 0.0086  (P=0.0044, R=0.1351)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.0044, batch_loss=0.0076, lr=4.2e-5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0111  Val F1: 0.0093  (P=0.0048, R=0.1536)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00428, batch_loss=0.00414, lr=4.32e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0111  Val F1: 0.0166  (P=0.0087, R=0.1648)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00378, batch_loss=0.0051, lr=4.45e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0112  Val F1: 0.0166  (P=0.0087, R=0.1572)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00347, batch_loss=0.00388, lr=4.57e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0114  Val F1: 0.0091  (P=0.0047, R=0.1500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.0029, batch_loss=0.00353, lr=4.7e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0114  Val F1: 0.0190  (P=0.0102, R=0.1516)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00236, batch_loss=0.00202, lr=4.82e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0112  Val F1: 0.0170  (P=0.0089, R=0.1859)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00337, batch_loss=0.00324, lr=4.95e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0112  Val F1: 0.0135  (P=0.0070, R=0.1813)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00439, batch_loss=0.00421, lr=5.07e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0113  Val F1: 0.0122  (P=0.0063, R=0.1816)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00394, batch_loss=0.0111, lr=5.2e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0115  Val F1: 0.0236  (P=0.0129, R=0.1431)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00361, batch_loss=0.00689, lr=5.33e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0115  Val F1: 0.0181  (P=0.0097, R=0.1345)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00319, batch_loss=0.00544, lr=5.45e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0113  Val F1: 0.0092  (P=0.0047, R=0.1788)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00319, batch_loss=0.00325, lr=5.58e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0115  Val F1: 0.0252  (P=0.0139, R=0.1357)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00215, batch_loss=0.00482, lr=5.7e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0114  Val F1: 0.0317  (P=0.0177, R=0.1510)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00231, batch_loss=0.00189, lr=5.83e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0116  Val F1: 0.0115  (P=0.0060, R=0.1709)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00338, batch_loss=0.00324, lr=5.95e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0117  Val F1: 0.0213  (P=0.0115, R=0.1520)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00387, batch_loss=0.00451, lr=6.07e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0118  Val F1: 0.0071  (P=0.0036, R=0.1415)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00394, batch_loss=0.00406, lr=6.2e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0118  Val F1: 0.0108  (P=0.0056, R=0.1597)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00352, batch_loss=0.00497, lr=6.32e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0117  Val F1: 0.0270  (P=0.0150, R=0.1340)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 235/235 [01:09<00:00,  3.37it/s, avg_train_loss=0.00311, batch_loss=0.00296, lr=6.44e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0118  Val F1: 0.0117  (P=0.0061, R=0.1502)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 235/235 [01:11<00:00,  3.30it/s, avg_train_loss=0.00226, batch_loss=0.000998, lr=6.56e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0116  Val F1: 0.0314  (P=0.0177, R=0.1393)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 235/235 [01:10<00:00,  3.32it/s, avg_train_loss=0.00256, batch_loss=0.00751, lr=6.68e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0117  Val F1: 0.0311  (P=0.0174, R=0.1493)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 235/235 [01:10<00:00,  3.32it/s, avg_train_loss=0.00266, batch_loss=0.00242, lr=6.8e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0120  Val F1: 0.0166  (P=0.0088, R=0.1401)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 235/235 [01:13<00:00,  3.21it/s, avg_train_loss=0.00317, batch_loss=0.00374, lr=6.92e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0118  Val F1: 0.0155  (P=0.0082, R=0.1466)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 235/235 [01:10<00:00,  3.32it/s, avg_train_loss=0.00347, batch_loss=0.00817, lr=7.04e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0117  Val F1: 0.0131  (P=0.0068, R=0.1714)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 235/235 [01:10<00:00,  3.31it/s, avg_train_loss=0.00449, batch_loss=0.00396, lr=7.15e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0118  Val F1: 0.0143  (P=0.0075, R=0.1504)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 235/235 [01:10<00:00,  3.31it/s, avg_train_loss=0.00294, batch_loss=0.0068, lr=7.27e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0120  Val F1: 0.0096  (P=0.0050, R=0.1485)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 235/235 [01:11<00:00,  3.31it/s, avg_train_loss=0.00321, batch_loss=0.00784, lr=7.38e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0119  Val F1: 0.0172  (P=0.0091, R=0.1789)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 235/235 [01:11<00:00,  3.31it/s, avg_train_loss=0.00258, batch_loss=0.00188, lr=7.49e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0122  Val F1: 0.0143  (P=0.0076, R=0.1355)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 235/235 [01:10<00:00,  3.31it/s, avg_train_loss=0.00211, batch_loss=0.00173, lr=7.6e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0121  Val F1: 0.0243  (P=0.0133, R=0.1460)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 235/235 [01:10<00:00,  3.31it/s, avg_train_loss=0.00205, batch_loss=0.00197, lr=7.71e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0120  Val F1: 0.0262  (P=0.0142, R=0.1707)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████| 235/235 [01:11<00:00,  3.31it/s, avg_train_loss=0.00199, batch_loss=0.00226, lr=7.81e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0122  Val F1: 0.0232  (P=0.0125, R=0.1682)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 235/235 [01:11<00:00,  3.31it/s, avg_train_loss=0.00275, batch_loss=0.00336, lr=7.92e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0123  Val F1: 0.0171  (P=0.0091, R=0.1383)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 235/235 [01:11<00:00,  3.31it/s, avg_train_loss=0.00327, batch_loss=0.00219, lr=8.02e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0118  Val F1: 0.0144  (P=0.0075, R=0.1824)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 235/235 [01:10<00:00,  3.31it/s, avg_train_loss=0.00318, batch_loss=0.00386, lr=8.12e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0121  Val F1: 0.0147  (P=0.0077, R=0.1635)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|██████████| 235/235 [01:10<00:00,  3.33it/s, avg_train_loss=0.00338, batch_loss=0.00286, lr=8.22e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0120  Val F1: 0.0155  (P=0.0081, R=0.1627)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00277, batch_loss=0.0022, lr=8.32e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0122  Val F1: 0.0148  (P=0.0077, R=0.1695)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00244, batch_loss=0.0019, lr=8.41e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0123  Val F1: 0.0164  (P=0.0086, R=0.1699)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00235, batch_loss=0.00472, lr=8.5e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0126  Val F1: 0.0121  (P=0.0063, R=0.1285)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00227, batch_loss=0.00412, lr=8.59e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0123  Val F1: 0.0301  (P=0.0168, R=0.1476)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00184, batch_loss=0.00214, lr=8.68e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0123  Val F1: 0.0135  (P=0.0070, R=0.1709)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|██████████| 235/235 [01:10<00:00,  3.36it/s, avg_train_loss=0.00227, batch_loss=0.00383, lr=8.77e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0122  Val F1: 0.0298  (P=0.0164, R=0.1591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00334, batch_loss=0.0046, lr=8.85e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0125  Val F1: 0.0236  (P=0.0128, R=0.1528)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00293, batch_loss=0.00213, lr=8.93e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0122  Val F1: 0.0319  (P=0.0179, R=0.1457)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.0027, batch_loss=0.00209, lr=9.01e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0125  Val F1: 0.0275  (P=0.0153, R=0.1323)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00192, batch_loss=0.00115, lr=9.08e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0122  Val F1: 0.0328  (P=0.0186, R=0.1390)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00174, batch_loss=0.0015, lr=9.16e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0126  Val F1: 0.0253  (P=0.0139, R=0.1409)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00216, batch_loss=0.00374, lr=9.23e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0125  Val F1: 0.0439  (P=0.0261, R=0.1399)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00227, batch_loss=0.00482, lr=9.29e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0127  Val F1: 0.0240  (P=0.0129, R=0.1684)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00202, batch_loss=0.00512, lr=9.36e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0125  Val F1: 0.0189  (P=0.0101, R=0.1470)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00221, batch_loss=0.00217, lr=9.42e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0125  Val F1: 0.0269  (P=0.0146, R=0.1646)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102: 100%|██████████| 235/235 [01:10<00:00,  3.35it/s, avg_train_loss=0.00299, batch_loss=0.00286, lr=9.48e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0127  Val F1: 0.0252  (P=0.0138, R=0.1430)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103: 100%|██████████| 235/235 [01:11<00:00,  3.28it/s, avg_train_loss=0.00241, batch_loss=0.00418, lr=9.53e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0125  Val F1: 0.0319  (P=0.0179, R=0.1494)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104: 100%|██████████| 235/235 [01:15<00:00,  3.13it/s, avg_train_loss=0.00208, batch_loss=0.00265, lr=9.58e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0129  Val F1: 0.0236  (P=0.0130, R=0.1301)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105: 100%|██████████| 235/235 [01:13<00:00,  3.19it/s, avg_train_loss=0.00195, batch_loss=0.0029, lr=9.63e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.0127  Val F1: 0.0436  (P=0.0259, R=0.1372)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106:  14%|█▍        | 34/235 [00:10<01:00,  3.34it/s, avg_train_loss=0.0021, batch_loss=0.00334, lr=9.64e-5] "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T16:56:37.387903Z",
     "start_time": "2025-05-20T16:56:37.385633Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"unet_basic.pth\")",
   "id": "8ffd3f3dd115837f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e2a77c0e24318912"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
