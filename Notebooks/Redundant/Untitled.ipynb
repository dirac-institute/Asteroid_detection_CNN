{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8713c13-814b-44fb-b170-271616f4661a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The provided filename unet_tf_parity_scripted.pt does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m device = torch.device(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# ---- load scripted model (no class/arch needed) ----\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m model = torch.jit.load(\u001b[33m\"\u001b[39m\u001b[33munet_tf_parity_scripted.pt\u001b[39m\u001b[33m\"\u001b[39m, map_location=device)\n\u001b[32m      9\u001b[39m model.eval().to(device)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# ---- pick your loss (same as train) ----\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# If you trained with Focal-Tversky on probs:\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/jit/_serialization.py:158\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, _extra_files, _restore_shapes)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, (\u001b[38;5;28mstr\u001b[39m, os.PathLike)):\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(f):\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe provided filename \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(f):\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe provided filename \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is a directory\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: The provided filename unet_tf_parity_scripted.pt does not exist"
     ]
    }
   ],
   "source": [
    "import time, numpy as np, torch, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ---- load scripted model (no class/arch needed) ----\n",
    "model = torch.jit.load(\"unet_tf_parity_scripted.pt\", map_location=device)\n",
    "model.eval().to(device)\n",
    "\n",
    "# ---- pick your loss (same as train) ----\n",
    "# If you trained with Focal-Tversky on probs:\n",
    "class FocalTverskyLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=0.95, gamma=3.1, eps=1.0):\n",
    "        super().__init__(); self.alpha, self.gamma, self.eps = alpha, gamma, eps; self.beta = 1 - alpha\n",
    "    def forward(self, p, t):\n",
    "        p = p.view(-1); t = t.view(-1)\n",
    "        TP = (p*t).sum(); FP = (p*(1-t)).sum(); FN = ((1-p)*t).sum()\n",
    "        tv = (TP + self.eps)/(TP + self.alpha*FN + self.beta*FP + self.eps)\n",
    "        return torch.pow(1 - tv, self.gamma)\n",
    "\n",
    "criterion = FocalTverskyLoss(alpha=0.95, gamma=3.1)\n",
    "\n",
    "# ---- mask resize helper (your TF-parity step) ----\n",
    "def resize_masks_to(pred, masks):\n",
    "    H, W = pred.shape[-2:]\n",
    "    m = F.interpolate(masks.float(), size=(H, W), mode='bilinear', align_corners=False)\n",
    "    return torch.ceil(m).clamp_(0, 1)\n",
    "\n",
    "# ---- evaluation loop (AUC computed once at end) ----\n",
    "@torch.no_grad()\n",
    "def evaluate(loader, tag=\"Test\", print_every=10):\n",
    "    start = time.time()\n",
    "    model.eval()\n",
    "    total = len(loader.dataset)\n",
    "    seen = 0\n",
    "    running_loss = 0.0\n",
    "    tp = fp = fn = 0.0\n",
    "    preds_all, targs_all = [], []\n",
    "\n",
    "    for b, (xb, yb) in enumerate(loader, start=1):\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = model(xb)                 # sigmoid probs\n",
    "        yb_r = resize_masks_to(out, yb)\n",
    "        loss = criterion(out, yb_r)\n",
    "\n",
    "        bs = xb.size(0)\n",
    "        seen += bs\n",
    "        running_loss += float(loss.item()) * bs\n",
    "\n",
    "        p = out.detach().cpu().view(-1)\n",
    "        t = yb_r.detach().cpu().view(-1)\n",
    "        preds_all.append(p.numpy())\n",
    "        targs_all.append(t.numpy())\n",
    "\n",
    "        # stream PRF1\n",
    "        p_bin = (p >= 0.5).float()\n",
    "        tp += float((p_bin * t).sum())\n",
    "        fp += float((p_bin * (1 - t)).sum())\n",
    "        fn += float(((1 - p_bin) * t).sum())\n",
    "\n",
    "        if (b % print_every == 0) or (seen == total):\n",
    "            prec = tp / (tp + fp + 1e-8)\n",
    "            rec  = tp / (tp + fn + 1e-8)\n",
    "            f1   = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "            avg_loss = running_loss / seen\n",
    "            print(f\"\\r[{tag}] {seen}/{total} ex | loss={avg_loss:.4f} | F1 {f1:.4f} | P {prec:.4f} | R {rec:.4f} | {time.time()-start:.1f}s\",\n",
    "                  end='', flush=True)\n",
    "\n",
    "    print()  # newline\n",
    "    # Final AUC (fixes your “AUC None” — now computed once per split)\n",
    "    try:\n",
    "        P = np.concatenate(preds_all, 0)\n",
    "        T = np.concatenate(targs_all, 0)\n",
    "        auc = roc_auc_score(T, P)\n",
    "    except Exception:\n",
    "        auc = float('nan')\n",
    "\n",
    "    prec = tp / (tp + fp + 1e-8)\n",
    "    rec  = tp / (tp + fn + 1e-8)\n",
    "    f1   = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "    loss = running_loss / total\n",
    "    print(f\"[{tag}] Loss {loss:.4f} | AUC {auc:.4f} | F1 {f1:.4f} | P {prec:.4f} | R {rec:.4f}\")\n",
    "    return loss, auc, prec, rec, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d55074-1ad3-4500-947a-3ff4e5966ae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'UNetTFParity' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = torch.load(\u001b[33m\"\u001b[39m\u001b[33m./model1.pt\u001b[39m\u001b[33m\"\u001b[39m, weights_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/serialization.py:1525\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1523\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1524\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1525\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1526\u001b[39m             opened_zipfile,\n\u001b[32m   1527\u001b[39m             map_location,\n\u001b[32m   1528\u001b[39m             pickle_module,\n\u001b[32m   1529\u001b[39m             overall_storage=overall_storage,\n\u001b[32m   1530\u001b[39m             **pickle_load_args,\n\u001b[32m   1531\u001b[39m         )\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[32m   1533\u001b[39m     f_name = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/serialization.py:2114\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2112\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   2113\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2114\u001b[39m result = unpickler.load()\n\u001b[32m   2115\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2117\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/serialization.py:2103\u001b[39m, in \u001b[36m_load.<locals>.UnpicklerWrapper.find_class\u001b[39m\u001b[34m(self, mod_name, name)\u001b[39m\n\u001b[32m   2101\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   2102\u001b[39m mod_name = load_module_mapping.get(mod_name, mod_name)\n\u001b[32m-> \u001b[39m\u001b[32m2103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().find_class(mod_name, name)\n",
      "\u001b[31mAttributeError\u001b[39m: Can't get attribute 'UNetTFParity' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"./model1.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f5f5b5-ac19-451c-8997-6332b799c4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Asteroid detection",
   "language": "python",
   "name": "asteroid_detection_cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
