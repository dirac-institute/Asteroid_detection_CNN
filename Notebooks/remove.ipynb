{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T17:01:52.093730Z",
     "start_time": "2025-06-04T17:01:50.810306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "id": "badb4d69691fed76",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T17:10:43.476767Z",
     "start_time": "2025-06-04T17:10:43.473410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigzi(x, axis=None):\n",
    "    \"\"\"\n",
    "Compute the interquartile range (IQR) of x along the specified axis.\n",
    "    Args:\n",
    "        x: array-like, shape (P, H, W) or (H, W) or (N, C, H, W)\n",
    "        axis: axis along which to compute the IQR.\n",
    "              If None, computes over the flattened array.\n",
    "\n",
    "    Returns: float, the IQR of x.\n",
    "\n",
    "    \"\"\"\n",
    "    return 0.741 * (np.percentile(x, 75, axis=axis) - np.percentile(x, 25, axis=axis))\n",
    "\n",
    "def split_stack(arr, nrows, ncols):\n",
    "    \"\"\"\n",
    "    Split a stack of 2D panels into (nrows × ncols) tiles.\n",
    "    arr: ndarray, shape (P, H, W)\n",
    "    Returns: ndarray, shape (P * (H//nrows)*(W//ncols), nrows, ncols)\n",
    "    \"\"\"\n",
    "    P, H, W = arr.shape\n",
    "    pad_h = (-H) % nrows\n",
    "    pad_w = (-W) % ncols\n",
    "    if pad_h or pad_w:\n",
    "        arr = np.pad(arr,\n",
    "                     ((0, 0),\n",
    "                      (0, pad_h),\n",
    "                      (0, pad_w)),\n",
    "                     mode='constant',\n",
    "                     constant_values=0)\n",
    "    H2, W2 = arr.shape[1], arr.shape[2]\n",
    "    blocks = (arr\n",
    "              .reshape(P,\n",
    "                       H2 // nrows, nrows,\n",
    "                       W2 // ncols, ncols)\n",
    "              .swapaxes(2, 3))\n",
    "    P2, Hb, Wb, nr, nc = blocks.shape\n",
    "    out = blocks.reshape(P2 * Hb * Wb, nr, nc)\n",
    "    return out\n",
    "\n",
    "def build_datasets(npz_file, tile_size=128):\n",
    "    \"\"\"\n",
    "    Load data from .npz, clip exactly as TF did, split into tiles, return PyTorch tensors.\n",
    "      - Clips x to [-166.43, 169.96]\n",
    "      - Splits each large image into (tile_size × tile_size) patches\n",
    "      - Adds a channel dimension (→ shape (N, 1, tile_size, tile_size))\n",
    "    \"\"\"\n",
    "    data = np.load(npz_file)\n",
    "    x = data['x']  # shape (P, H, W)\n",
    "    y = data['y']\n",
    "\n",
    "    x = x/sigzi(x)  # normalize by interquartile range\n",
    "    x = np.clip(x, -5, 5) # clip to [-5, 5]\n",
    "\n",
    "    # Split into tiles (tile_size × tile_size)\n",
    "    x_tiles = split_stack(x, tile_size, tile_size)  # (N_tiles, tile_size, tile_size)\n",
    "    y_tiles = split_stack(y, tile_size, tile_size)\n",
    "\n",
    "    # Convert to FloatTensor and add channel dimension\n",
    "    x_tiles = torch.from_numpy(x_tiles).float().unsqueeze(1)  # (N, 1, tile_size, tile_size)\n",
    "    y_tiles = torch.from_numpy(y_tiles).float().unsqueeze(1)  # (N, 1, tile_size, tile_size)\n",
    "\n",
    "    return x_tiles, y_tiles\n",
    "\n",
    "def split_train_val(x_tiles, y_tiles, train_frac=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Shuffle and split x_tiles, y_tiles into two TensorDatasets: train (80%) and val (20%).\n",
    "    \"\"\"\n",
    "    n = x_tiles.shape[0]\n",
    "    idx = torch.randperm(n, generator=torch.Generator().manual_seed(seed))\n",
    "    split = int(train_frac * n)\n",
    "    train_idx = idx[:split]\n",
    "    val_idx   = idx[split:]\n",
    "    # sort indices to keep order in each dataset\n",
    "    train_idx, val_idx = train_idx.sort().values, val_idx.sort().values\n",
    "    x_tr, y_tr = x_tiles[train_idx], y_tiles[train_idx]\n",
    "    x_val, y_val = x_tiles[val_idx], y_tiles[val_idx]\n",
    "    return TensorDataset(x_tr, y_tr), TensorDataset(x_val, y_val)"
   ],
   "id": "64b18f61b52e366b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T17:07:39.647998Z",
     "start_time": "2025-06-04T17:07:37.105578Z"
    }
   },
   "cell_type": "code",
   "source": "x_test, y_test = np.load(\"../DATA/test.npz\").values() # load the npz file",
   "id": "initial_id",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T17:08:11.964735Z",
     "start_time": "2025-06-04T17:07:56.633609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_tiles, y_tiles = build_datasets(\"../DATA/test.npz\", tile_size=128)\n",
    "# 5) Split into train/val datasets:\n",
    "test_ds, _ = split_train_val(x_tiles, y_tiles, train_frac=1, seed=42)"
   ],
   "id": "94ed35851b352ac1",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 18613 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m x_tiles, y_tiles = build_datasets(\u001B[33m\"\u001B[39m\u001B[33m../DATA/test.npz\u001B[39m\u001B[33m\"\u001B[39m, tile_size=\u001B[32m128\u001B[39m)\n\u001B[32m      2\u001B[39m \u001B[38;5;66;03m# 5) Split into train/val datasets:\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m test_ds, _ = split_train_val(x_tiles, y_tiles, train_frac=\u001B[32m1\u001B[39m, seed=\u001B[32m42\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 75\u001B[39m, in \u001B[36msplit_train_val\u001B[39m\u001B[34m(x_tiles, y_tiles, train_frac, seed)\u001B[39m\n\u001B[32m     73\u001B[39m \u001B[38;5;66;03m# sort indices to keep order in each dataset\u001B[39;00m\n\u001B[32m     74\u001B[39m train_idx, val_idx = train_idx.sort(), val_idx.sort()\n\u001B[32m---> \u001B[39m\u001B[32m75\u001B[39m x_tr, y_tr = x_tiles[train_idx], y_tiles[train_idx]\n\u001B[32m     76\u001B[39m x_val, y_val = x_tiles[val_idx], y_tiles[val_idx]\n\u001B[32m     77\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m TensorDataset(x_tr, y_tr), TensorDataset(x_val, y_val)\n",
      "\u001B[31mIndexError\u001B[39m: index 18613 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T17:10:54.888262Z",
     "start_time": "2025-06-04T17:10:54.687363Z"
    }
   },
   "cell_type": "code",
   "source": "test_ds, _ = split_train_val(x_tiles, y_tiles, train_frac=1, seed=42)",
   "id": "7d2aa799e19a772a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bbdffb1b53694f05"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
