{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T20:09:26.004163Z",
     "start_time": "2025-06-11T20:09:25.000708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import sklearn"
   ],
   "id": "c757f4099bf6030e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T20:09:26.119180Z",
     "start_time": "2025-06-11T20:09:26.041538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def activation_parser(activation_str):\n",
    "    \"\"\"\n",
    "    Parse a string to return the corresponding activation function.\n",
    "    Supported strings: 'relu', 'sigmoid', 'tanh', 'leaky_relu'.\n",
    "    \"\"\"\n",
    "    if activation_str.lower() == \"elu\":\n",
    "        return nn.ELU(inplace=True)\n",
    "    elif activation_str.lower() == \"hardshrink\":\n",
    "        return nn.Hardshrink(lambd=0.5)\n",
    "    elif activation_str.lower() == \"hardtanh\":\n",
    "        return nn.Hardtanh(min_val=-1, max_val=1, inplace=True)\n",
    "    elif activation_str.lower() == \"logsigmoid\":\n",
    "        return nn.LogSigmoid()\n",
    "    elif activation_str.lower() == \"relu6\":\n",
    "        return nn.ReLU6(inplace=True)\n",
    "    elif activation_str.lower() == \"softplus\":\n",
    "        return nn.Softplus()\n",
    "    elif activation_str.lower() == \"selu\":\n",
    "        return nn.SELU(inplace=True)\n",
    "    elif activation_str.lower() == \"prelu\":\n",
    "        return nn.PReLU()\n",
    "    elif activation_str.lower() == \"softmax\":\n",
    "        return nn.Softmax(dim=1)  # softmax along channel dimension\n",
    "    if activation_str.lower() == 'relu':\n",
    "        return nn.ReLU(inplace=True)\n",
    "    elif activation_str.lower() == 'sigmoid':\n",
    "        return nn.Sigmoid()\n",
    "    elif activation_str.lower() == 'tanh':\n",
    "        return nn.Tanh()\n",
    "    elif activation_str.lower() == 'leaky_relu':\n",
    "        return nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported activation: {activation_str}\")\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_channels, in_channels // ratio, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(in_channels // ratio, in_channels, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self.norm = nn.LayerNorm(in_channels)\n",
    "        self.norm = nn.BatchNorm1d(in_channels)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        #nn.init.constant_(self.fc1.bias, 0)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, mode='fan_out', nonlinearity='sigmoid')\n",
    "        #nn.init.constant_(self.fc2.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.avg_pool(x)        # (B, C, 1, 1)\n",
    "        avg_out = avg_out.view(avg_out.size(0), avg_out.size(1))  # (B, C)\n",
    "        avg_out = self.fc1(avg_out)       # (B, C//ratio)\n",
    "        avg_out = self.relu(avg_out)\n",
    "        avg_out = self.fc2(avg_out)       # (B, C)\n",
    "\n",
    "        max_out = self.max_pool(x)        # (B, C, 1, 1)\n",
    "        max_out = max_out.view(max_out.size(0), max_out.size(1))  # (B, C)\n",
    "        max_out = self.fc1(max_out)       # (B, C//ratio)\n",
    "        max_out = self.relu(max_out)\n",
    "        max_out = self.fc2(max_out)       # (B, C)\n",
    "\n",
    "        out = avg_out + max_out           # (B, C)\n",
    "        out = self.norm(out)              # (B, C)\n",
    "        scale = self.sigmoid(out)         # (B, C)\n",
    "        scale = scale.view(scale.size(0), scale.size(1), 1, 1)  # (B, C, 1, 1)\n",
    "        return x * scale                  # broadcast along H, W\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=5):\n",
    "        super().__init__()\n",
    "        assert kernel_size in (3, 5, 7)\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.norm = nn.BatchNorm2d(1)\n",
    "        nn.init.kaiming_normal_(self.conv.weight, mode='fan_in', nonlinearity='sigmoid')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)     # (B, 1, H, W)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)   # (B, 1, H, W)\n",
    "        concat = torch.cat([avg_out, max_out], dim=1)    # (B, 2, H, W)\n",
    "        attn = self.conv(concat)                         # (B, 1, H, W)\n",
    "        attn = self.norm(attn)                           # (B, 1, H, W)\n",
    "        attn = self.sigmoid(attn)\n",
    "        return x * attn                                  # broadcast across C\n",
    "\n",
    "class CBAMBlock(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=8, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.channel_att = ChannelAttention(in_channels, ratio)\n",
    "        self.spatial_att = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.channel_att(x)\n",
    "        x = self.spatial_att(x)\n",
    "        return x\n",
    "\n",
    "class SepConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation, kernel_size, padding, dilation=1):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_ch, in_ch, kernel_size=kernel_size,\n",
    "            padding=padding, dilation=dilation,\n",
    "            groups=in_ch, bias=True\n",
    "        )\n",
    "        self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=True)\n",
    "        self.norm = nn.BatchNorm2d(out_ch)\n",
    "        self.act = activation_parser(activation)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.depthwise.weight, mode='fan_out', nonlinearity=activation)\n",
    "        nn.init.constant_(self.depthwise.bias, 0)\n",
    "        nn.init.kaiming_normal_(self.pointwise.weight, mode='fan_out', nonlinearity=activation)\n",
    "        nn.init.constant_(self.pointwise.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return self.act(self.norm(x))\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation):\n",
    "        super().__init__()\n",
    "        dilations = [1, 2, 3, 4]\n",
    "        kernels   = [1, 3, 5, 7]\n",
    "        self.branches = nn.ModuleList()\n",
    "        for d, k in zip(dilations, kernels):\n",
    "            pad = (k // 2) * d\n",
    "            self.branches.append(\n",
    "                SepConv(in_ch, out_ch, activation, kernel_size=k, padding=pad, dilation=d)\n",
    "            )\n",
    "        self.merge = nn.Sequential(\n",
    "            nn.Conv2d(len(dilations) * out_ch, out_ch, kernel_size=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation_parser(activation)\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.merge[0].weight, mode='fan_out', nonlinearity=activation)\n",
    "        nn.init.constant_(self.merge[0].bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = [branch(x) for branch in self.branches]\n",
    "        x = torch.cat(outs, dim=1)\n",
    "        return self.merge(x)\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation_parser(activation),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation_parser(activation)\n",
    "        )\n",
    "        for m in self.block.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity=activation)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        # W_g projects gating signal\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # W_x projects skip connection\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # psi computes 1‐channel attention map\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, F_g, kernel_size=1, bias=True),\n",
    "            nn.BatchNorm2d(F_g),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.W_g[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.constant_(self.W_g[0].bias, 0)\n",
    "        nn.init.kaiming_normal_(self.W_x[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.constant_(self.W_x[0].bias, 0)\n",
    "        nn.init.kaiming_normal_(self.psi[0].weight, mode='fan_out', nonlinearity='sigmoid')\n",
    "        nn.init.constant_(self.psi[0].bias, 0)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        \"\"\"\n",
    "        g: gating signal from decoder, shape (B, F_g, H, W)\n",
    "        x: skip connection from encoder, shape (B, F_l, H, W)\n",
    "        \"\"\"\n",
    "        g1 = self.W_g(g)   # (B, F_int, H, W)\n",
    "        x1 = self.W_x(x)   # (B, F_int, H, W)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)   # (B, 1, H, W)\n",
    "        return x * psi        # broadcast along channel\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation, dropout_prob=0.0, attention=True, pool=True, ASPP_blocks=True):\n",
    "        super().__init__()\n",
    "        if ASPP_blocks:\n",
    "            # Use ASPP instead of DoubleConv\n",
    "            self.conv = ASPP(in_ch, out_ch, activation)\n",
    "        else:\n",
    "            # Use DoubleConv if ASPP_blocks is False\n",
    "            self.conv = DoubleConv(in_ch, out_ch, activation)\n",
    "        self.cbam        = CBAMBlock(out_ch, ratio=8, kernel_size=7) if attention else nn.Identity()\n",
    "        self.dropout     = nn.Dropout2d(dropout_prob) if dropout_prob > 0 else nn.Identity()\n",
    "        self.pool        = pool\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.cbam(x)\n",
    "        x = self.dropout(x)\n",
    "        skip = x.clone()\n",
    "        if self.pool:\n",
    "            x = F.max_pool2d(x, kernel_size=2)\n",
    "        return x, skip\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, skip_ch, out_ch, activation, dropout_prob=0.0, attention=True, upsample=True, ASPP_blocks=True):\n",
    "        \"\"\"\n",
    "        in_ch:   channels from previous layer (bottleneck or previous decoder)\n",
    "        skip_ch: channels in the corresponding encoder skip\n",
    "        out_ch:  desired output channels for this decoder block\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        self.skip_ch = skip_ch\n",
    "\n",
    "        if self.upsample:\n",
    "            # ConvTranspose2d(in_ch → skip_ch) to match spatial & channel dims\n",
    "            self.up = nn.ConvTranspose2d(in_ch, skip_ch, kernel_size=3,\n",
    "                                         stride=2, padding=1, output_padding=1, bias=True)\n",
    "            nn.init.kaiming_normal_(self.up.weight, mode='fan_out', nonlinearity='relu')\n",
    "            self.bn_up = nn.BatchNorm2d(skip_ch)\n",
    "            self.act_up = activation_parser(activation)\n",
    "            self.attention = AttentionGate(F_g=skip_ch, F_l=skip_ch, F_int=skip_ch // 2) if attention else nn.Identity()\n",
    "        else:\n",
    "            self.up = None\n",
    "            self.bn_up = None\n",
    "            self.act_up = None\n",
    "            self.attention = AttentionGate(F_g=in_ch, F_l=in_ch, F_int=in_ch // 2) if attention else nn.Identity()\n",
    "\n",
    "        #self.double_conv = DoubleConv(in_double, out_ch, activation)\n",
    "        if ASPP_blocks:\n",
    "            # Use ASPP instead of DoubleConv\n",
    "            self.conv = ASPP(in_ch, out_ch, activation)\n",
    "        else:\n",
    "            # Use DoubleConv if ASPP_blocks is False\n",
    "            self.conv = DoubleConv(in_ch, out_ch, activation)\n",
    "        self.cbam        = CBAMBlock(out_ch, ratio=8, kernel_size=7) if attention else nn.Identity()\n",
    "        self.dropout     = nn.Dropout2d(dropout_prob) if dropout_prob > 0 else nn.Identity()\n",
    "\n",
    "    def forward(self, x, skip=None):\n",
    "        if self.upsample:\n",
    "            x = self.up(x)       # (B, skip_ch, H*2, W*2)\n",
    "            x = self.bn_up(x)\n",
    "            x = self.act_up(x)\n",
    "        if skip is not None:\n",
    "            skip = self.attention(g=x, x=skip)\n",
    "            x = torch.cat([x, skip], dim=1)  # (B, 2*skip_ch, H*2, W*2)\n",
    "        x = self.conv(x)\n",
    "        x = self.cbam(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleneckTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes a tensor of shape (B, C, H, W), flattens the H×W patches into tokens,\n",
    "    runs a small TransformerEncoder over them, then reshapes back to (B, C, H, W).\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, heads=8, depth=3, mlp_dim=None):\n",
    "        super().__init__()\n",
    "        mlp_dim = mlp_dim or dim * 4\n",
    "        # one TransformerEncoderLayer (or more, if depth>1)\n",
    "        layer_e = nn.TransformerEncoderLayer(\n",
    "            d_model=dim,\n",
    "            nhead=heads,\n",
    "            dim_feedforward=mlp_dim,\n",
    "            activation='relu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        layer_d = nn.TransformerDecoderLayer(\n",
    "            d_model=dim,\n",
    "            nhead=heads,\n",
    "            dim_feedforward=mlp_dim,\n",
    "            activation='relu',\n",
    "            norm_first=True,  # important for TransformerDecoder\n",
    "            #batch_first=True\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(layer_e, num_layers=depth//2 if depth > 1 else depth)\n",
    "        self.norm    = nn.LayerNorm(dim)\n",
    "        if depth > 1:\n",
    "            self.decoder = nn.TransformerDecoder(layer_d, num_layers=depth - depth//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W)\n",
    "        B, C, H, W = x.shape\n",
    "        # flatten spatial dims:\n",
    "        # → (B, C, H*W) then permute to (H*W, B, C) for PyTorch’s MHSA\n",
    "        tokens = x.flatten(2).permute(2, 0, 1)   # (H*W, B, C)\n",
    "        # run through TransformerEncoder\n",
    "        out   = self.encoder(tokens)             # (H*W, B, C)\n",
    "        # run through TransformerDecoder (optional, if depth > 1)\n",
    "        if hasattr(self, 'decoder'):\n",
    "            out = self.decoder(out, out)          # (H*W, B, C)\n",
    "        # put back into (B, C, H, W) after a LayerNorm on each token\n",
    "        out   = out.permute(1, 2, 0).view(B, C, H, W)\n",
    "        return self.norm(out.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
    "        # explanation of the two permutes:\n",
    "        #  - out.permute(1,2,0)→(B, C, H*W) then .view(B, C, H, W)\n",
    "        #  - we want LN over the C‐dimension, so we permute to (B, H, W, C), apply LayerNorm,\n",
    "        #    then back to (B, C, H, W).\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=1,\n",
    "                 out_channels=1,\n",
    "                 down_filters=None,\n",
    "                 down_activations=None,\n",
    "                 up_filters=None,\n",
    "                 up_activations=None,\n",
    "                 bottleneck_transformer=True,\n",
    "                 ASPP_blocks=True):\n",
    "        super().__init__()\n",
    "        assert len(down_filters) == len(down_activations)\n",
    "        assert len(up_filters)   == len(up_activations)\n",
    "\n",
    "        # Build Encoder path\n",
    "        self.input_norm = nn.BatchNorm2d(in_channels)\n",
    "        self.encoders = nn.ModuleList()\n",
    "        self.bottleneck_transformer = bottleneck_transformer\n",
    "        prev_ch = in_channels\n",
    "        for i, out_ch in enumerate(down_filters):\n",
    "            act_str = down_activations[i].lower()\n",
    "            self.encoders.append(\n",
    "                EncoderBlock(in_ch=prev_ch,\n",
    "                             out_ch=out_ch,\n",
    "                             activation=act_str,\n",
    "                             dropout_prob=0.0,\n",
    "                             attention=(i != 0),\n",
    "                             pool=True,\n",
    "                             ASPP_blocks=ASPP_blocks)\n",
    "            )\n",
    "            prev_ch = out_ch\n",
    "\n",
    "        # Bottleneck:\n",
    "        if bottleneck_transformer:\n",
    "            self.bottleneck  = BottleneckTransformer(dim=down_filters[-1],\n",
    "                                                           heads=4,\n",
    "                                                           depth=4)\n",
    "        else:\n",
    "            self.bottleneck = nn.Identity()\n",
    "\n",
    "        # Build Decoder path\n",
    "        self.decoders = nn.ModuleList()\n",
    "        N = len(down_filters)\n",
    "        for i in range(len(up_filters)):\n",
    "            act_str = up_activations[i].lower()\n",
    "            # Corresponding skip channels from encoder\n",
    "            skip_ch = down_filters[N - 1 - i]\n",
    "            # Input channels for this decoder block\n",
    "            out_ch = up_filters[i]\n",
    "            in_ch_dec = (down_filters[-1] * 1) if (i == 0) else up_filters[i - 1]\n",
    "\n",
    "            self.decoders.append(\n",
    "                DecoderBlock(in_ch=in_ch_dec,\n",
    "                             skip_ch=skip_ch,\n",
    "                             out_ch=out_ch,\n",
    "                             activation=act_str,\n",
    "                             dropout_prob=0.0,\n",
    "                             attention= True,\n",
    "                             upsample=True,\n",
    "                             ASPP_blocks=ASPP_blocks)\n",
    "            )\n",
    "\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv2d(up_filters[-1], out_channels, kernel_size=5, padding=2, bias=True),\n",
    "            nn.Sigmoid())\n",
    "        nn.init.kaiming_normal_(self.final_conv[0].weight, mode='fan_out', nonlinearity='sigmoid')\n",
    "        nn.init.constant_(self.final_conv[0].bias, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_norm(x)  # Normalize input\n",
    "        # x: (B, 1, 128, 128)\n",
    "        skips = []\n",
    "        for enc in self.encoders[:-1]:  # skip last encoder (bottleneck)\n",
    "            x, skip = enc(x)\n",
    "            skips.append(skip)\n",
    "\n",
    "        # Bottleneck:\n",
    "        x, _ = self.encoders[-1](x) # last encoder does not return a skip\n",
    "        skips.append(None)\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        x = self.decoders[0](x, skips[-1])  # first decoder uses the last encoder skip\n",
    "\n",
    "        skips = skips[::-1]              # reverse order for decoding\n",
    "\n",
    "        for i in range(1, len(self.decoders)):\n",
    "            skip_feat = skips[i]\n",
    "            x = self.decoders[i](x, skip_feat)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ],
   "id": "6b0ee8133ceb7c68",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T20:09:26.125852Z",
     "start_time": "2025-06-11T20:09:26.123153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        \"\"\"\n",
    "        preds:   Tensor (B,1,H,W) after Sigmoid\n",
    "        targets: Tensor (B,1,H,W) binary {0,1}\n",
    "        \"\"\"\n",
    "        p_flat = preds.view(-1)\n",
    "        t_flat = targets.view(-1)\n",
    "        intersection = (p_flat * t_flat).sum()\n",
    "        dice_coeff = (2. * intersection + self.smooth) / (p_flat.sum() + t_flat.sum() + self.smooth)\n",
    "        return 1 - dice_coeff\n",
    "\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.9, gamma=2.0, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha, self.gamma, self.eps = alpha, gamma, eps\n",
    "        self.beta = 1 - alpha  # Ensure alpha + beta = 1\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        preds = preds.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        TP = (preds * targets).sum()\n",
    "        FP = (preds * (1 - targets)).sum()\n",
    "        FN = ((1 - preds) * targets).sum()\n",
    "        tversky = (TP + self.eps) / (TP + self.alpha*FN + self.beta*FP + self.eps)\n",
    "        return torch.pow((1 - tversky), self.gamma)\n",
    "\n",
    "class ComboLossTF(nn.Module):\n",
    "    def __init__(self, bce_weight=0.33, dice_weight=0.33, focal_twersky_weight=0.33):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.dice = DiceLoss(smooth=1e-6)\n",
    "        self.FW = FocalTverskyLoss (alpha = 0.95, gamma=3.1)\n",
    "        self.bw, self.dw, self.fw = bce_weight, dice_weight, focal_twersky_weight\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        # preds, targets both (B,1,H,W)\n",
    "        total_loss = 0\n",
    "        if self.bw > 0:\n",
    "            l_bce = self.bce(preds, targets)\n",
    "            total_loss += self.bw * l_bce\n",
    "        if self.dw > 0:\n",
    "            l_dice = self.dice(preds, targets)\n",
    "            total_loss += self.dw * l_dice\n",
    "        if self.fw > 0:\n",
    "            l_focal_tversky = self.FW(preds, targets)\n",
    "            total_loss += self.fw * l_focal_tversky\n",
    "        return total_loss"
   ],
   "id": "4668bc53416e595c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T20:09:26.169243Z",
     "start_time": "2025-06-11T20:09:26.166361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigzi(x, axis=None):\n",
    "    \"\"\"\n",
    "Compute the interquartile range (IQR) of x along the specified axis.\n",
    "    Args:\n",
    "        x: array-like, shape (P, H, W) or (H, W) or (N, C, H, W)\n",
    "        axis: axis along which to compute the IQR.\n",
    "              If None, computes over the flattened array.\n",
    "\n",
    "    Returns: float, the IQR of x.\n",
    "\n",
    "    \"\"\"\n",
    "    return 0.741 * (np.percentile(x, 75, axis=axis) - np.percentile(x, 25, axis=axis))\n",
    "\n",
    "def split_stack(arr, nrows, ncols):\n",
    "    \"\"\"\n",
    "    Split a stack of 2D panels into (nrows × ncols) tiles.\n",
    "    arr: ndarray, shape (P, H, W)\n",
    "    Returns: ndarray, shape (P * (H//nrows)*(W//ncols), nrows, ncols)\n",
    "    \"\"\"\n",
    "    P, H, W = arr.shape\n",
    "    pad_h = (-H) % nrows\n",
    "    pad_w = (-W) % ncols\n",
    "    if pad_h or pad_w:\n",
    "        arr = np.pad(arr,\n",
    "                     ((0, 0),\n",
    "                      (0, pad_h),\n",
    "                      (0, pad_w)),\n",
    "                     mode='constant',\n",
    "                     constant_values=0)\n",
    "    H2, W2 = arr.shape[1], arr.shape[2]\n",
    "    blocks = (arr\n",
    "              .reshape(P,\n",
    "                       H2 // nrows, nrows,\n",
    "                       W2 // ncols, ncols)\n",
    "              .swapaxes(2, 3))\n",
    "    P2, Hb, Wb, nr, nc = blocks.shape\n",
    "    out = blocks.reshape(P2 * Hb * Wb, nr, nc)\n",
    "    return out\n",
    "\n",
    "def build_datasets(npz_file, tile_size=128):\n",
    "    \"\"\"\n",
    "    Load data from .npz, clip exactly as TF did, split into tiles, return PyTorch tensors.\n",
    "      - Clips x to [-166.43, 169.96]\n",
    "      - Splits each large image into (tile_size × tile_size) patches\n",
    "      - Adds a channel dimension (→ shape (N, 1, tile_size, tile_size))\n",
    "    \"\"\"\n",
    "    data = np.load(npz_file)\n",
    "    x = data['x']  # shape (P, H, W)\n",
    "    y = data['y']\n",
    "\n",
    "    x = x/sigzi(x)  # normalize by interquartile range\n",
    "    x = np.clip(x, -7, 7) # clip to [-5, 5]\n",
    "\n",
    "    # Split into tiles (tile_size × tile_size)\n",
    "    x_tiles = split_stack(x, tile_size, tile_size)  # (N_tiles, tile_size, tile_size)\n",
    "    y_tiles = split_stack(y, tile_size, tile_size)\n",
    "\n",
    "    # Convert to FloatTensor and add channel dimension\n",
    "    x_tiles = torch.from_numpy(x_tiles).float().unsqueeze(1)  # (N, 1, tile_size, tile_size)\n",
    "    y_tiles = torch.from_numpy(y_tiles).float().unsqueeze(1)  # (N, 1, tile_size, tile_size)\n",
    "\n",
    "    return x_tiles, y_tiles\n",
    "\n",
    "def reshape_masks(masks, new_size):\n",
    "    \"\"\"\n",
    "    Resize binary masks (0/1) to `new_size`:\n",
    "      - Uses bilinear interpolation (same as TF’s tf.image.resize with bilinear)\n",
    "      - Applies torch.ceil(...) to recover {0,1} values exactly.\n",
    "    Input:\n",
    "      - masks: either a Tensor of shape (N, 1, H_orig, W_orig)\n",
    "               or a numpy array of shape (N, H_orig, W_orig)\n",
    "      - new_size: tuple (new_H, new_W)\n",
    "    Returns:\n",
    "      - Tensor of shape (N, 1, new_H, new_W), values in {0,1}\n",
    "    \"\"\"\n",
    "    if isinstance(masks, np.ndarray):\n",
    "        m = torch.from_numpy(masks).float().unsqueeze(1)  # → (N,1,H,W)\n",
    "    else:\n",
    "        m = masks  # assume already FloatTensor (N,1,H,W)\n",
    "    m_resized = F.interpolate(m, size=new_size, mode='bilinear', align_corners=False)\n",
    "    m_resized = torch.ceil(m_resized)\n",
    "    return m_resized.clamp(0, 1)\n",
    "\n",
    "def split_train_val(x_tiles, y_tiles, train_frac=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Shuffle and split x_tiles, y_tiles into two TensorDatasets: train (80%) and val (20%).\n",
    "    \"\"\"\n",
    "    n = x_tiles.shape[0]\n",
    "    idx = torch.randperm(n, generator=torch.Generator().manual_seed(seed))\n",
    "    split = int(train_frac * n)\n",
    "    train_idx = idx[:split]\n",
    "    val_idx   = idx[split:]\n",
    "    train_idx, val_idx = train_idx.sort().values, val_idx.sort().values\n",
    "    x_tr, y_tr = x_tiles[train_idx], y_tiles[train_idx]\n",
    "    x_val, y_val = x_tiles[val_idx], y_tiles[val_idx]\n",
    "    return TensorDataset(x_tr, y_tr), TensorDataset(x_val, y_val)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T20:09:26.213278Z",
     "start_time": "2025-06-11T20:09:26.209265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_ds, val_ds, epochs=100, batch_size=32, lr=1e-3, device=None):\n",
    "    \"\"\"\n",
    "    Train the model on train_ds, validate on val_ds, and print losses + F1 each epoch.\n",
    "    Resizes all masks to `output_size` so that preds and targets match in spatial dims.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 1) Figure out the model’s output spatial size by pushing a dummy 128×128 patch.\n",
    "    model.eval()  # ensure BatchNorm uses running‐stats, not “batch” stats\n",
    "    with torch.no_grad():\n",
    "        dummy = torch.randn(1, 1, 128, 128).to(device)\n",
    "        out_dummy = model(dummy)\n",
    "        output_size = (out_dummy.shape[-2], out_dummy.shape[-1])  # e.g. (32,32) for your JSON\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=4, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=4, pin_memory=True)\n",
    "\n",
    "    criterion = ComboLossTF(bce_weight=0.0, dice_weight=0.0, focal_twersky_weight=1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                max_lr=lr,\n",
    "                                                steps_per_epoch=len(train_loader),\n",
    "                                                epochs=epochs,\n",
    "                                                pct_start=0.1,\n",
    "                                                anneal_strategy='cos')\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ——— Training ———\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        tp = fp = fn = 0\n",
    "        for batch_num, (imgs, masks) in enumerate(train_loader):\n",
    "            imgs = imgs.to(device)  # (B,1,128,128)\n",
    "\n",
    "            # Resize the ground‐truth masks to output_size (e.g. (32,32))\n",
    "            m_resized = reshape_masks(masks, new_size=output_size).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(imgs)              # (B,1, output_H, output_W)\n",
    "            loss = criterion(preds, m_resized)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            sched.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_bin = (preds > 0.5).float()\n",
    "                t = m_resized\n",
    "                tp += (pred_bin * t).sum().item()\n",
    "                fp += (pred_bin * (1 - t)).sum().item()\n",
    "                fn += ((1 - pred_bin) * t).sum().item()\n",
    "\n",
    "            prec = tp / (tp + fp + 1e-8)\n",
    "            rec  = tp / (tp + fn + 1e-8)\n",
    "            f1   = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "            print (f\"\\rEpoch {epoch:03d}  \"\n",
    "                   f\"Batch {batch_num+1:03d}/{len(train_loader)}  \"\n",
    "                   f\"Batch Loss: {loss.item():.4f}  \"\n",
    "                   f\"| train F1: {f1:.4f}  | train precision: {prec:.4f}  | train recall: {rec:.4f}\", end='\\r')\n",
    "\n",
    "        train_loss = running_loss / len(train_ds)\n",
    "        prec = tp / (tp + fp + 1e-8)\n",
    "        rec  = tp / (tp + fn + 1e-8)\n",
    "        f1   = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "\n",
    "        # ——— Validation ———\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        tp = fp = fn = 0\n",
    "        val_y = []\n",
    "        pred_val = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                m_resized = reshape_masks(masks, new_size=output_size).to(device)\n",
    "                preds = model(imgs)\n",
    "                loss = criterion(preds, m_resized)\n",
    "                val_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "                pred_bin = (preds > 0.5).float()\n",
    "                tp += (pred_bin * m_resized).sum().item()\n",
    "                fp += (pred_bin * (1 - m_resized)).sum().item()\n",
    "                fn += ((1 - pred_bin) * m_resized).sum().item()\n",
    "                val_y.append(m_resized.cpu().numpy())\n",
    "                pred_val.append(preds.cpu().numpy())\n",
    "        # Collect all validation masks for AUC calculation\n",
    "        val_y = np.concatenate(val_y, axis=0)\n",
    "        preds_val = np.concatenate(pred_val, axis=0)  # (N, 1, Hout, Wout)\n",
    "        val_loss = val_loss / len(val_ds)\n",
    "        prec = tp / (tp + fp + 1e-8)\n",
    "        rec  = tp / (tp + fn + 1e-8)\n",
    "        f1_val = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "        auc_val = sklearn.metrics.roc_auc_score(val_y.flatten(), preds_val.flatten() )\n",
    "\n",
    "        print(f\"Epoch {epoch:03d}  \"\n",
    "              f\"Train Loss: {train_loss:.4f}  \"\n",
    "              f\"| Val Loss: {val_loss:.4f}  \"\n",
    "              f\"| Train F1: {f1:.4f}  \"\n",
    "              f\"| Val F1: {f1_val:.4f}  \"\n",
    "              f\"| Val Prec: {prec:.4f}  \"\n",
    "              f\"| Val Rec: {rec:.4f}\"\n",
    "              f\"| Val AUC: {auc_val:.4f}\")\n",
    "\n",
    "    return model"
   ],
   "id": "b42c2e411098d4b5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T20:10:43.162383Z",
     "start_time": "2025-06-11T20:09:27.278878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "npz_file = \"../DATA/train.npz\"\n",
    "x_tiles, y_tiles = build_datasets(npz_file, tile_size=128)\n",
    "train_ds, val_ds = split_train_val(x_tiles, y_tiles, train_frac=0.8, seed=42)\n",
    "del x_tiles, y_tiles"
   ],
   "id": "cdca56a2e5d4e6d2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T22:03:14.781864Z",
     "start_time": "2025-06-11T20:10:43.294798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#down_filters     = [32, 64, 128, 256, 512]\n",
    "down_filters =  [32, 32, 32, 64, 128, 256, 512]\n",
    "down_activations = ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu']\n",
    "\n",
    "up_filters       = [512, 256, 128, 64, 32]\n",
    "up_activations   = ['relu', 'relu', 'relu', 'relu', 'relu']\n",
    "\n",
    "model = UNet(\n",
    "        down_filters=down_filters,\n",
    "        down_activations=down_activations,\n",
    "        up_filters=up_filters,\n",
    "        up_activations=up_activations,\n",
    "        bottleneck_transformer=False,\n",
    "        ASPP_blocks=False)\n",
    "\n",
    "\n",
    "trained_model = train_model(model,\n",
    "                            train_ds, val_ds,\n",
    "                            epochs=150,\n",
    "                            batch_size=128,\n",
    "                            lr=0.0015)"
   ],
   "id": "dbe140c0ff8133fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001  Train Loss: 0.8211  | Val Loss: 0.8007  | Train F1: 0.0070  | Val F1: 0.0080  | Val Prec: 0.0040  | Val Rec: 0.8195| Val AUC: 0.5747\n",
      "Epoch 002  Train Loss: 0.7492  | Val Loss: 0.6448  | Train F1: 0.0107  | Val F1: 0.0228  | Val Prec: 0.0117  | Val Rec: 0.4181| Val AUC: 0.6985\n",
      "Epoch 003  Train Loss: 0.6206  | Val Loss: 0.6405  | Train F1: 0.0258  | Val F1: 0.0232  | Val Prec: 0.0119  | Val Rec: 0.4325| Val AUC: 0.6758\n",
      "Epoch 004  Train Loss: 0.6019  | Val Loss: 0.6227  | Train F1: 0.0303  | Val F1: 0.0248  | Val Prec: 0.0128  | Val Rec: 0.3940| Val AUC: 0.6824\n",
      "Epoch 005  Train Loss: 0.5942  | Val Loss: 0.5900  | Train F1: 0.0305  | Val F1: 0.0334  | Val Prec: 0.0175  | Val Rec: 0.3848| Val AUC: 0.6814\n",
      "Epoch 006  Train Loss: 0.5884  | Val Loss: 0.6022  | Train F1: 0.0313  | Val F1: 0.0282  | Val Prec: 0.0146  | Val Rec: 0.4066| Val AUC: 0.6853\n",
      "Epoch 007  Train Loss: 0.5830  | Val Loss: 0.5798  | Train F1: 0.0328  | Val F1: 0.0314  | Val Prec: 0.0163  | Val Rec: 0.4213| Val AUC: 0.6893\n",
      "Epoch 008  Train Loss: 0.5689  | Val Loss: 0.5819  | Train F1: 0.0347  | Val F1: 0.0364  | Val Prec: 0.0191  | Val Rec: 0.3688| Val AUC: 0.6884\n",
      "Epoch 009  Train Loss: 0.5749  | Val Loss: 0.5493  | Train F1: 0.0339  | Val F1: 0.0419  | Val Prec: 0.0221  | Val Rec: 0.3964| Val AUC: 0.6821\n",
      "Epoch 010  Train Loss: 0.5680  | Val Loss: 0.5619  | Train F1: 0.0341  | Val F1: 0.0387  | Val Prec: 0.0203  | Val Rec: 0.3972| Val AUC: 0.6980\n",
      "Epoch 011  Train Loss: 0.5597  | Val Loss: 0.5846  | Train F1: 0.0369  | Val F1: 0.0428  | Val Prec: 0.0229  | Val Rec: 0.3251| Val AUC: 0.6500\n",
      "Epoch 012  Train Loss: 0.5695  | Val Loss: 0.5493  | Train F1: 0.0392  | Val F1: 0.0629  | Val Prec: 0.0347  | Val Rec: 0.3328| Val AUC: 0.6648\n",
      "Epoch 013  Train Loss: 0.5490  | Val Loss: 0.5821  | Train F1: 0.0407  | Val F1: 0.0305  | Val Prec: 0.0158  | Val Rec: 0.4184| Val AUC: 0.6811\n",
      "Epoch 014  Train Loss: 0.5546  | Val Loss: 0.5336  | Train F1: 0.0403  | Val F1: 0.0604  | Val Prec: 0.0330  | Val Rec: 0.3623| Val AUC: 0.6657\n",
      "Epoch 015  Train Loss: 0.5461  | Val Loss: 0.6511  | Train F1: 0.0455  | Val F1: 0.0464  | Val Prec: 0.0259  | Val Rec: 0.2258| Val AUC: 0.6160\n",
      "Epoch 016  Train Loss: 0.5308  | Val Loss: 0.5667  | Train F1: 0.0452  | Val F1: 0.0503  | Val Prec: 0.0273  | Val Rec: 0.3245| Val AUC: 0.6749\n",
      "Epoch 017  Train Loss: 0.5319  | Val Loss: 0.5195  | Train F1: 0.0530  | Val F1: 0.0581  | Val Prec: 0.0314  | Val Rec: 0.3832| Val AUC: 0.6791\n",
      "Epoch 018  Train Loss: 0.5042  | Val Loss: 0.5168  | Train F1: 0.0546  | Val F1: 0.0839  | Val Prec: 0.0478  | Val Rec: 0.3428| Val AUC: 0.6936\n",
      "Epoch 019  Train Loss: 0.4671  | Val Loss: 0.4752  | Train F1: 0.0748  | Val F1: 0.0582  | Val Prec: 0.0311  | Val Rec: 0.4462| Val AUC: 0.7452\n",
      "Epoch 020  Train Loss: 0.4670  | Val Loss: 0.5112  | Train F1: 0.0758  | Val F1: 0.1322  | Val Prec: 0.0833  | Val Rec: 0.3203| Val AUC: 0.6927\n",
      "Epoch 021  Train Loss: 0.4280  | Val Loss: 0.5150  | Train F1: 0.0895  | Val F1: 0.0386  | Val Prec: 0.0201  | Val Rec: 0.4812| Val AUC: 0.7313\n",
      "Epoch 022  Train Loss: 0.4385  | Val Loss: 0.4739  | Train F1: 0.0866  | Val F1: 0.1180  | Val Prec: 0.0707  | Val Rec: 0.3580| Val AUC: 0.6930\n",
      "Epoch 023  Train Loss: 0.4290  | Val Loss: 0.5073  | Train F1: 0.0903  | Val F1: 0.0457  | Val Prec: 0.0241  | Val Rec: 0.4432| Val AUC: 0.7210\n",
      "Epoch 024  Train Loss: 0.4365  | Val Loss: 0.4488  | Train F1: 0.0832  | Val F1: 0.0793  | Val Prec: 0.0437  | Val Rec: 0.4319| Val AUC: 0.7344\n",
      "Epoch 025  Train Loss: 0.4211  | Val Loss: 0.5021  | Train F1: 0.0972  | Val F1: 0.0559  | Val Prec: 0.0301  | Val Rec: 0.3948| Val AUC: 0.7291\n",
      "Epoch 026  Train Loss: 0.4105  | Val Loss: 0.4714  | Train F1: 0.0964  | Val F1: 0.1557  | Val Prec: 0.0992  | Val Rec: 0.3627| Val AUC: 0.7171\n",
      "Epoch 027  Train Loss: 0.4184  | Val Loss: 0.4800  | Train F1: 0.1121  | Val F1: 0.0592  | Val Prec: 0.0317  | Val Rec: 0.4438| Val AUC: 0.7302\n",
      "Epoch 028  Train Loss: 0.4074  | Val Loss: 0.4919  | Train F1: 0.1034  | Val F1: 0.1626  | Val Prec: 0.1079  | Val Rec: 0.3300| Val AUC: 0.7107\n",
      "Epoch 029  Train Loss: 0.4237  | Val Loss: 0.4552  | Train F1: 0.1095  | Val F1: 0.1174  | Val Prec: 0.0696  | Val Rec: 0.3749| Val AUC: 0.7060\n",
      "Epoch 030  Train Loss: 0.4098  | Val Loss: 0.4580  | Train F1: 0.1099  | Val F1: 0.1217  | Val Prec: 0.0725  | Val Rec: 0.3791| Val AUC: 0.7072\n",
      "Epoch 031  Train Loss: 0.3886  | Val Loss: 0.4518  | Train F1: 0.1256  | Val F1: 0.1092  | Val Prec: 0.0634  | Val Rec: 0.3942| Val AUC: 0.7252\n",
      "Epoch 032  Train Loss: 0.4201  | Val Loss: 0.4840  | Train F1: 0.0892  | Val F1: 0.0629  | Val Prec: 0.0339  | Val Rec: 0.4236| Val AUC: 0.7101\n",
      "Epoch 033  Train Loss: 0.3959  | Val Loss: 0.4367  | Train F1: 0.1118  | Val F1: 0.1314  | Val Prec: 0.0788  | Val Rec: 0.3958| Val AUC: 0.6987\n",
      "Epoch 034  Train Loss: 0.3762  | Val Loss: 0.4227  | Train F1: 0.1222  | Val F1: 0.1230  | Val Prec: 0.0726  | Val Rec: 0.4021| Val AUC: 0.7218\n",
      "Epoch 035  Train Loss: 0.3731  | Val Loss: 0.4361  | Train F1: 0.1375  | Val F1: 0.1283  | Val Prec: 0.0766  | Val Rec: 0.3943| Val AUC: 0.7076\n",
      "Epoch 036  Train Loss: 0.3810  | Val Loss: 0.4335  | Train F1: 0.1314  | Val F1: 0.1385  | Val Prec: 0.0840  | Val Rec: 0.3960| Val AUC: 0.7140\n",
      "Epoch 037  Train Loss: 0.3816  | Val Loss: 0.4250  | Train F1: 0.1349  | Val F1: 0.1039  | Val Prec: 0.0593  | Val Rec: 0.4182| Val AUC: 0.7256\n",
      "Epoch 038  Train Loss: 0.3618  | Val Loss: 0.4385  | Train F1: 0.1134  | Val F1: 0.1594  | Val Prec: 0.1000  | Val Rec: 0.3928| Val AUC: 0.7102\n",
      "Epoch 039  Train Loss: 0.3448  | Val Loss: 0.4242  | Train F1: 0.1484  | Val F1: 0.1215  | Val Prec: 0.0712  | Val Rec: 0.4148| Val AUC: 0.7200\n",
      "Epoch 040  Train Loss: 0.3492  | Val Loss: 0.4231  | Train F1: 0.1371  | Val F1: 0.1130  | Val Prec: 0.0653  | Val Rec: 0.4204| Val AUC: 0.7162\n",
      "Epoch 041  Train Loss: 0.3478  | Val Loss: 0.4548  | Train F1: 0.1323  | Val F1: 0.1234  | Val Prec: 0.0738  | Val Rec: 0.3770| Val AUC: 0.7113\n",
      "Epoch 042  Train Loss: 0.3482  | Val Loss: 0.4550  | Train F1: 0.1334  | Val F1: 0.1971  | Val Prec: 0.1354  | Val Rec: 0.3617| Val AUC: 0.7011\n",
      "Epoch 043  Train Loss: 0.3392  | Val Loss: 0.4361  | Train F1: 0.1464  | Val F1: 0.1217  | Val Prec: 0.0714  | Val Rec: 0.4109| Val AUC: 0.7177\n",
      "Epoch 044  Train Loss: 0.3520  | Val Loss: 0.4296  | Train F1: 0.1476  | Val F1: 0.1138  | Val Prec: 0.0660  | Val Rec: 0.4115| Val AUC: 0.7246\n",
      "Epoch 045  Train Loss: 0.3336  | Val Loss: 0.4275  | Train F1: 0.1443  | Val F1: 0.1491  | Val Prec: 0.0919  | Val Rec: 0.3935| Val AUC: 0.7001\n",
      "Epoch 046  Train Loss: 0.3265  | Val Loss: 0.4282  | Train F1: 0.1599  | Val F1: 0.1304  | Val Prec: 0.0774  | Val Rec: 0.4122| Val AUC: 0.7273\n",
      "Epoch 047  Train Loss: 0.3213  | Val Loss: 0.4242  | Train F1: 0.1664  | Val F1: 0.1112  | Val Prec: 0.0637  | Val Rec: 0.4366| Val AUC: 0.7195\n",
      "Epoch 048  Train Loss: 0.3402  | Val Loss: 0.4346  | Train F1: 0.1388  | Val F1: 0.1125  | Val Prec: 0.0652  | Val Rec: 0.4115| Val AUC: 0.7121\n",
      "Epoch 049  Train Loss: 0.3445  | Val Loss: 0.4465  | Train F1: 0.1325  | Val F1: 0.1182  | Val Prec: 0.0693  | Val Rec: 0.4002| Val AUC: 0.7048\n",
      "Epoch 050  Train Loss: 0.3145  | Val Loss: 0.4301  | Train F1: 0.1561  | Val F1: 0.1159  | Val Prec: 0.0674  | Val Rec: 0.4150| Val AUC: 0.7179\n",
      "Epoch 051  Train Loss: 0.3189  | Val Loss: 0.4389  | Train F1: 0.1574  | Val F1: 0.1334  | Val Prec: 0.0805  | Val Rec: 0.3886| Val AUC: 0.7166\n",
      "Epoch 052  Train Loss: 0.3183  | Val Loss: 0.4236  | Train F1: 0.1839  | Val F1: 0.1526  | Val Prec: 0.0944  | Val Rec: 0.3991| Val AUC: 0.7245\n",
      "Epoch 053  Train Loss: 0.3205  | Val Loss: 0.4455  | Train F1: 0.1719  | Val F1: 0.1611  | Val Prec: 0.1023  | Val Rec: 0.3783| Val AUC: 0.6997\n",
      "Epoch 054  Train Loss: 0.3121  | Val Loss: 0.4303  | Train F1: 0.1630  | Val F1: 0.1412  | Val Prec: 0.0857  | Val Rec: 0.3998| Val AUC: 0.7143\n",
      "Epoch 055  Train Loss: 0.3046  | Val Loss: 0.4360  | Train F1: 0.1662  | Val F1: 0.1571  | Val Prec: 0.0989  | Val Rec: 0.3814| Val AUC: 0.7177\n",
      "Epoch 056  Train Loss: 0.3152  | Val Loss: 0.4269  | Train F1: 0.1636  | Val F1: 0.1342  | Val Prec: 0.0805  | Val Rec: 0.4051| Val AUC: 0.7079\n",
      "Epoch 057  Train Loss: 0.3024  | Val Loss: 0.4432  | Train F1: 0.1989  | Val F1: 0.1829  | Val Prec: 0.1216  | Val Rec: 0.3692| Val AUC: 0.7082\n",
      "Epoch 058  Train Loss: 0.3060  | Val Loss: 0.4484  | Train F1: 0.1914  | Val F1: 0.1530  | Val Prec: 0.0962  | Val Rec: 0.3744| Val AUC: 0.6843\n",
      "Epoch 059  Train Loss: 0.2899  | Val Loss: 0.4276  | Train F1: 0.2028  | Val F1: 0.1984  | Val Prec: 0.1334  | Val Rec: 0.3873| Val AUC: 0.7024\n",
      "Epoch 060  Train Loss: 0.2960  | Val Loss: 0.4437  | Train F1: 0.2121  | Val F1: 0.1808  | Val Prec: 0.1189  | Val Rec: 0.3776| Val AUC: 0.6846\n",
      "Epoch 061  Train Loss: 0.2939  | Val Loss: 0.4421  | Train F1: 0.1955  | Val F1: 0.1654  | Val Prec: 0.1055  | Val Rec: 0.3832| Val AUC: 0.6998\n",
      "Epoch 062  Train Loss: 0.2946  | Val Loss: 0.4465  | Train F1: 0.1978  | Val F1: 0.1287  | Val Prec: 0.0769  | Val Rec: 0.3929| Val AUC: 0.7095\n",
      "Epoch 063  Train Loss: 0.2796  | Val Loss: 0.4406  | Train F1: 0.2003  | Val F1: 0.1718  | Val Prec: 0.1108  | Val Rec: 0.3816| Val AUC: 0.7095\n",
      "Epoch 064  Train Loss: 0.2944  | Val Loss: 0.4264  | Train F1: 0.2069  | Val F1: 0.1741  | Val Prec: 0.1119  | Val Rec: 0.3918| Val AUC: 0.7120\n",
      "Epoch 065  Train Loss: 0.3127  | Val Loss: 0.4365  | Train F1: 0.1783  | Val F1: 0.1756  | Val Prec: 0.1146  | Val Rec: 0.3748| Val AUC: 0.6892\n",
      "Epoch 066  Train Loss: 0.2897  | Val Loss: 0.4242  | Train F1: 0.1927  | Val F1: 0.2145  | Val Prec: 0.1496  | Val Rec: 0.3789| Val AUC: 0.6924\n",
      "Epoch 067  Train Loss: 0.2758  | Val Loss: 0.4395  | Train F1: 0.2364  | Val F1: 0.1774  | Val Prec: 0.1158  | Val Rec: 0.3791| Val AUC: 0.6935\n",
      "Epoch 068  Train Loss: 0.2620  | Val Loss: 0.4299  | Train F1: 0.2511  | Val F1: 0.1691  | Val Prec: 0.1079  | Val Rec: 0.3897| Val AUC: 0.7017\n",
      "Epoch 069  Train Loss: 0.2739  | Val Loss: 0.4343  | Train F1: 0.2440  | Val F1: 0.1949  | Val Prec: 0.1315  | Val Rec: 0.3764| Val AUC: 0.7111\n",
      "Epoch 070  Train Loss: 0.2798  | Val Loss: 0.4321  | Train F1: 0.2136  | Val F1: 0.1390  | Val Prec: 0.0841  | Val Rec: 0.4008| Val AUC: 0.7115\n",
      "Epoch 071  Train Loss: 0.2588  | Val Loss: 0.4519  | Train F1: 0.2548  | Val F1: 0.2580  | Val Prec: 0.2057  | Val Rec: 0.3459| Val AUC: 0.6904\n",
      "Epoch 072  Train Loss: 0.2573  | Val Loss: 0.4476  | Train F1: 0.2640  | Val F1: 0.1690  | Val Prec: 0.1096  | Val Rec: 0.3694| Val AUC: 0.7024\n",
      "Epoch 073  Train Loss: 0.2655  | Val Loss: 0.4415  | Train F1: 0.2335  | Val F1: 0.1498  | Val Prec: 0.0925  | Val Rec: 0.3931| Val AUC: 0.7019\n",
      "Epoch 074  Train Loss: 0.2684  | Val Loss: 0.4284  | Train F1: 0.2434  | Val F1: 0.1544  | Val Prec: 0.0960  | Val Rec: 0.3942| Val AUC: 0.7149\n",
      "Epoch 075  Train Loss: 0.2370  | Val Loss: 0.4520  | Train F1: 0.2539  | Val F1: 0.2005  | Val Prec: 0.1382  | Val Rec: 0.3653| Val AUC: 0.6992\n",
      "Epoch 076  Train Loss: 0.2561  | Val Loss: 0.4350  | Train F1: 0.2588  | Val F1: 0.1739  | Val Prec: 0.1122  | Val Rec: 0.3860| Val AUC: 0.7053\n",
      "Epoch 077  Train Loss: 0.2412  | Val Loss: 0.4618  | Train F1: 0.2837  | Val F1: 0.2343  | Val Prec: 0.1780  | Val Rec: 0.3426| Val AUC: 0.6913\n",
      "Epoch 078  Train Loss: 0.2546  | Val Loss: 0.4363  | Train F1: 0.2577  | Val F1: 0.2228  | Val Prec: 0.1594  | Val Rec: 0.3702| Val AUC: 0.7107\n",
      "Epoch 079  Train Loss: 0.2491  | Val Loss: 0.4675  | Train F1: 0.2797  | Val F1: 0.1760  | Val Prec: 0.1168  | Val Rec: 0.3566| Val AUC: 0.7002\n",
      "Epoch 080  Train Loss: 0.2649  | Val Loss: 0.4483  | Train F1: 0.2248  | Val F1: 0.2229  | Val Prec: 0.1617  | Val Rec: 0.3586| Val AUC: 0.7024\n",
      "Epoch 081  Train Loss: 0.2532  | Val Loss: 0.4463  | Train F1: 0.2754  | Val F1: 0.1875  | Val Prec: 0.1252  | Val Rec: 0.3733| Val AUC: 0.7038\n",
      "Epoch 082  Train Loss: 0.2437  | Val Loss: 0.4481  | Train F1: 0.2806  | Val F1: 0.1357  | Val Prec: 0.0824  | Val Rec: 0.3829| Val AUC: 0.7023\n",
      "Epoch 083  Train Loss: 0.2486  | Val Loss: 0.4605  | Train F1: 0.2386  | Val F1: 0.1901  | Val Prec: 0.1301  | Val Rec: 0.3531| Val AUC: 0.6984\n",
      "Epoch 084  Train Loss: 0.2398  | Val Loss: 0.4194  | Train F1: 0.2899  | Val F1: 0.1927  | Val Prec: 0.1290  | Val Rec: 0.3809| Val AUC: 0.6940\n",
      "Epoch 085  Train Loss: 0.2339  | Val Loss: 0.4516  | Train F1: 0.2924  | Val F1: 0.1349  | Val Prec: 0.0824  | Val Rec: 0.3710| Val AUC: 0.6920\n",
      "Epoch 086  Train Loss: 0.2445  | Val Loss: 0.4499  | Train F1: 0.2591  | Val F1: 0.2152  | Val Prec: 0.1549  | Val Rec: 0.3527| Val AUC: 0.6853\n",
      "Epoch 087  Train Loss: 0.2349  | Val Loss: 0.4687  | Train F1: 0.3201  | Val F1: 0.2344  | Val Prec: 0.1781  | Val Rec: 0.3425| Val AUC: 0.6734\n",
      "Epoch 088  Train Loss: 0.2306  | Val Loss: 0.4243  | Train F1: 0.3041  | Val F1: 0.1572  | Val Prec: 0.0986  | Val Rec: 0.3872| Val AUC: 0.6960\n",
      "Epoch 089  Train Loss: 0.2346  | Val Loss: 0.4590  | Train F1: 0.2922  | Val F1: 0.2595  | Val Prec: 0.2070  | Val Rec: 0.3475| Val AUC: 0.6901\n",
      "Epoch 090  Train Loss: 0.2264  | Val Loss: 0.4640  | Train F1: 0.3192  | Val F1: 0.2317  | Val Prec: 0.1746  | Val Rec: 0.3440| Val AUC: 0.6772\n",
      "Epoch 091  Train Loss: 0.2283  | Val Loss: 0.4466  | Train F1: 0.3489  | Val F1: 0.1993  | Val Prec: 0.1367  | Val Rec: 0.3677| Val AUC: 0.6867\n",
      "Epoch 092  Train Loss: 0.2312  | Val Loss: 0.4461  | Train F1: 0.2753  | Val F1: 0.2438  | Val Prec: 0.1855  | Val Rec: 0.3557| Val AUC: 0.7002\n",
      "Epoch 093  Train Loss: 0.2111  | Val Loss: 0.4593  | Train F1: 0.3389  | Val F1: 0.1998  | Val Prec: 0.1396  | Val Rec: 0.3512| Val AUC: 0.6862\n",
      "Epoch 094  Train Loss: 0.2167  | Val Loss: 0.4552  | Train F1: 0.3340  | Val F1: 0.2470  | Val Prec: 0.1904  | Val Rec: 0.3517| Val AUC: 0.6896\n",
      "Epoch 095  Train Loss: 0.2189  | Val Loss: 0.4677  | Train F1: 0.3647  | Val F1: 0.2547  | Val Prec: 0.2037  | Val Rec: 0.3397| Val AUC: 0.6974\n",
      "Epoch 096  Train Loss: 0.2173  | Val Loss: 0.4474  | Train F1: 0.3405  | Val F1: 0.2422  | Val Prec: 0.1838  | Val Rec: 0.3551| Val AUC: 0.6940\n",
      "Epoch 097  Train Loss: 0.2160  | Val Loss: 0.4400  | Train F1: 0.3387  | Val F1: 0.2131  | Val Prec: 0.1498  | Val Rec: 0.3689| Val AUC: 0.6980\n",
      "Epoch 098  Train Loss: 0.2158  | Val Loss: 0.4676  | Train F1: 0.3705  | Val F1: 0.2662  | Val Prec: 0.2162  | Val Rec: 0.3463| Val AUC: 0.6853\n",
      "Epoch 099  Train Loss: 0.2113  | Val Loss: 0.4742  | Train F1: 0.3921  | Val F1: 0.2820  | Val Prec: 0.2458  | Val Rec: 0.3306| Val AUC: 0.6815\n",
      "Epoch 100  Train Loss: 0.2157  | Val Loss: 0.4477  | Train F1: 0.3404  | Val F1: 0.1668  | Val Prec: 0.1073  | Val Rec: 0.3745| Val AUC: 0.6923\n",
      "Epoch 101  Train Loss: 0.1961  | Val Loss: 0.4631  | Train F1: 0.3772  | Val F1: 0.2625  | Val Prec: 0.2138  | Val Rec: 0.3398| Val AUC: 0.6841\n",
      "Epoch 102  Train Loss: 0.1947  | Val Loss: 0.4582  | Train F1: 0.4038  | Val F1: 0.2684  | Val Prec: 0.2197  | Val Rec: 0.3446| Val AUC: 0.6870\n",
      "Epoch 103  Train Loss: 0.2131  | Val Loss: 0.4730  | Train F1: 0.3772  | Val F1: 0.2616  | Val Prec: 0.2149  | Val Rec: 0.3343| Val AUC: 0.6875\n",
      "Epoch 104  Train Loss: 0.2115  | Val Loss: 0.4656  | Train F1: 0.3684  | Val F1: 0.2375  | Val Prec: 0.1802  | Val Rec: 0.3482| Val AUC: 0.6843\n",
      "Epoch 105  Train Loss: 0.1965  | Val Loss: 0.4501  | Train F1: 0.4118  | Val F1: 0.2345  | Val Prec: 0.1735  | Val Rec: 0.3617| Val AUC: 0.6934\n",
      "Epoch 106  Train Loss: 0.2051  | Val Loss: 0.4689  | Train F1: 0.3960  | Val F1: 0.2761  | Val Prec: 0.2318  | Val Rec: 0.3414| Val AUC: 0.6858\n",
      "Epoch 107  Train Loss: 0.1980  | Val Loss: 0.4815  | Train F1: 0.4253  | Val F1: 0.2914  | Val Prec: 0.2636  | Val Rec: 0.3256| Val AUC: 0.6825\n",
      "Epoch 108  Train Loss: 0.2006  | Val Loss: 0.4639  | Train F1: 0.4222  | Val F1: 0.2724  | Val Prec: 0.2261  | Val Rec: 0.3424| Val AUC: 0.6867\n",
      "Epoch 109  Train Loss: 0.2103  | Val Loss: 0.4707  | Train F1: 0.4389  | Val F1: 0.2723  | Val Prec: 0.2284  | Val Rec: 0.3371| Val AUC: 0.6890\n",
      "Epoch 110  Train Loss: 0.1994  | Val Loss: 0.4783  | Train F1: 0.4035  | Val F1: 0.2856  | Val Prec: 0.2512  | Val Rec: 0.3308| Val AUC: 0.6763\n",
      "Epoch 111  Train Loss: 0.1913  | Val Loss: 0.4755  | Train F1: 0.4361  | Val F1: 0.2635  | Val Prec: 0.2196  | Val Rec: 0.3295| Val AUC: 0.6778\n",
      "Epoch 112  Train Loss: 0.2105  | Val Loss: 0.4952  | Train F1: 0.4255  | Val F1: 0.2879  | Val Prec: 0.2631  | Val Rec: 0.3177| Val AUC: 0.6787\n",
      "Epoch 113  Train Loss: 0.1887  | Val Loss: 0.4786  | Train F1: 0.3762  | Val F1: 0.2534  | Val Prec: 0.2040  | Val Rec: 0.3342| Val AUC: 0.6823\n",
      "Epoch 114  Train Loss: 0.1981  | Val Loss: 0.4990  | Train F1: 0.4387  | Val F1: 0.2811  | Val Prec: 0.2533  | Val Rec: 0.3156| Val AUC: 0.6763\n",
      "Epoch 115  Train Loss: 0.1853  | Val Loss: 0.4858  | Train F1: 0.4699  | Val F1: 0.2905  | Val Prec: 0.2642  | Val Rec: 0.3227| Val AUC: 0.6751\n",
      "Epoch 116  Train Loss: 0.1903  | Val Loss: 0.4872  | Train F1: 0.4577  | Val F1: 0.2677  | Val Prec: 0.2277  | Val Rec: 0.3248| Val AUC: 0.6802\n",
      "Epoch 117  Train Loss: 0.1914  | Val Loss: 0.5015  | Train F1: 0.4669  | Val F1: 0.2881  | Val Prec: 0.2713  | Val Rec: 0.3071| Val AUC: 0.6701\n",
      "Epoch 118  Train Loss: 0.1979  | Val Loss: 0.4919  | Train F1: 0.4122  | Val F1: 0.2410  | Val Prec: 0.1930  | Val Rec: 0.3207| Val AUC: 0.6753\n",
      "Epoch 119  Train Loss: 0.1897  | Val Loss: 0.4964  | Train F1: 0.4539  | Val F1: 0.2865  | Val Prec: 0.2644  | Val Rec: 0.3127| Val AUC: 0.6744\n",
      "Epoch 120  Train Loss: 0.1856  | Val Loss: 0.4925  | Train F1: 0.4796  | Val F1: 0.2862  | Val Prec: 0.2618  | Val Rec: 0.3156| Val AUC: 0.6752\n",
      "Epoch 121  Train Loss: 0.1743  | Val Loss: 0.5012  | Train F1: 0.4941  | Val F1: 0.3024  | Val Prec: 0.2970  | Val Rec: 0.3081| Val AUC: 0.6708\n",
      "Epoch 122  Train Loss: 0.2029  | Val Loss: 0.4843  | Train F1: 0.4711  | Val F1: 0.2913  | Val Prec: 0.2679  | Val Rec: 0.3191| Val AUC: 0.6690\n",
      "Epoch 123  Train Loss: 0.1899  | Val Loss: 0.4890  | Train F1: 0.5012  | Val F1: 0.2966  | Val Prec: 0.2796  | Val Rec: 0.3160| Val AUC: 0.6730\n",
      "Epoch 124  Train Loss: 0.1904  | Val Loss: 0.5070  | Train F1: 0.5012  | Val F1: 0.3193  | Val Prec: 0.3360  | Val Rec: 0.3041| Val AUC: 0.6679\n",
      "Epoch 125  Train Loss: 0.1885  | Val Loss: 0.5054  | Train F1: 0.5009  | Val F1: 0.3051  | Val Prec: 0.3027  | Val Rec: 0.3076| Val AUC: 0.6697\n",
      "Epoch 126  Train Loss: 0.1951  | Val Loss: 0.5057  | Train F1: 0.5086  | Val F1: 0.3013  | Val Prec: 0.2948  | Val Rec: 0.3081| Val AUC: 0.6695\n",
      "Epoch 127  Train Loss: 0.1751  | Val Loss: 0.5090  | Train F1: 0.5021  | Val F1: 0.3033  | Val Prec: 0.2991  | Val Rec: 0.3075| Val AUC: 0.6758\n",
      "Epoch 128  Train Loss: 0.1753  | Val Loss: 0.5087  | Train F1: 0.4970  | Val F1: 0.2760  | Val Prec: 0.2493  | Val Rec: 0.3092| Val AUC: 0.6792\n",
      "Epoch 129  Train Loss: 0.1850  | Val Loss: 0.5082  | Train F1: 0.5066  | Val F1: 0.2922  | Val Prec: 0.2780  | Val Rec: 0.3080| Val AUC: 0.6766\n",
      "Epoch 130  Train Loss: 0.1889  | Val Loss: 0.5061  | Train F1: 0.5024  | Val F1: 0.2896  | Val Prec: 0.2692  | Val Rec: 0.3135| Val AUC: 0.6764\n",
      "Epoch 131  Train Loss: 0.1813  | Val Loss: 0.5152  | Train F1: 0.5047  | Val F1: 0.3080  | Val Prec: 0.3131  | Val Rec: 0.3030| Val AUC: 0.6735\n",
      "Epoch 132  Train Loss: 0.1917  | Val Loss: 0.5058  | Train F1: 0.5076  | Val F1: 0.2967  | Val Prec: 0.2843  | Val Rec: 0.3103| Val AUC: 0.6743\n",
      "Epoch 133  Train Loss: 0.1740  | Val Loss: 0.5107  | Train F1: 0.5118  | Val F1: 0.2943  | Val Prec: 0.2815  | Val Rec: 0.3083| Val AUC: 0.6747\n",
      "Epoch 134  Train Loss: 0.1689  | Val Loss: 0.5062  | Train F1: 0.5153  | Val F1: 0.3077  | Val Prec: 0.3071  | Val Rec: 0.3083| Val AUC: 0.6730\n",
      "Epoch 135  Train Loss: 0.1669  | Val Loss: 0.5137  | Train F1: 0.5260  | Val F1: 0.3191  | Val Prec: 0.3391  | Val Rec: 0.3013| Val AUC: 0.6700\n",
      "Epoch 136  Train Loss: 0.1804  | Val Loss: 0.5079  | Train F1: 0.5263  | Val F1: 0.3058  | Val Prec: 0.3049  | Val Rec: 0.3067| Val AUC: 0.6705\n",
      "Epoch 137  Batch 647/647  Batch Loss: 1.0000  | train F1: 0.5286  | train precision: 0.4555  | train recall: 0.6296\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m      6\u001B[39m up_activations   = [\u001B[33m'\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m      8\u001B[39m model = UNet(\n\u001B[32m      9\u001B[39m         down_filters=down_filters,\n\u001B[32m     10\u001B[39m         down_activations=down_activations,\n\u001B[32m   (...)\u001B[39m\u001B[32m     13\u001B[39m         bottleneck_transformer=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m     14\u001B[39m         ASPP_blocks=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m trained_model = train_model(model,\n\u001B[32m     18\u001B[39m                             train_ds, val_ds,\n\u001B[32m     19\u001B[39m                             epochs=\u001B[32m150\u001B[39m,\n\u001B[32m     20\u001B[39m                             batch_size=\u001B[32m128\u001B[39m,\n\u001B[32m     21\u001B[39m                             lr=\u001B[32m0.0015\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 83\u001B[39m, in \u001B[36mtrain_model\u001B[39m\u001B[34m(model, train_ds, val_ds, epochs, batch_size, lr, device)\u001B[39m\n\u001B[32m     81\u001B[39m imgs = imgs.to(device)\n\u001B[32m     82\u001B[39m m_resized = reshape_masks(masks, new_size=output_size).to(device)\n\u001B[32m---> \u001B[39m\u001B[32m83\u001B[39m preds = model(imgs)\n\u001B[32m     84\u001B[39m loss = criterion(preds, m_resized)\n\u001B[32m     85\u001B[39m val_loss += loss.item() * imgs.size(\u001B[32m0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 405\u001B[39m, in \u001B[36mUNet.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    403\u001B[39m skips = []\n\u001B[32m    404\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m enc \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.encoders[:-\u001B[32m1\u001B[39m]:  \u001B[38;5;66;03m# skip last encoder (bottleneck)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m405\u001B[39m     x, skip = enc(x)\n\u001B[32m    406\u001B[39m     skips.append(skip)\n\u001B[32m    408\u001B[39m \u001B[38;5;66;03m# Bottleneck:\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 223\u001B[39m, in \u001B[36mEncoderBlock.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    222\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m--> \u001B[39m\u001B[32m223\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.conv(x)\n\u001B[32m    224\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.cbam(x)\n\u001B[32m    225\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.dropout(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 167\u001B[39m, in \u001B[36mDoubleConv.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    166\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m--> \u001B[39m\u001B[32m167\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.block(x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    238\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    239\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m240\u001B[39m         \u001B[38;5;28minput\u001B[39m = module(\u001B[38;5;28minput\u001B[39m)\n\u001B[32m    241\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_impl(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(*args, **kwargs)\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001B[39m, in \u001B[36mConv2d.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    553\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m554\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._conv_forward(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m.weight, \u001B[38;5;28mself\u001B[39m.bias)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001B[39m, in \u001B[36mConv2d._conv_forward\u001B[39m\u001B[34m(self, input, weight, bias)\u001B[39m\n\u001B[32m    537\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.padding_mode != \u001B[33m\"\u001B[39m\u001B[33mzeros\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    538\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.conv2d(\n\u001B[32m    539\u001B[39m         F.pad(\n\u001B[32m    540\u001B[39m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m._reversed_padding_repeated_twice, mode=\u001B[38;5;28mself\u001B[39m.padding_mode\n\u001B[32m   (...)\u001B[39m\u001B[32m    547\u001B[39m         \u001B[38;5;28mself\u001B[39m.groups,\n\u001B[32m    548\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m549\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m F.conv2d(\n\u001B[32m    550\u001B[39m     \u001B[38;5;28minput\u001B[39m, weight, bias, \u001B[38;5;28mself\u001B[39m.stride, \u001B[38;5;28mself\u001B[39m.padding, \u001B[38;5;28mself\u001B[39m.dilation, \u001B[38;5;28mself\u001B[39m.groups\n\u001B[32m    551\u001B[39m )\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T22:03:20.511700Z",
     "start_time": "2025-06-11T22:03:20.462611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_path = \"../DATA/unet_model4.pth\"\n",
    "torch.save(model.state_dict(), save_path)"
   ],
   "id": "754226ac719ba211",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T15:13:59.771888Z",
     "start_time": "2025-06-11T15:13:59.666127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "down_filters =  [32, 32, 32, 64, 128, 256, 512]\n",
    "down_activations = ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu']\n",
    "\n",
    "up_filters       = [512, 256, 128, 64, 32]\n",
    "up_activations   = ['relu', 'relu', 'relu', 'relu', 'relu']\n",
    "\n",
    "model_loaded = UNet(\n",
    "    down_filters=down_filters,\n",
    "    down_activations=down_activations,\n",
    "    up_filters=up_filters,\n",
    "    up_activations=up_activations,\n",
    "    bottleneck_transformer=False,\n",
    "    ASPP_blocks=False\n",
    ")\n",
    "\n",
    "# 2) Load the saved state_dict:\n",
    "checkpoint = torch.load(\"../DATA/unet_model3.pth\", map_location=\"cpu\")\n",
    "model_loaded.load_state_dict(checkpoint)\n",
    "\n",
    "# 3) Put into eval mode (if only doing inference):\n",
    "model_loaded.eval()\n"
   ],
   "id": "e4eaf1e38b6330f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (input_norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (encoders): ModuleList(\n",
       "    (0): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): Identity()\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (1): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Sigmoid()\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=64, out_features=8, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=8, out_features=64, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (2): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=128, out_features=16, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (3): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=256, out_features=32, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=32, out_features=256, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (4): EncoderBlock(\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=512, out_features=64, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=64, out_features=512, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): Identity()\n",
       "  (decoders): ModuleList(\n",
       "    (0): DecoderBlock(\n",
       "      (up): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (bn_up): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_up): ReLU(inplace=True)\n",
       "      (attention): AttentionGate(\n",
       "        (W_g): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (W_x): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (psi): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Sigmoid()\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=512, out_features=64, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=64, out_features=512, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (1): DecoderBlock(\n",
       "      (up): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (bn_up): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_up): ReLU(inplace=True)\n",
       "      (attention): AttentionGate(\n",
       "        (W_g): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (W_x): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (psi): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Sigmoid()\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=256, out_features=32, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=32, out_features=256, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (2): DecoderBlock(\n",
       "      (up): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "      (bn_up): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_up): ReLU(inplace=True)\n",
       "      (attention): AttentionGate(\n",
       "        (W_g): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (W_x): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (psi): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Sigmoid()\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv): DoubleConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Linear(in_features=128, out_features=16, bias=False)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Linear(in_features=16, out_features=128, bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "          (norm): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Sequential(\n",
       "    (0): Conv2d(128, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T22:03:24.722469Z",
     "start_time": "2025-06-11T22:03:24.719467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(model, dataset, batch_size=32, device=None,\n",
    "                  return_probs: bool = True,  # if False, returns binary masks (0/1)\n",
    "                  threshold: float = 0.5      # threshold for binarization if return_probs=False\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Run inference on `dataset` using `model` and return all predictions.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): trained segmentation model (expects input shape (B,1,128,128) → output (B,1,Hout,Wout)).\n",
    "        dataset (torch.utils.data.Dataset): either\n",
    "            - A TensorDataset of (images, masks), or\n",
    "            - A Dataset that returns just `image` (no mask) if you only want predictions.\n",
    "        batch_size (int): batch size for DataLoader.\n",
    "        device (torch.device or str): 'cuda' or 'cpu'. If None, uses CUDA if available.\n",
    "        return_probs (bool):\n",
    "            - If True, returns the raw sigmoid‐probabilities of shape (N, 1, Hout, Wout).\n",
    "            - If False, thresholds those probabilities at `threshold` and returns binary masks (0/1).\n",
    "        threshold (float): cutoff for turning probability → 0/1 when return_probs=False.\n",
    "\n",
    "    Returns:\n",
    "        preds: numpy array of shape\n",
    "            - (N, 1, Hout, Wout) with float32 probs  in [0,1], if return_probs=True;\n",
    "            - (N, 1, Hout, Wout) with uint8 masks {0,1},       if return_probs=False.\n",
    "\n",
    "    Usage:\n",
    "        # 1) If you have (x_val, y_val) as a TensorDataset and want only predictions:\n",
    "        preds = predict_model(model, TensorDataset(torch.from_numpy(x_val).float(), torch.zeros(len(x_val),1,1,1)),\n",
    "                              batch_size=64, device='cuda', return_probs=False)\n",
    "\n",
    "        # 2) If your dataset yields only images (no masks):\n",
    "        preds = predict_model(model, test_dataset, batch_size=64, device='cuda', return_probs=True)\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # We don’t need real masks during inference, so DataLoader can silently ignore them.\n",
    "    # We'll detect whether dataset returns (img, mask) or just img.\n",
    "    def _collate_fn(batch):\n",
    "        # batch is a list of dataset[i] returns.\n",
    "        # If dataset[i] is a tuple (img, mask), take only img.\n",
    "        if isinstance(batch[0], (list, tuple)):\n",
    "            imgs = torch.stack([item[0] for item in batch], dim=0)\n",
    "        else:\n",
    "            imgs = torch.stack(batch, dim=0)\n",
    "        return imgs\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                        collate_fn=_collate_fn,\n",
    "                        num_workers=4, pin_memory=True)\n",
    "\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in loader:\n",
    "            imgs = imgs.to(device)                     # (B, 1, 128, 128) or similar\n",
    "            probs = model(imgs)                        # (B, 1, Hout, Wout), already in [0,1] due to final Sigmoid\n",
    "            if return_probs:\n",
    "                all_preds.append(probs.cpu())\n",
    "            else:\n",
    "                bin_masks = (probs > threshold).float()  # (B, 1, Hout, Wout) of 0.0 or 1.0\n",
    "                all_preds.append(bin_masks.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0)  # (N, 1, Hout, Wout)\n",
    "    if return_probs:\n",
    "        return all_preds.numpy().astype('float32')\n",
    "    else:\n",
    "        # convert to uint8 (0/1) for easier downstream use\n",
    "        return all_preds.numpy().astype('uint8')\n"
   ],
   "id": "14d55bcde18116e8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T22:03:25.305265Z",
     "start_time": "2025-06-11T22:03:25.301471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dataset_to_numpy(dataset, batch_size=64, device=None):\n",
    "    \"\"\"\n",
    "    Given a Dataset that returns either:\n",
    "      - (image_tensor, mask_tensor),  or\n",
    "      - just image_tensor\n",
    "    this function will loop once through the dataset, gather everything,\n",
    "    and return NumPy arrays.\n",
    "\n",
    "    Returns:\n",
    "      If dataset[i] returns (img, mask) for each i, then\n",
    "        imgs_np: shape (N, C, H, W) or whatever\n",
    "        masks_np: shape (N, Cm, Hm, Wm) (e.g. (N,1,128,128))\n",
    "      If dataset[i] returns only img, then\n",
    "        imgs_np: shape (N, C, H, W)\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # We won’t actually move data to GPU here, just stack on CPU at the end.\n",
    "    # But if your dataset does expensive preprocessing on CPU, you can pin_memory=True.\n",
    "\n",
    "    def _collate_fn(batch):\n",
    "        # If each element is (img, mask), we stack only imgs and masks separately.\n",
    "        # But DataLoader collate_fn must return a single tensor; we’ll handle masks in the loop.\n",
    "        # Instead, we return the raw batch list and unpack in the loop below.\n",
    "        return batch\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=_collate_fn,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    imgs_list = []\n",
    "    masks_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            # batch is a list of length `batch_size` (or the remainder on the last batch).\n",
    "            # Each element is either (img, mask) or just img.\n",
    "            first_elem = batch[0]\n",
    "            if isinstance(first_elem, (tuple, list)) and len(first_elem) == 2:\n",
    "                # Dataset returns (img, mask)\n",
    "                imgs = torch.stack([item[0] for item in batch], dim=0)   # (B, C, H, W)\n",
    "                masks = torch.stack([item[1] for item in batch], dim=0)  # (B, Cm, Hm, Wm)\n",
    "                imgs_list.append(imgs.cpu().numpy())\n",
    "                masks_list.append(masks.cpu().numpy())\n",
    "            else:\n",
    "                # Dataset returns only img\n",
    "                imgs = torch.stack(batch, dim=0)  # (B, C, H, W)\n",
    "                imgs_list.append(imgs.cpu().numpy())\n",
    "\n",
    "    imgs_np = np.concatenate(imgs_list, axis=0)\n",
    "    if masks_list:\n",
    "        masks_np = np.concatenate(masks_list, axis=0)\n",
    "        return imgs_np, masks_np\n",
    "    else:\n",
    "        return imgs_np\n",
    "\n",
    "def f2_score_numpy(y_true, y_pred, threshold=0.5, eps=1e-8):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: arrays of the same shape, either (N,H,W) or (N,1,H,W).\n",
    "    threshold: cutoff on y_pred if it’s in [0,1]; if y_pred is already binary, set threshold<0 or skip binarize.\n",
    "    Returns one global F2 (scalar).\n",
    "    \"\"\"\n",
    "    # 1) Binarize predictions (if they’re probabilities)\n",
    "    if y_pred.dtype != np.uint8 and threshold >= 0:\n",
    "        p_bin = (y_pred > threshold).astype(np.uint8)\n",
    "    else:\n",
    "        p_bin = y_pred.astype(np.uint8)\n",
    "\n",
    "    # 2) Similarly ensure y_true is 0/1 uint8\n",
    "    y_bin = y_true.astype(np.uint8)\n",
    "\n",
    "    # 3) Flatten to 1D\n",
    "    if p_bin.ndim == 4 and p_bin.shape[1] == 1:\n",
    "        p_flat = p_bin.squeeze(1).ravel()\n",
    "        y_flat = y_bin.squeeze(1).ravel()\n",
    "    else:\n",
    "        p_flat = p_bin.ravel()\n",
    "        y_flat = y_bin.ravel()\n",
    "\n",
    "    # 4) Compute TP, FP, FN\n",
    "    TP = np.sum((p_flat == 1) & (y_flat == 1))\n",
    "    FP = np.sum((p_flat == 1) & (y_flat == 0))\n",
    "    FN = np.sum((p_flat == 0) & (y_flat == 1))\n",
    "\n",
    "    # 5) Precision = TP / (TP + FP), Recall = TP / (TP + FN)\n",
    "    prec = TP / (TP + FP + eps)\n",
    "    rec  = TP / (TP + FN + eps)\n",
    "\n",
    "    # 6) F2 = 5 * (prec * rec) / (4*prec + rec)\n",
    "    f2 = (1 + 2**2) * (prec * rec) / (2**2 * prec + rec + eps)\n",
    "    return f2"
   ],
   "id": "9025c0e112346b9a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T22:03:50.836823Z",
     "start_time": "2025-06-11T22:03:30.656568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p = predict(model, val_ds, batch_size=128, device='cuda', return_probs=True)\n",
    "val_x, val_y = dataset_to_numpy(val_ds, batch_size=128)\n",
    "val_y = reshape_masks(torch.from_numpy(val_y).float(), new_size=(32, 32)).numpy()  # resize to match model output size\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(17, 5))\n",
    "\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(val_y.flatten(), p.flatten())\n",
    "auc_score = sklearn.metrics.auc(fpr, tpr)\n",
    "ax[0].plot(fpr, tpr, label=f'AUC = {auc_score:.4f}')\n",
    "ax[0].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax[0].set_xlabel('False positive rate')\n",
    "ax[0].set_ylabel('True positive rate')\n",
    "ax[0].legend()\n",
    "\n",
    "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(val_y.flatten(), p.flatten())\n",
    "ax[1].plot(precision, recall, label='Precision-Recall curve')\n",
    "ax[1].set_xlabel('Precision')\n",
    "ax[1].set_ylabel('Recall')\n",
    "ax[1].legend()\n",
    "ax[2].plot(thresholds, precision[1:], label='Precision')\n",
    "ax[2].plot(thresholds, recall[1:], label='Recall')\n",
    "ax[2].set_xlabel('Threshold')\n",
    "ax[2].set_ylabel('Score')\n",
    "ax[2].legend()\n",
    "print (f\"F2 score on validation set: {f2_score_numpy(val_y, p, threshold=0.5):.4f}\")"
   ],
   "id": "603238926fbca032",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score on validation set: 0.3062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1700x500 with 3 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T18:55:54.865030Z",
     "start_time": "2025-06-11T18:55:54.835019Z"
    }
   },
   "cell_type": "code",
   "source": "print (f\"F2 score on validation set: {f2_score_numpy(val_y, p, threshold=0.6):.4f}\")",
   "id": "e31f80100bf5ab3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score on validation set: 0.3207\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T18:29:39.648592Z",
     "start_time": "2025-06-11T16:03:15.327901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trained_model = train_model(model_loaded,\n",
    "                            train_ds, val_ds,\n",
    "                            epochs=100,\n",
    "                            batch_size=128,\n",
    "                            lr=1e-5)"
   ],
   "id": "29b3acb1925ba38a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001  Train Loss: 0.2414  | Val Loss: 0.4921  | Train F1: 0.5197  | Val F1: 0.3530  | Val Prec: 0.4040  | Val Rec: 0.3134| Val AUC: 0.6737\n",
      "Epoch 002  Train Loss: 0.2429  | Val Loss: 0.4816  | Train F1: 0.5194  | Val F1: 0.3450  | Val Prec: 0.3741  | Val Rec: 0.3201| Val AUC: 0.6745\n",
      "Epoch 003  Train Loss: 0.2491  | Val Loss: 0.4762  | Train F1: 0.5181  | Val F1: 0.3385  | Val Prec: 0.3546  | Val Rec: 0.3238| Val AUC: 0.6765\n",
      "Epoch 004  Train Loss: 0.2473  | Val Loss: 0.4889  | Train F1: 0.5171  | Val F1: 0.3510  | Val Prec: 0.3947  | Val Rec: 0.3160| Val AUC: 0.6740\n",
      "Epoch 005  Train Loss: 0.2461  | Val Loss: 0.4727  | Train F1: 0.5177  | Val F1: 0.3355  | Val Prec: 0.3439  | Val Rec: 0.3276| Val AUC: 0.6763\n",
      "Epoch 006  Train Loss: 0.2476  | Val Loss: 0.4813  | Train F1: 0.5092  | Val F1: 0.3418  | Val Prec: 0.3644  | Val Rec: 0.3219| Val AUC: 0.6740\n",
      "Epoch 007  Train Loss: 0.2389  | Val Loss: 0.4752  | Train F1: 0.5083  | Val F1: 0.3370  | Val Prec: 0.3489  | Val Rec: 0.3259| Val AUC: 0.6758\n",
      "Epoch 008  Train Loss: 0.2443  | Val Loss: 0.4766  | Train F1: 0.5065  | Val F1: 0.3388  | Val Prec: 0.3543  | Val Rec: 0.3246| Val AUC: 0.6753\n",
      "Epoch 009  Train Loss: 0.2482  | Val Loss: 0.4693  | Train F1: 0.5015  | Val F1: 0.3292  | Val Prec: 0.3267  | Val Rec: 0.3317| Val AUC: 0.6761\n",
      "Epoch 010  Train Loss: 0.2507  | Val Loss: 0.4759  | Train F1: 0.4998  | Val F1: 0.3346  | Val Prec: 0.3428  | Val Rec: 0.3268| Val AUC: 0.6753\n",
      "Epoch 011  Train Loss: 0.2419  | Val Loss: 0.4716  | Train F1: 0.4944  | Val F1: 0.3331  | Val Prec: 0.3367  | Val Rec: 0.3295| Val AUC: 0.6745\n",
      "Epoch 012  Train Loss: 0.2505  | Val Loss: 0.4724  | Train F1: 0.4935  | Val F1: 0.3349  | Val Prec: 0.3412  | Val Rec: 0.3288| Val AUC: 0.6740\n",
      "Epoch 013  Train Loss: 0.2177  | Val Loss: 0.4597  | Train F1: 0.4918  | Val F1: 0.3173  | Val Prec: 0.2989  | Val Rec: 0.3381| Val AUC: 0.6779\n",
      "Epoch 014  Train Loss: 0.2537  | Val Loss: 0.4766  | Train F1: 0.4918  | Val F1: 0.3360  | Val Prec: 0.3457  | Val Rec: 0.3268| Val AUC: 0.6731\n",
      "Epoch 015  Train Loss: 0.2337  | Val Loss: 0.4716  | Train F1: 0.4892  | Val F1: 0.3315  | Val Prec: 0.3331  | Val Rec: 0.3298| Val AUC: 0.6748\n",
      "Epoch 016  Train Loss: 0.2421  | Val Loss: 0.4628  | Train F1: 0.4867  | Val F1: 0.3116  | Val Prec: 0.2895  | Val Rec: 0.3372| Val AUC: 0.6754\n",
      "Epoch 017  Train Loss: 0.2345  | Val Loss: 0.4767  | Train F1: 0.4869  | Val F1: 0.3347  | Val Prec: 0.3419  | Val Rec: 0.3277| Val AUC: 0.6725\n",
      "Epoch 018  Train Loss: 0.2284  | Val Loss: 0.4782  | Train F1: 0.4848  | Val F1: 0.3350  | Val Prec: 0.3452  | Val Rec: 0.3255| Val AUC: 0.6724\n",
      "Epoch 019  Train Loss: 0.2390  | Val Loss: 0.4694  | Train F1: 0.4836  | Val F1: 0.3224  | Val Prec: 0.3133  | Val Rec: 0.3321| Val AUC: 0.6743\n",
      "Epoch 020  Train Loss: 0.2435  | Val Loss: 0.4825  | Train F1: 0.4808  | Val F1: 0.3331  | Val Prec: 0.3426  | Val Rec: 0.3241| Val AUC: 0.6716\n",
      "Epoch 021  Train Loss: 0.2455  | Val Loss: 0.4662  | Train F1: 0.4820  | Val F1: 0.3148  | Val Prec: 0.2971  | Val Rec: 0.3348| Val AUC: 0.6743\n",
      "Epoch 022  Train Loss: 0.2403  | Val Loss: 0.4663  | Train F1: 0.4819  | Val F1: 0.3167  | Val Prec: 0.3009  | Val Rec: 0.3344| Val AUC: 0.6739\n",
      "Epoch 023  Train Loss: 0.2438  | Val Loss: 0.4769  | Train F1: 0.4789  | Val F1: 0.3334  | Val Prec: 0.3421  | Val Rec: 0.3251| Val AUC: 0.6734\n",
      "Epoch 024  Train Loss: 0.2394  | Val Loss: 0.4742  | Train F1: 0.4757  | Val F1: 0.3330  | Val Prec: 0.3383  | Val Rec: 0.3279| Val AUC: 0.6734\n",
      "Epoch 025  Train Loss: 0.2381  | Val Loss: 0.4627  | Train F1: 0.4799  | Val F1: 0.3137  | Val Prec: 0.2938  | Val Rec: 0.3366| Val AUC: 0.6760\n",
      "Epoch 026  Train Loss: 0.2539  | Val Loss: 0.4701  | Train F1: 0.4813  | Val F1: 0.3233  | Val Prec: 0.3150  | Val Rec: 0.3320| Val AUC: 0.6723\n",
      "Epoch 027  Train Loss: 0.2376  | Val Loss: 0.4757  | Train F1: 0.4794  | Val F1: 0.3298  | Val Prec: 0.3329  | Val Rec: 0.3267| Val AUC: 0.6725\n",
      "Epoch 028  Train Loss: 0.2360  | Val Loss: 0.4701  | Train F1: 0.4775  | Val F1: 0.3199  | Val Prec: 0.3084  | Val Rec: 0.3323| Val AUC: 0.6725\n",
      "Epoch 029  Train Loss: 0.2355  | Val Loss: 0.4676  | Train F1: 0.4791  | Val F1: 0.3189  | Val Prec: 0.3054  | Val Rec: 0.3336| Val AUC: 0.6728\n",
      "Epoch 030  Train Loss: 0.2411  | Val Loss: 0.4592  | Train F1: 0.4811  | Val F1: 0.3063  | Val Prec: 0.2789  | Val Rec: 0.3398| Val AUC: 0.6748\n",
      "Epoch 031  Train Loss: 0.2589  | Val Loss: 0.4705  | Train F1: 0.4754  | Val F1: 0.3234  | Val Prec: 0.3158  | Val Rec: 0.3315| Val AUC: 0.6716\n",
      "Epoch 032  Train Loss: 0.2542  | Val Loss: 0.4687  | Train F1: 0.4798  | Val F1: 0.3137  | Val Prec: 0.2954  | Val Rec: 0.3343| Val AUC: 0.6718\n",
      "Epoch 033  Train Loss: 0.2283  | Val Loss: 0.4773  | Train F1: 0.4790  | Val F1: 0.3291  | Val Prec: 0.3325  | Val Rec: 0.3257| Val AUC: 0.6706\n",
      "Epoch 034  Train Loss: 0.2505  | Val Loss: 0.4778  | Train F1: 0.4821  | Val F1: 0.3291  | Val Prec: 0.3332  | Val Rec: 0.3251| Val AUC: 0.6703\n",
      "Epoch 035  Train Loss: 0.2414  | Val Loss: 0.4759  | Train F1: 0.4809  | Val F1: 0.3280  | Val Prec: 0.3287  | Val Rec: 0.3273| Val AUC: 0.6711\n",
      "Epoch 036  Train Loss: 0.2454  | Val Loss: 0.4702  | Train F1: 0.4846  | Val F1: 0.3208  | Val Prec: 0.3114  | Val Rec: 0.3307| Val AUC: 0.6738\n",
      "Epoch 037  Train Loss: 0.2279  | Val Loss: 0.4657  | Train F1: 0.4847  | Val F1: 0.3156  | Val Prec: 0.2984  | Val Rec: 0.3349| Val AUC: 0.6741\n",
      "Epoch 038  Train Loss: 0.2359  | Val Loss: 0.4795  | Train F1: 0.4825  | Val F1: 0.3274  | Val Prec: 0.3310  | Val Rec: 0.3239| Val AUC: 0.6716\n",
      "Epoch 039  Train Loss: 0.2346  | Val Loss: 0.4812  | Train F1: 0.4831  | Val F1: 0.3275  | Val Prec: 0.3305  | Val Rec: 0.3245| Val AUC: 0.6703\n",
      "Epoch 040  Train Loss: 0.2453  | Val Loss: 0.4698  | Train F1: 0.4819  | Val F1: 0.3162  | Val Prec: 0.3017  | Val Rec: 0.3322| Val AUC: 0.6717\n",
      "Epoch 041  Train Loss: 0.2392  | Val Loss: 0.4728  | Train F1: 0.4826  | Val F1: 0.3258  | Val Prec: 0.3222  | Val Rec: 0.3295| Val AUC: 0.6718\n",
      "Epoch 042  Train Loss: 0.2427  | Val Loss: 0.4768  | Train F1: 0.4836  | Val F1: 0.3243  | Val Prec: 0.3204  | Val Rec: 0.3282| Val AUC: 0.6699\n",
      "Epoch 043  Train Loss: 0.2394  | Val Loss: 0.4722  | Train F1: 0.4818  | Val F1: 0.3184  | Val Prec: 0.3069  | Val Rec: 0.3308| Val AUC: 0.6716\n",
      "Epoch 044  Train Loss: 0.2369  | Val Loss: 0.4884  | Train F1: 0.4829  | Val F1: 0.3322  | Val Prec: 0.3467  | Val Rec: 0.3189| Val AUC: 0.6701\n",
      "Epoch 045  Train Loss: 0.2327  | Val Loss: 0.4699  | Train F1: 0.4852  | Val F1: 0.3109  | Val Prec: 0.2923  | Val Rec: 0.3321| Val AUC: 0.6734\n",
      "Epoch 046  Train Loss: 0.2345  | Val Loss: 0.4800  | Train F1: 0.4848  | Val F1: 0.3279  | Val Prec: 0.3315  | Val Rec: 0.3244| Val AUC: 0.6724\n",
      "Epoch 047  Train Loss: 0.2379  | Val Loss: 0.4707  | Train F1: 0.4843  | Val F1: 0.3181  | Val Prec: 0.3061  | Val Rec: 0.3311| Val AUC: 0.6724\n",
      "Epoch 048  Train Loss: 0.2543  | Val Loss: 0.4685  | Train F1: 0.4841  | Val F1: 0.3204  | Val Prec: 0.3091  | Val Rec: 0.3325| Val AUC: 0.6743\n",
      "Epoch 049  Train Loss: 0.2276  | Val Loss: 0.4615  | Train F1: 0.4821  | Val F1: 0.3020  | Val Prec: 0.2733  | Val Rec: 0.3375| Val AUC: 0.6742\n",
      "Epoch 050  Train Loss: 0.2439  | Val Loss: 0.4616  | Train F1: 0.4842  | Val F1: 0.2974  | Val Prec: 0.2659  | Val Rec: 0.3373| Val AUC: 0.6731\n",
      "Epoch 051  Train Loss: 0.2411  | Val Loss: 0.4759  | Train F1: 0.4829  | Val F1: 0.3187  | Val Prec: 0.3101  | Val Rec: 0.3277| Val AUC: 0.6721\n",
      "Epoch 052  Train Loss: 0.2479  | Val Loss: 0.4844  | Train F1: 0.4812  | Val F1: 0.3300  | Val Prec: 0.3395  | Val Rec: 0.3210| Val AUC: 0.6707\n",
      "Epoch 053  Train Loss: 0.2550  | Val Loss: 0.4736  | Train F1: 0.4799  | Val F1: 0.3173  | Val Prec: 0.3059  | Val Rec: 0.3295| Val AUC: 0.6732\n",
      "Epoch 054  Train Loss: 0.2529  | Val Loss: 0.4685  | Train F1: 0.4828  | Val F1: 0.3093  | Val Prec: 0.2886  | Val Rec: 0.3332| Val AUC: 0.6729\n",
      "Epoch 055  Train Loss: 0.2390  | Val Loss: 0.4749  | Train F1: 0.4818  | Val F1: 0.3173  | Val Prec: 0.3062  | Val Rec: 0.3293| Val AUC: 0.6713\n",
      "Epoch 056  Train Loss: 0.2485  | Val Loss: 0.4655  | Train F1: 0.4804  | Val F1: 0.3076  | Val Prec: 0.2842  | Val Rec: 0.3352| Val AUC: 0.6757\n",
      "Epoch 057  Train Loss: 0.2442  | Val Loss: 0.4720  | Train F1: 0.4780  | Val F1: 0.3162  | Val Prec: 0.3025  | Val Rec: 0.3312| Val AUC: 0.6717\n",
      "Epoch 058  Train Loss: 0.2348  | Val Loss: 0.4783  | Train F1: 0.4788  | Val F1: 0.3203  | Val Prec: 0.3138  | Val Rec: 0.3271| Val AUC: 0.6711\n",
      "Epoch 059  Train Loss: 0.2391  | Val Loss: 0.4870  | Train F1: 0.4795  | Val F1: 0.3285  | Val Prec: 0.3384  | Val Rec: 0.3191| Val AUC: 0.6713\n",
      "Epoch 060  Train Loss: 0.2577  | Val Loss: 0.4769  | Train F1: 0.4784  | Val F1: 0.3239  | Val Prec: 0.3216  | Val Rec: 0.3263| Val AUC: 0.6718\n",
      "Epoch 061  Train Loss: 0.2445  | Val Loss: 0.4826  | Train F1: 0.4803  | Val F1: 0.3277  | Val Prec: 0.3330  | Val Rec: 0.3226| Val AUC: 0.6708\n",
      "Epoch 062  Train Loss: 0.2498  | Val Loss: 0.4724  | Train F1: 0.4781  | Val F1: 0.3177  | Val Prec: 0.3063  | Val Rec: 0.3300| Val AUC: 0.6738\n",
      "Epoch 063  Train Loss: 0.2457  | Val Loss: 0.4800  | Train F1: 0.4814  | Val F1: 0.3192  | Val Prec: 0.3130  | Val Rec: 0.3257| Val AUC: 0.6707\n",
      "Epoch 064  Train Loss: 0.2539  | Val Loss: 0.4806  | Train F1: 0.4811  | Val F1: 0.3211  | Val Prec: 0.3180  | Val Rec: 0.3242| Val AUC: 0.6708\n",
      "Epoch 065  Train Loss: 0.2315  | Val Loss: 0.4781  | Train F1: 0.4807  | Val F1: 0.3202  | Val Prec: 0.3147  | Val Rec: 0.3259| Val AUC: 0.6712\n",
      "Epoch 066  Train Loss: 0.2409  | Val Loss: 0.4715  | Train F1: 0.4804  | Val F1: 0.3194  | Val Prec: 0.3091  | Val Rec: 0.3303| Val AUC: 0.6739\n",
      "Epoch 067  Train Loss: 0.2285  | Val Loss: 0.4793  | Train F1: 0.4819  | Val F1: 0.3246  | Val Prec: 0.3246  | Val Rec: 0.3246| Val AUC: 0.6716\n",
      "Epoch 068  Train Loss: 0.2396  | Val Loss: 0.4722  | Train F1: 0.4816  | Val F1: 0.3172  | Val Prec: 0.3050  | Val Rec: 0.3304| Val AUC: 0.6727\n",
      "Epoch 069  Train Loss: 0.2279  | Val Loss: 0.4715  | Train F1: 0.4848  | Val F1: 0.3156  | Val Prec: 0.3021  | Val Rec: 0.3302| Val AUC: 0.6740\n",
      "Epoch 070  Train Loss: 0.2133  | Val Loss: 0.4760  | Train F1: 0.4834  | Val F1: 0.3151  | Val Prec: 0.3039  | Val Rec: 0.3272| Val AUC: 0.6721\n",
      "Epoch 071  Train Loss: 0.2556  | Val Loss: 0.4756  | Train F1: 0.4805  | Val F1: 0.3183  | Val Prec: 0.3099  | Val Rec: 0.3272| Val AUC: 0.6725\n",
      "Epoch 072  Train Loss: 0.2388  | Val Loss: 0.4767  | Train F1: 0.4838  | Val F1: 0.3194  | Val Prec: 0.3128  | Val Rec: 0.3263| Val AUC: 0.6706\n",
      "Epoch 073  Train Loss: 0.2494  | Val Loss: 0.4740  | Train F1: 0.4819  | Val F1: 0.3146  | Val Prec: 0.3012  | Val Rec: 0.3293| Val AUC: 0.6717\n",
      "Epoch 074  Train Loss: 0.2384  | Val Loss: 0.4999  | Train F1: 0.4804  | Val F1: 0.3388  | Val Prec: 0.3727  | Val Rec: 0.3106| Val AUC: 0.6675\n",
      "Epoch 075  Train Loss: 0.2264  | Val Loss: 0.4801  | Train F1: 0.4812  | Val F1: 0.3167  | Val Prec: 0.3085  | Val Rec: 0.3253| Val AUC: 0.6713\n",
      "Epoch 076  Train Loss: 0.2346  | Val Loss: 0.4844  | Train F1: 0.4853  | Val F1: 0.3198  | Val Prec: 0.3174  | Val Rec: 0.3222| Val AUC: 0.6701\n",
      "Epoch 077  Train Loss: 0.2277  | Val Loss: 0.4827  | Train F1: 0.4836  | Val F1: 0.3229  | Val Prec: 0.3222  | Val Rec: 0.3236| Val AUC: 0.6709\n",
      "Epoch 078  Train Loss: 0.2546  | Val Loss: 0.4763  | Train F1: 0.4809  | Val F1: 0.3173  | Val Prec: 0.3077  | Val Rec: 0.3275| Val AUC: 0.6725\n",
      "Epoch 079  Train Loss: 0.2257  | Val Loss: 0.4865  | Train F1: 0.4866  | Val F1: 0.3247  | Val Prec: 0.3285  | Val Rec: 0.3210| Val AUC: 0.6698\n",
      "Epoch 080  Train Loss: 0.2226  | Val Loss: 0.4747  | Train F1: 0.4834  | Val F1: 0.3189  | Val Prec: 0.3102  | Val Rec: 0.3281| Val AUC: 0.6731\n",
      "Epoch 081  Train Loss: 0.2266  | Val Loss: 0.4857  | Train F1: 0.4853  | Val F1: 0.3244  | Val Prec: 0.3271  | Val Rec: 0.3217| Val AUC: 0.6698\n",
      "Epoch 082  Train Loss: 0.2402  | Val Loss: 0.4672  | Train F1: 0.4853  | Val F1: 0.3087  | Val Prec: 0.2872  | Val Rec: 0.3336| Val AUC: 0.6736\n",
      "Epoch 083  Train Loss: 0.2356  | Val Loss: 0.4821  | Train F1: 0.4863  | Val F1: 0.3201  | Val Prec: 0.3162  | Val Rec: 0.3240| Val AUC: 0.6695\n",
      "Epoch 084  Train Loss: 0.2499  | Val Loss: 0.4915  | Train F1: 0.4837  | Val F1: 0.3291  | Val Prec: 0.3422  | Val Rec: 0.3170| Val AUC: 0.6691\n",
      "Epoch 085  Train Loss: 0.2589  | Val Loss: 0.4802  | Train F1: 0.4856  | Val F1: 0.3285  | Val Prec: 0.3330  | Val Rec: 0.3242| Val AUC: 0.6710\n",
      "Epoch 086  Train Loss: 0.2449  | Val Loss: 0.4782  | Train F1: 0.4858  | Val F1: 0.3128  | Val Prec: 0.2992  | Val Rec: 0.3278| Val AUC: 0.6715\n",
      "Epoch 087  Train Loss: 0.2347  | Val Loss: 0.4855  | Train F1: 0.4830  | Val F1: 0.3242  | Val Prec: 0.3260  | Val Rec: 0.3223| Val AUC: 0.6687\n",
      "Epoch 088  Train Loss: 0.2300  | Val Loss: 0.4917  | Train F1: 0.4841  | Val F1: 0.3377  | Val Prec: 0.3628  | Val Rec: 0.3158| Val AUC: 0.6691\n",
      "Epoch 089  Train Loss: 0.2472  | Val Loss: 0.4828  | Train F1: 0.4844  | Val F1: 0.3219  | Val Prec: 0.3202  | Val Rec: 0.3236| Val AUC: 0.6716\n",
      "Epoch 090  Train Loss: 0.2310  | Val Loss: 0.4895  | Train F1: 0.4841  | Val F1: 0.3305  | Val Prec: 0.3447  | Val Rec: 0.3175| Val AUC: 0.6701\n",
      "Epoch 091  Train Loss: 0.2409  | Val Loss: 0.4864  | Train F1: 0.4840  | Val F1: 0.3232  | Val Prec: 0.3251  | Val Rec: 0.3213| Val AUC: 0.6699\n",
      "Epoch 092  Train Loss: 0.2370  | Val Loss: 0.4811  | Train F1: 0.4845  | Val F1: 0.3222  | Val Prec: 0.3204  | Val Rec: 0.3241| Val AUC: 0.6712\n",
      "Epoch 093  Train Loss: 0.2406  | Val Loss: 0.4873  | Train F1: 0.4833  | Val F1: 0.3288  | Val Prec: 0.3390  | Val Rec: 0.3192| Val AUC: 0.6700\n",
      "Epoch 094  Train Loss: 0.2443  | Val Loss: 0.4939  | Train F1: 0.4851  | Val F1: 0.3323  | Val Prec: 0.3509  | Val Rec: 0.3155| Val AUC: 0.6687\n",
      "Epoch 095  Train Loss: 0.2534  | Val Loss: 0.4899  | Train F1: 0.4853  | Val F1: 0.3295  | Val Prec: 0.3406  | Val Rec: 0.3190| Val AUC: 0.6684\n",
      "Epoch 096  Train Loss: 0.2459  | Val Loss: 0.4813  | Train F1: 0.4836  | Val F1: 0.3216  | Val Prec: 0.3197  | Val Rec: 0.3235| Val AUC: 0.6706\n",
      "Epoch 097  Train Loss: 0.2531  | Val Loss: 0.4862  | Train F1: 0.4827  | Val F1: 0.3284  | Val Prec: 0.3362  | Val Rec: 0.3210| Val AUC: 0.6698\n",
      "Epoch 098  Train Loss: 0.2377  | Val Loss: 0.4838  | Train F1: 0.4820  | Val F1: 0.3186  | Val Prec: 0.3147  | Val Rec: 0.3226| Val AUC: 0.6706\n",
      "Epoch 099  Train Loss: 0.2410  | Val Loss: 0.4750  | Train F1: 0.4841  | Val F1: 0.3172  | Val Prec: 0.3071  | Val Rec: 0.3280| Val AUC: 0.6719\n",
      "Epoch 100  Train Loss: 0.2378  | Val Loss: 0.4803  | Train F1: 0.4830  | Val F1: 0.3141  | Val Prec: 0.3044  | Val Rec: 0.3246| Val AUC: 0.6715\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T18:29:40.141421Z",
     "start_time": "2025-06-11T18:29:39.774490Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model_loaded.state_dict(), \"../DATA/unet_model3.pth\")",
   "id": "660ef874dd4ccc6",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f034104f5508fc2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================================================================\n",
      "Layer (type:depth-idx)                             Input Shape               Output Shape              Param #                   Trainable\n",
      "======================================================================================================================================================\n",
      "UNet                                               [128, 1, 128, 128]        [128, 1, 32, 32]          --                        True\n",
      "├─BatchNorm2d: 1-1                                 [128, 1, 128, 128]        [128, 1, 128, 128]        2                         True\n",
      "├─ModuleList: 1-2                                  --                        --                        --                        True\n",
      "│    └─EncoderBlock: 2-1                           [128, 1, 128, 128]        [128, 32, 64, 64]         --                        True\n",
      "│    │    └─DoubleConv: 3-1                        [128, 1, 128, 128]        [128, 32, 128, 128]       9,696                     True\n",
      "│    │    └─Identity: 3-2                          [128, 32, 128, 128]       [128, 32, 128, 128]       --                        --\n",
      "│    │    └─Identity: 3-3                          [128, 32, 128, 128]       [128, 32, 128, 128]       --                        --\n",
      "│    └─EncoderBlock: 2-2                           [128, 32, 64, 64]         [128, 64, 32, 32]         --                        True\n",
      "│    │    └─DoubleConv: 3-4                        [128, 32, 64, 64]         [128, 64, 64, 64]         55,680                    True\n",
      "│    │    └─CBAMBlock: 3-5                         [128, 64, 64, 64]         [128, 64, 64, 64]         1,252                     True\n",
      "│    │    └─Identity: 3-6                          [128, 64, 64, 64]         [128, 64, 64, 64]         --                        --\n",
      "│    └─EncoderBlock: 2-3                           [128, 64, 32, 32]         [128, 128, 16, 16]        --                        True\n",
      "│    │    └─DoubleConv: 3-7                        [128, 64, 32, 32]         [128, 128, 32, 32]        221,952                   True\n",
      "│    │    └─CBAMBlock: 3-8                         [128, 128, 32, 32]        [128, 128, 32, 32]        4,452                     True\n",
      "│    │    └─Identity: 3-9                          [128, 128, 32, 32]        [128, 128, 32, 32]        --                        --\n",
      "│    └─EncoderBlock: 2-4                           [128, 128, 16, 16]        [128, 256, 8, 8]          --                        True\n",
      "│    │    └─DoubleConv: 3-10                       [128, 128, 16, 16]        [128, 256, 16, 16]        886,272                   True\n",
      "│    │    └─CBAMBlock: 3-11                        [128, 256, 16, 16]        [128, 256, 16, 16]        16,996                    True\n",
      "│    │    └─Identity: 3-12                         [128, 256, 16, 16]        [128, 256, 16, 16]        --                        --\n",
      "│    └─EncoderBlock: 2-5                           [128, 256, 8, 8]          [128, 512, 4, 4]          --                        True\n",
      "│    │    └─DoubleConv: 3-13                       [128, 256, 8, 8]          [128, 512, 8, 8]          3,542,016                 True\n",
      "│    │    └─CBAMBlock: 3-14                        [128, 512, 8, 8]          [128, 512, 8, 8]          66,660                    True\n",
      "│    │    └─Identity: 3-15                         [128, 512, 8, 8]          [128, 512, 8, 8]          --                        --\n",
      "├─Identity: 1-3                                    [128, 512, 4, 4]          [128, 512, 4, 4]          --                        --\n",
      "├─ModuleList: 1-4                                  --                        --                        --                        True\n",
      "│    └─DecoderBlock: 2-6                           [128, 512, 4, 4]          [128, 512, 8, 8]          396,288                   True\n",
      "│    │    └─ConvTranspose2d: 3-16                  [128, 512, 4, 4]          [128, 512, 8, 8]          2,359,808                 True\n",
      "│    │    └─BatchNorm2d: 3-17                      [128, 512, 8, 8]          [128, 512, 8, 8]          1,024                     True\n",
      "│    │    └─ReLU: 3-18                             [128, 512, 8, 8]          [128, 512, 8, 8]          --                        --\n",
      "│    │    └─DoubleConv: 3-19                       [128, 512, 8, 8]          [128, 512, 8, 8]          4,721,664                 True\n",
      "│    │    └─CBAMBlock: 3-20                        [128, 512, 8, 8]          [128, 512, 8, 8]          66,660                    True\n",
      "│    │    └─Identity: 3-21                         [128, 512, 8, 8]          [128, 512, 8, 8]          --                        --\n",
      "│    └─DecoderBlock: 2-7                           [128, 512, 8, 8]          [128, 256, 16, 16]        --                        True\n",
      "│    │    └─ConvTranspose2d: 3-22                  [128, 512, 8, 8]          [128, 256, 16, 16]        1,179,904                 True\n",
      "│    │    └─BatchNorm2d: 3-23                      [128, 256, 16, 16]        [128, 256, 16, 16]        512                       True\n",
      "│    │    └─ReLU: 3-24                             [128, 256, 16, 16]        [128, 256, 16, 16]        --                        --\n",
      "│    │    └─AttentionGate: 3-25                    --                        [128, 256, 16, 16]        99,840                    True\n",
      "│    │    └─DoubleConv: 3-26                       [128, 512, 16, 16]        [128, 256, 16, 16]        1,771,008                 True\n",
      "│    │    └─CBAMBlock: 3-27                        [128, 256, 16, 16]        [128, 256, 16, 16]        16,996                    True\n",
      "│    │    └─Identity: 3-28                         [128, 256, 16, 16]        [128, 256, 16, 16]        --                        --\n",
      "│    └─DecoderBlock: 2-8                           [128, 256, 16, 16]        [128, 128, 32, 32]        --                        True\n",
      "│    │    └─ConvTranspose2d: 3-29                  [128, 256, 16, 16]        [128, 128, 32, 32]        295,040                   True\n",
      "│    │    └─BatchNorm2d: 3-30                      [128, 128, 32, 32]        [128, 128, 32, 32]        256                       True\n",
      "│    │    └─ReLU: 3-31                             [128, 128, 32, 32]        [128, 128, 32, 32]        --                        --\n",
      "│    │    └─AttentionGate: 3-32                    --                        [128, 128, 32, 32]        25,344                    True\n",
      "│    │    └─DoubleConv: 3-33                       [128, 256, 32, 32]        [128, 128, 32, 32]        443,136                   True\n",
      "│    │    └─CBAMBlock: 3-34                        [128, 128, 32, 32]        [128, 128, 32, 32]        4,452                     True\n",
      "│    │    └─Identity: 3-35                         [128, 128, 32, 32]        [128, 128, 32, 32]        --                        --\n",
      "├─Sequential: 1-5                                  [128, 128, 32, 32]        [128, 1, 32, 32]          --                        True\n",
      "│    └─Conv2d: 2-9                                 [128, 128, 32, 32]        [128, 1, 32, 32]          3,201                     True\n",
      "│    └─Sigmoid: 2-10                               [128, 1, 32, 32]          [128, 1, 32, 32]          --                        --\n",
      "======================================================================================================================================================\n",
      "Total params: 16,190,111\n",
      "Trainable params: 16,190,111\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 394.54\n",
      "======================================================================================================================================================\n",
      "Input size (MB): 8.39\n",
      "Forward/backward pass size (MB): 6413.24\n",
      "Params size (MB): 63.18\n",
      "Estimated Total Size (MB): 6484.80\n",
      "======================================================================================================================================================\n"
     ]
    }
   ],
   "execution_count": 10,
   "source": [
    "# 1) pip install torchinfo\n",
    "#    (if you haven’t already)\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "down_filters     = [32, 64, 128, 256, 512]\n",
    "down_activations = ['relu', 'relu', 'relu', 'relu', 'relu']\n",
    "\n",
    "up_filters       = [512, 256, 128]\n",
    "up_activations   = ['relu', 'relu', 'relu']\n",
    "\n",
    "# 2) Re‐instantiate your UNet exactly as in your training code:\n",
    "model = UNet(\n",
    "        down_filters=down_filters,\n",
    "        down_activations=down_activations,\n",
    "        up_filters=up_filters,\n",
    "        up_activations=up_activations,\n",
    "bottleneck_transformer=False,\n",
    "ASPP_blocks=False)\n",
    "\n",
    "# 3) Ask for a summary on a dummy (1×1×128×128) input:\n",
    "_ = summary(\n",
    "    model,\n",
    "    input_size=(128, 1, 128, 128),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    verbose=1\n",
    ")\n"
   ],
   "id": "ead34bf5eaaf1c3e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
