{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:37:39.817643Z",
     "start_time": "2025-06-10T19:37:37.251706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import sklearn"
   ],
   "id": "c757f4099bf6030e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 21:37:38.443352: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-10 21:37:38.532524: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/karlo/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T21:58:00.743256Z",
     "start_time": "2025-06-10T21:58:00.727288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def activation_parser(activation_str):\n",
    "    \"\"\"\n",
    "    Parse a string to return the corresponding activation function.\n",
    "    Supported strings: 'relu', 'sigmoid', 'tanh', 'leaky_relu'.\n",
    "    \"\"\"\n",
    "    if activation_str.lower() == \"elu\":\n",
    "        return nn.ELU(inplace=True)\n",
    "    elif activation_str.lower() == \"hardshrink\":\n",
    "        return nn.Hardshrink(lambd=0.5)\n",
    "    elif activation_str.lower() == \"hardtanh\":\n",
    "        return nn.Hardtanh(min_val=-1, max_val=1, inplace=True)\n",
    "    elif activation_str.lower() == \"logsigmoid\":\n",
    "        return nn.LogSigmoid()\n",
    "    elif activation_str.lower() == \"relu6\":\n",
    "        return nn.ReLU6(inplace=True)\n",
    "    elif activation_str.lower() == \"softplus\":\n",
    "        return nn.Softplus()\n",
    "    elif activation_str.lower() == \"selu\":\n",
    "        return nn.SELU(inplace=True)\n",
    "    elif activation_str.lower() == \"prelu\":\n",
    "        return nn.PReLU()\n",
    "    elif activation_str.lower() == \"softmax\":\n",
    "        return nn.Softmax(dim=1)  # softmax along channel dimension\n",
    "    if activation_str.lower() == 'relu':\n",
    "        return nn.ReLU(inplace=True)\n",
    "    elif activation_str.lower() == 'sigmoid':\n",
    "        return nn.Sigmoid()\n",
    "    elif activation_str.lower() == 'tanh':\n",
    "        return nn.Tanh()\n",
    "    elif activation_str.lower() == 'leaky_relu':\n",
    "        return nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported activation: {activation_str}\")\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_channels, in_channels // ratio, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(in_channels // ratio, in_channels, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self.norm = nn.LayerNorm(in_channels)\n",
    "        self.norm = nn.BatchNorm1d(in_channels)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        #nn.init.constant_(self.fc1.bias, 0)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, mode='fan_out', nonlinearity='sigmoid')\n",
    "        #nn.init.constant_(self.fc2.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.avg_pool(x)        # (B, C, 1, 1)\n",
    "        avg_out = avg_out.view(avg_out.size(0), avg_out.size(1))  # (B, C)\n",
    "        avg_out = self.fc1(avg_out)       # (B, C//ratio)\n",
    "        avg_out = self.relu(avg_out)\n",
    "        avg_out = self.fc2(avg_out)       # (B, C)\n",
    "\n",
    "        max_out = self.max_pool(x)        # (B, C, 1, 1)\n",
    "        max_out = max_out.view(max_out.size(0), max_out.size(1))  # (B, C)\n",
    "        max_out = self.fc1(max_out)       # (B, C//ratio)\n",
    "        max_out = self.relu(max_out)\n",
    "        max_out = self.fc2(max_out)       # (B, C)\n",
    "\n",
    "        out = avg_out + max_out           # (B, C)\n",
    "        out = self.norm(out)              # (B, C)\n",
    "        scale = self.sigmoid(out)         # (B, C)\n",
    "        scale = scale.view(scale.size(0), scale.size(1), 1, 1)  # (B, C, 1, 1)\n",
    "        return x * scale                  # broadcast along H, W\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=5):\n",
    "        super().__init__()\n",
    "        assert kernel_size in (3, 5, 7)\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.norm = nn.BatchNorm2d(1)\n",
    "        nn.init.kaiming_normal_(self.conv.weight, mode='fan_in', nonlinearity='sigmoid')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)     # (B, 1, H, W)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)   # (B, 1, H, W)\n",
    "        concat = torch.cat([avg_out, max_out], dim=1)    # (B, 2, H, W)\n",
    "        attn = self.conv(concat)                         # (B, 1, H, W)\n",
    "        attn = self.norm(attn)                           # (B, 1, H, W)\n",
    "        attn = self.sigmoid(attn)\n",
    "        return x * attn                                  # broadcast across C\n",
    "\n",
    "class CBAMBlock(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=8, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.channel_att = ChannelAttention(in_channels, ratio)\n",
    "        self.spatial_att = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.channel_att(x)\n",
    "        x = self.spatial_att(x)\n",
    "        return x\n",
    "\n",
    "class SepConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation, kernel_size, padding, dilation=1):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_ch, in_ch, kernel_size=kernel_size,\n",
    "            padding=padding, dilation=dilation,\n",
    "            groups=in_ch, bias=True\n",
    "        )\n",
    "        self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=True)\n",
    "        self.norm = nn.BatchNorm2d(out_ch)\n",
    "        self.act = activation_parser(activation)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.depthwise.weight, mode='fan_out', nonlinearity=activation)\n",
    "        nn.init.constant_(self.depthwise.bias, 0)\n",
    "        nn.init.kaiming_normal_(self.pointwise.weight, mode='fan_out', nonlinearity=activation)\n",
    "        nn.init.constant_(self.pointwise.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return self.act(self.norm(x))\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation):\n",
    "        super().__init__()\n",
    "        dilations = [1, 2, 3, 4]\n",
    "        kernels   = [1, 3, 5, 7]\n",
    "        self.branches = nn.ModuleList()\n",
    "        for d, k in zip(dilations, kernels):\n",
    "            pad = (k // 2) * d\n",
    "            self.branches.append(\n",
    "                SepConv(in_ch, out_ch, activation, kernel_size=k, padding=pad, dilation=d)\n",
    "            )\n",
    "        self.merge = nn.Sequential(\n",
    "            nn.Conv2d(len(dilations) * out_ch, out_ch, kernel_size=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation_parser(activation)\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.merge[0].weight, mode='fan_out', nonlinearity=activation)\n",
    "        nn.init.constant_(self.merge[0].bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = [branch(x) for branch in self.branches]\n",
    "        x = torch.cat(outs, dim=1)\n",
    "        return self.merge(x)\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation_parser(activation),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation_parser(activation)\n",
    "        )\n",
    "        for m in self.block.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity=activation)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        # W_g projects gating signal\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # W_x projects skip connection\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # psi computes 1‐channel attention map\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, F_g, kernel_size=1, bias=True),\n",
    "            nn.BatchNorm2d(F_g),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.W_g[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.constant_(self.W_g[0].bias, 0)\n",
    "        nn.init.kaiming_normal_(self.W_x[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.constant_(self.W_x[0].bias, 0)\n",
    "        nn.init.kaiming_normal_(self.psi[0].weight, mode='fan_out', nonlinearity='sigmoid')\n",
    "        nn.init.constant_(self.psi[0].bias, 0)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        \"\"\"\n",
    "        g: gating signal from decoder, shape (B, F_g, H, W)\n",
    "        x: skip connection from encoder, shape (B, F_l, H, W)\n",
    "        \"\"\"\n",
    "        g1 = self.W_g(g)   # (B, F_int, H, W)\n",
    "        x1 = self.W_x(x)   # (B, F_int, H, W)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)   # (B, 1, H, W)\n",
    "        return x * psi        # broadcast along channel\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation, dropout_prob=0.0, attention=True, pool=True, ASPP_blocks=True):\n",
    "        super().__init__()\n",
    "        if ASPP_blocks:\n",
    "            # Use ASPP instead of DoubleConv\n",
    "            self.conv = ASPP(in_ch, out_ch, activation)\n",
    "        else:\n",
    "            # Use DoubleConv if ASPP_blocks is False\n",
    "            self.conv = DoubleConv(in_ch, out_ch, activation)\n",
    "        self.cbam        = CBAMBlock(out_ch, ratio=8, kernel_size=7) if attention else nn.Identity()\n",
    "        self.dropout     = nn.Dropout2d(dropout_prob) if dropout_prob > 0 else nn.Identity()\n",
    "        self.pool        = pool\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.cbam(x)\n",
    "        x = self.dropout(x)\n",
    "        skip = x.clone()\n",
    "        if self.pool:\n",
    "            x = F.max_pool2d(x, kernel_size=2)\n",
    "        return x, skip\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, skip_ch, out_ch, activation, dropout_prob=0.0, attention=True, upsample=True, ASPP_blocks=True):\n",
    "        \"\"\"\n",
    "        in_ch:   channels from previous layer (bottleneck or previous decoder)\n",
    "        skip_ch: channels in the corresponding encoder skip\n",
    "        out_ch:  desired output channels for this decoder block\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        self.skip_ch = skip_ch\n",
    "\n",
    "        if self.upsample:\n",
    "            # ConvTranspose2d(in_ch → skip_ch) to match spatial & channel dims\n",
    "            self.up = nn.ConvTranspose2d(in_ch, skip_ch, kernel_size=3,\n",
    "                                         stride=2, padding=1, output_padding=1, bias=True)\n",
    "            nn.init.kaiming_normal_(self.up.weight, mode='fan_out', nonlinearity='relu')\n",
    "            self.bn_up = nn.BatchNorm2d(skip_ch)\n",
    "            self.act_up = activation_parser(activation)\n",
    "            self.attention = AttentionGate(F_g=skip_ch, F_l=skip_ch, F_int=skip_ch // 2) if attention else nn.Identity()\n",
    "        else:\n",
    "            self.up = None\n",
    "            self.bn_up = None\n",
    "            self.act_up = None\n",
    "            self.attention = AttentionGate(F_g=in_ch, F_l=in_ch, F_int=in_ch // 2) if attention else nn.Identity()\n",
    "\n",
    "        #self.double_conv = DoubleConv(in_double, out_ch, activation)\n",
    "        if ASPP_blocks:\n",
    "            # Use ASPP instead of DoubleConv\n",
    "            self.conv = ASPP(in_ch, out_ch, activation)\n",
    "        else:\n",
    "            # Use DoubleConv if ASPP_blocks is False\n",
    "            self.conv = DoubleConv(in_ch, out_ch, activation)\n",
    "        self.cbam        = CBAMBlock(out_ch, ratio=8, kernel_size=7) if attention else nn.Identity()\n",
    "        self.dropout     = nn.Dropout2d(dropout_prob) if dropout_prob > 0 else nn.Identity()\n",
    "\n",
    "    def forward(self, x, skip=None):\n",
    "        if self.upsample:\n",
    "            x = self.up(x)       # (B, skip_ch, H*2, W*2)\n",
    "            x = self.bn_up(x)\n",
    "            x = self.act_up(x)\n",
    "        if skip is not None:\n",
    "            skip = self.attention(g=x, x=skip)\n",
    "            x = torch.cat([x, skip], dim=1)  # (B, 2*skip_ch, H*2, W*2)\n",
    "        x = self.conv(x)\n",
    "        x = self.cbam(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleneckTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes a tensor of shape (B, C, H, W), flattens the H×W patches into tokens,\n",
    "    runs a small TransformerEncoder over them, then reshapes back to (B, C, H, W).\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, heads=8, depth=3, mlp_dim=None):\n",
    "        super().__init__()\n",
    "        mlp_dim = mlp_dim or dim * 4\n",
    "        # one TransformerEncoderLayer (or more, if depth>1)\n",
    "        layer_e = nn.TransformerEncoderLayer(\n",
    "            d_model=dim,\n",
    "            nhead=heads,\n",
    "            dim_feedforward=mlp_dim,\n",
    "            activation='relu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        layer_d = nn.TransformerDecoderLayer(\n",
    "            d_model=dim,\n",
    "            nhead=heads,\n",
    "            dim_feedforward=mlp_dim,\n",
    "            activation='relu',\n",
    "            norm_first=True,  # important for TransformerDecoder\n",
    "            #batch_first=True\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.TransformerEncoder(layer_e, num_layers=depth//2 if depth > 1 else depth)\n",
    "        self.norm    = nn.LayerNorm(dim)\n",
    "        if depth > 1:\n",
    "            self.decoder = nn.TransformerDecoder(layer_d, num_layers=depth - depth//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W)\n",
    "        B, C, H, W = x.shape\n",
    "        # flatten spatial dims:\n",
    "        # → (B, C, H*W) then permute to (H*W, B, C) for PyTorch’s MHSA\n",
    "        tokens = x.flatten(2).permute(2, 0, 1)   # (H*W, B, C)\n",
    "        # run through TransformerEncoder\n",
    "        out   = self.encoder(tokens)             # (H*W, B, C)\n",
    "        # run through TransformerDecoder (optional, if depth > 1)\n",
    "        if hasattr(self, 'decoder'):\n",
    "            out = self.decoder(out, out)          # (H*W, B, C)\n",
    "        # put back into (B, C, H, W) after a LayerNorm on each token\n",
    "        out   = out.permute(1, 2, 0).view(B, C, H, W)\n",
    "        return self.norm(out.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
    "        # explanation of the two permutes:\n",
    "        #  - out.permute(1,2,0)→(B, C, H*W) then .view(B, C, H, W)\n",
    "        #  - we want LN over the C‐dimension, so we permute to (B, H, W, C), apply LayerNorm,\n",
    "        #    then back to (B, C, H, W).\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=1,\n",
    "                 out_channels=1,\n",
    "                 down_filters=None,\n",
    "                 down_activations=None,\n",
    "                 up_filters=None,\n",
    "                 up_activations=None,\n",
    "                 bottleneck_transformer=True,\n",
    "                 ASPP_blocks=True):\n",
    "        super().__init__()\n",
    "        assert len(down_filters) == len(down_activations)\n",
    "        assert len(up_filters)   == len(up_activations)\n",
    "\n",
    "        # Build Encoder path\n",
    "        self.input_norm = nn.BatchNorm2d(in_channels)\n",
    "        self.encoders = nn.ModuleList()\n",
    "        self.bottleneck_transformer = bottleneck_transformer\n",
    "        prev_ch = in_channels\n",
    "        for i, out_ch in enumerate(down_filters):\n",
    "            act_str = down_activations[i].lower()\n",
    "            self.encoders.append(\n",
    "                EncoderBlock(in_ch=prev_ch,\n",
    "                             out_ch=out_ch,\n",
    "                             activation=act_str,\n",
    "                             dropout_prob=0.0,\n",
    "                             attention=(i != 0),\n",
    "                             pool=True,\n",
    "                             ASPP_blocks=ASPP_blocks)\n",
    "            )\n",
    "            prev_ch = out_ch\n",
    "\n",
    "        # Bottleneck:\n",
    "        if bottleneck_transformer:\n",
    "            self.bottleneck  = BottleneckTransformer(dim=down_filters[-1],\n",
    "                                                           heads=4,\n",
    "                                                           depth=4)\n",
    "        else:\n",
    "            self.bottleneck = nn.Identity()\n",
    "\n",
    "        # Build Decoder path\n",
    "        self.decoders = nn.ModuleList()\n",
    "        N = len(down_filters)\n",
    "        for i in range(len(up_filters)):\n",
    "            act_str = up_activations[i].lower()\n",
    "            # Corresponding skip channels from encoder\n",
    "            skip_ch = down_filters[N - 1 - i]\n",
    "            # Input channels for this decoder block\n",
    "            out_ch = up_filters[i]\n",
    "            in_ch_dec = (down_filters[-1] * 1) if (i == 0) else up_filters[i - 1]\n",
    "\n",
    "            self.decoders.append(\n",
    "                DecoderBlock(in_ch=in_ch_dec,\n",
    "                             skip_ch=skip_ch,\n",
    "                             out_ch=out_ch,\n",
    "                             activation=act_str,\n",
    "                             dropout_prob=0.0,\n",
    "                             attention= True,\n",
    "                             upsample=True,\n",
    "                             ASPP_blocks=ASPP_blocks)\n",
    "            )\n",
    "\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv2d(up_filters[-1], out_channels, kernel_size=5, padding=2, bias=True),\n",
    "            nn.Sigmoid())\n",
    "        nn.init.kaiming_normal_(self.final_conv[0].weight, mode='fan_out', nonlinearity='sigmoid')\n",
    "        nn.init.constant_(self.final_conv[0].bias, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_norm(x)  # Normalize input\n",
    "        # x: (B, 1, 128, 128)\n",
    "        skips = []\n",
    "        for enc in self.encoders[:-1]:  # skip last encoder (bottleneck)\n",
    "            x, skip = enc(x)\n",
    "            skips.append(skip)\n",
    "\n",
    "        # Bottleneck:\n",
    "        x, _ = self.encoders[-1](x) # last encoder does not return a skip\n",
    "        skips.append(None)\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        x = self.decoders[0](x, skips[-1])  # first decoder uses the last encoder skip\n",
    "\n",
    "        skips = skips[::-1]              # reverse order for decoding\n",
    "\n",
    "        for i in range(1, len(self.decoders)):\n",
    "            skip_feat = skips[i]\n",
    "            x = self.decoders[i](x, skip_feat)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "        return x"
   ],
   "id": "6b0ee8133ceb7c68",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:49:56.619390Z",
     "start_time": "2025-06-10T19:49:56.503686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1) pip install torchinfo\n",
    "#    (if you haven’t already)\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "down_filters     = [32, 64, 128, 256, 512]\n",
    "down_activations = ['relu', 'relu', 'relu', 'relu', 'relu']\n",
    "\n",
    "up_filters       = [512, 256, 128]\n",
    "up_activations   = ['relu', 'relu', 'relu']\n",
    "\n",
    "# 2) Re‐instantiate your UNet exactly as in your training code:\n",
    "model = UNet(\n",
    "        down_filters=down_filters,\n",
    "        down_activations=down_activations,\n",
    "        up_filters=up_filters,\n",
    "        up_activations=up_activations,\n",
    "bottleneck_transformer=False,\n",
    "ASPP_blocks=False)\n",
    "\n",
    "# 3) Ask for a summary on a dummy (1×1×128×128) input:\n",
    "_ = summary(\n",
    "    model,\n",
    "    input_size=(128, 1, 128, 128),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    verbose=1\n",
    ")\n"
   ],
   "id": "ead34bf5eaaf1c3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================================================================\n",
      "Layer (type:depth-idx)                             Input Shape               Output Shape              Param #                   Trainable\n",
      "======================================================================================================================================================\n",
      "UNet                                               [128, 1, 128, 128]        [128, 1, 32, 32]          --                        True\n",
      "├─BatchNorm2d: 1-1                                 [128, 1, 128, 128]        [128, 1, 128, 128]        2                         True\n",
      "├─ModuleList: 1-2                                  --                        --                        --                        True\n",
      "│    └─EncoderBlock: 2-1                           [128, 1, 128, 128]        [128, 32, 64, 64]         --                        True\n",
      "│    │    └─DoubleConv: 3-1                        [128, 1, 128, 128]        [128, 32, 128, 128]       9,696                     True\n",
      "│    │    └─Identity: 3-2                          [128, 32, 128, 128]       [128, 32, 128, 128]       --                        --\n",
      "│    │    └─Identity: 3-3                          [128, 32, 128, 128]       [128, 32, 128, 128]       --                        --\n",
      "│    └─EncoderBlock: 2-2                           [128, 32, 64, 64]         [128, 64, 32, 32]         --                        True\n",
      "│    │    └─DoubleConv: 3-4                        [128, 32, 64, 64]         [128, 64, 64, 64]         55,680                    True\n",
      "│    │    └─CBAMBlock: 3-5                         [128, 64, 64, 64]         [128, 64, 64, 64]         1,252                     True\n",
      "│    │    └─Identity: 3-6                          [128, 64, 64, 64]         [128, 64, 64, 64]         --                        --\n",
      "│    └─EncoderBlock: 2-3                           [128, 64, 32, 32]         [128, 128, 16, 16]        --                        True\n",
      "│    │    └─DoubleConv: 3-7                        [128, 64, 32, 32]         [128, 128, 32, 32]        221,952                   True\n",
      "│    │    └─CBAMBlock: 3-8                         [128, 128, 32, 32]        [128, 128, 32, 32]        4,452                     True\n",
      "│    │    └─Identity: 3-9                          [128, 128, 32, 32]        [128, 128, 32, 32]        --                        --\n",
      "│    └─EncoderBlock: 2-4                           [128, 128, 16, 16]        [128, 256, 8, 8]          --                        True\n",
      "│    │    └─DoubleConv: 3-10                       [128, 128, 16, 16]        [128, 256, 16, 16]        886,272                   True\n",
      "│    │    └─CBAMBlock: 3-11                        [128, 256, 16, 16]        [128, 256, 16, 16]        16,996                    True\n",
      "│    │    └─Identity: 3-12                         [128, 256, 16, 16]        [128, 256, 16, 16]        --                        --\n",
      "│    └─EncoderBlock: 2-5                           [128, 256, 8, 8]          [128, 512, 4, 4]          --                        True\n",
      "│    │    └─DoubleConv: 3-13                       [128, 256, 8, 8]          [128, 512, 8, 8]          3,542,016                 True\n",
      "│    │    └─CBAMBlock: 3-14                        [128, 512, 8, 8]          [128, 512, 8, 8]          66,660                    True\n",
      "│    │    └─Identity: 3-15                         [128, 512, 8, 8]          [128, 512, 8, 8]          --                        --\n",
      "├─ModuleList: 1-3                                  --                        --                        --                        True\n",
      "│    └─DecoderBlock: 2-6                           [128, 512, 4, 4]          [128, 512, 8, 8]          396,288                   True\n",
      "│    │    └─ConvTranspose2d: 3-16                  [128, 512, 4, 4]          [128, 512, 8, 8]          2,359,808                 True\n",
      "│    │    └─BatchNorm2d: 3-17                      [128, 512, 8, 8]          [128, 512, 8, 8]          1,024                     True\n",
      "│    │    └─ReLU: 3-18                             [128, 512, 8, 8]          [128, 512, 8, 8]          --                        --\n",
      "│    │    └─DoubleConv: 3-19                       [128, 512, 8, 8]          [128, 512, 8, 8]          4,721,664                 True\n",
      "│    │    └─CBAMBlock: 3-20                        [128, 512, 8, 8]          [128, 512, 8, 8]          66,660                    True\n",
      "│    │    └─Identity: 3-21                         [128, 512, 8, 8]          [128, 512, 8, 8]          --                        --\n",
      "│    └─DecoderBlock: 2-7                           [128, 512, 8, 8]          [128, 256, 16, 16]        --                        True\n",
      "│    │    └─ConvTranspose2d: 3-22                  [128, 512, 8, 8]          [128, 256, 16, 16]        1,179,904                 True\n",
      "│    │    └─BatchNorm2d: 3-23                      [128, 256, 16, 16]        [128, 256, 16, 16]        512                       True\n",
      "│    │    └─ReLU: 3-24                             [128, 256, 16, 16]        [128, 256, 16, 16]        --                        --\n",
      "│    │    └─AttentionGate: 3-25                    --                        [128, 256, 16, 16]        99,840                    True\n",
      "│    │    └─DoubleConv: 3-26                       [128, 512, 16, 16]        [128, 256, 16, 16]        1,771,008                 True\n",
      "│    │    └─CBAMBlock: 3-27                        [128, 256, 16, 16]        [128, 256, 16, 16]        16,996                    True\n",
      "│    │    └─Identity: 3-28                         [128, 256, 16, 16]        [128, 256, 16, 16]        --                        --\n",
      "│    └─DecoderBlock: 2-8                           [128, 256, 16, 16]        [128, 128, 32, 32]        --                        True\n",
      "│    │    └─ConvTranspose2d: 3-29                  [128, 256, 16, 16]        [128, 128, 32, 32]        295,040                   True\n",
      "│    │    └─BatchNorm2d: 3-30                      [128, 128, 32, 32]        [128, 128, 32, 32]        256                       True\n",
      "│    │    └─ReLU: 3-31                             [128, 128, 32, 32]        [128, 128, 32, 32]        --                        --\n",
      "│    │    └─AttentionGate: 3-32                    --                        [128, 128, 32, 32]        25,344                    True\n",
      "│    │    └─DoubleConv: 3-33                       [128, 256, 32, 32]        [128, 128, 32, 32]        443,136                   True\n",
      "│    │    └─CBAMBlock: 3-34                        [128, 128, 32, 32]        [128, 128, 32, 32]        4,452                     True\n",
      "│    │    └─Identity: 3-35                         [128, 128, 32, 32]        [128, 128, 32, 32]        --                        --\n",
      "├─Sequential: 1-4                                  [128, 128, 32, 32]        [128, 1, 32, 32]          --                        True\n",
      "│    └─Conv2d: 2-9                                 [128, 128, 32, 32]        [128, 1, 32, 32]          3,201                     True\n",
      "│    └─Sigmoid: 2-10                               [128, 1, 32, 32]          [128, 1, 32, 32]          --                        --\n",
      "======================================================================================================================================================\n",
      "Total params: 16,190,111\n",
      "Trainable params: 16,190,111\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 394.54\n",
      "======================================================================================================================================================\n",
      "Input size (MB): 8.39\n",
      "Forward/backward pass size (MB): 6413.24\n",
      "Params size (MB): 63.18\n",
      "Estimated Total Size (MB): 6484.80\n",
      "======================================================================================================================================================\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:49:58.235462Z",
     "start_time": "2025-06-10T19:49:58.232283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        \"\"\"\n",
    "        preds:   Tensor (B,1,H,W) after Sigmoid\n",
    "        targets: Tensor (B,1,H,W) binary {0,1}\n",
    "        \"\"\"\n",
    "        p_flat = preds.view(-1)\n",
    "        t_flat = targets.view(-1)\n",
    "        intersection = (p_flat * t_flat).sum()\n",
    "        dice_coeff = (2. * intersection + self.smooth) / (p_flat.sum() + t_flat.sum() + self.smooth)\n",
    "        return 1 - dice_coeff\n",
    "\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.9, gamma=2.0, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha, self.gamma, self.eps = alpha, gamma, eps\n",
    "        self.beta = 1 - alpha  # Ensure alpha + beta = 1\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        preds = preds.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        TP = (preds * targets).sum()\n",
    "        FP = (preds * (1 - targets)).sum()\n",
    "        FN = ((1 - preds) * targets).sum()\n",
    "        tversky = (TP + self.eps) / (TP + self.alpha*FN + self.beta*FP + self.eps)\n",
    "        return torch.pow((1 - tversky), self.gamma)\n",
    "\n",
    "class ComboLossTF(nn.Module):\n",
    "    def __init__(self, bce_weight=0.33, dice_weight=0.33, focal_twersky_weight=0.33):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.dice = DiceLoss(smooth=1e-6)\n",
    "        self.FW = FocalTverskyLoss (alpha = 0.92, gamma=3.1)\n",
    "        self.bw, self.dw, self.fw = bce_weight, dice_weight, focal_twersky_weight\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        # preds, targets both (B,1,H,W)\n",
    "        total_loss = 0\n",
    "        if self.bw > 0:\n",
    "            l_bce = self.bce(preds, targets)\n",
    "            total_loss += self.bw * l_bce\n",
    "        if self.dw > 0:\n",
    "            l_dice = self.dice(preds, targets)\n",
    "            total_loss += self.dw * l_dice\n",
    "        if self.fw > 0:\n",
    "            l_focal_tversky = self.FW(preds, targets)\n",
    "            total_loss += self.fw * l_focal_tversky\n",
    "        return total_loss"
   ],
   "id": "4668bc53416e595c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:49:59.420982Z",
     "start_time": "2025-06-10T19:49:59.417494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigzi(x, axis=None):\n",
    "    \"\"\"\n",
    "Compute the interquartile range (IQR) of x along the specified axis.\n",
    "    Args:\n",
    "        x: array-like, shape (P, H, W) or (H, W) or (N, C, H, W)\n",
    "        axis: axis along which to compute the IQR.\n",
    "              If None, computes over the flattened array.\n",
    "\n",
    "    Returns: float, the IQR of x.\n",
    "\n",
    "    \"\"\"\n",
    "    return 0.741 * (np.percentile(x, 75, axis=axis) - np.percentile(x, 25, axis=axis))\n",
    "\n",
    "def split_stack(arr, nrows, ncols):\n",
    "    \"\"\"\n",
    "    Split a stack of 2D panels into (nrows × ncols) tiles.\n",
    "    arr: ndarray, shape (P, H, W)\n",
    "    Returns: ndarray, shape (P * (H//nrows)*(W//ncols), nrows, ncols)\n",
    "    \"\"\"\n",
    "    P, H, W = arr.shape\n",
    "    pad_h = (-H) % nrows\n",
    "    pad_w = (-W) % ncols\n",
    "    if pad_h or pad_w:\n",
    "        arr = np.pad(arr,\n",
    "                     ((0, 0),\n",
    "                      (0, pad_h),\n",
    "                      (0, pad_w)),\n",
    "                     mode='constant',\n",
    "                     constant_values=0)\n",
    "    H2, W2 = arr.shape[1], arr.shape[2]\n",
    "    blocks = (arr\n",
    "              .reshape(P,\n",
    "                       H2 // nrows, nrows,\n",
    "                       W2 // ncols, ncols)\n",
    "              .swapaxes(2, 3))\n",
    "    P2, Hb, Wb, nr, nc = blocks.shape\n",
    "    out = blocks.reshape(P2 * Hb * Wb, nr, nc)\n",
    "    return out\n",
    "\n",
    "def build_datasets(npz_file, tile_size=128):\n",
    "    \"\"\"\n",
    "    Load data from .npz, clip exactly as TF did, split into tiles, return PyTorch tensors.\n",
    "      - Clips x to [-166.43, 169.96]\n",
    "      - Splits each large image into (tile_size × tile_size) patches\n",
    "      - Adds a channel dimension (→ shape (N, 1, tile_size, tile_size))\n",
    "    \"\"\"\n",
    "    data = np.load(npz_file)\n",
    "    x = data['x']  # shape (P, H, W)\n",
    "    y = data['y']\n",
    "\n",
    "    x = x/sigzi(x)  # normalize by interquartile range\n",
    "    x = np.clip(x, -7, 7) # clip to [-5, 5]\n",
    "\n",
    "    # Split into tiles (tile_size × tile_size)\n",
    "    x_tiles = split_stack(x, tile_size, tile_size)  # (N_tiles, tile_size, tile_size)\n",
    "    y_tiles = split_stack(y, tile_size, tile_size)\n",
    "\n",
    "    # Convert to FloatTensor and add channel dimension\n",
    "    x_tiles = torch.from_numpy(x_tiles).float().unsqueeze(1)  # (N, 1, tile_size, tile_size)\n",
    "    y_tiles = torch.from_numpy(y_tiles).float().unsqueeze(1)  # (N, 1, tile_size, tile_size)\n",
    "\n",
    "    return x_tiles, y_tiles\n",
    "\n",
    "def reshape_masks(masks, new_size):\n",
    "    \"\"\"\n",
    "    Resize binary masks (0/1) to `new_size`:\n",
    "      - Uses bilinear interpolation (same as TF’s tf.image.resize with bilinear)\n",
    "      - Applies torch.ceil(...) to recover {0,1} values exactly.\n",
    "    Input:\n",
    "      - masks: either a Tensor of shape (N, 1, H_orig, W_orig)\n",
    "               or a numpy array of shape (N, H_orig, W_orig)\n",
    "      - new_size: tuple (new_H, new_W)\n",
    "    Returns:\n",
    "      - Tensor of shape (N, 1, new_H, new_W), values in {0,1}\n",
    "    \"\"\"\n",
    "    if isinstance(masks, np.ndarray):\n",
    "        m = torch.from_numpy(masks).float().unsqueeze(1)  # → (N,1,H,W)\n",
    "    else:\n",
    "        m = masks  # assume already FloatTensor (N,1,H,W)\n",
    "    m_resized = F.interpolate(m, size=new_size, mode='bilinear', align_corners=False)\n",
    "    m_resized = torch.ceil(m_resized)\n",
    "    return m_resized.clamp(0, 1)\n",
    "\n",
    "def split_train_val(x_tiles, y_tiles, train_frac=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Shuffle and split x_tiles, y_tiles into two TensorDatasets: train (80%) and val (20%).\n",
    "    \"\"\"\n",
    "    n = x_tiles.shape[0]\n",
    "    idx = torch.randperm(n, generator=torch.Generator().manual_seed(seed))\n",
    "    split = int(train_frac * n)\n",
    "    train_idx = idx[:split]\n",
    "    val_idx   = idx[split:]\n",
    "    train_idx, val_idx = train_idx.sort().values, val_idx.sort().values\n",
    "    x_tr, y_tr = x_tiles[train_idx], y_tiles[train_idx]\n",
    "    x_val, y_val = x_tiles[val_idx], y_tiles[val_idx]\n",
    "    return TensorDataset(x_tr, y_tr), TensorDataset(x_val, y_val)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:50:00.021354Z",
     "start_time": "2025-06-10T19:50:00.016323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_ds, val_ds, epochs=100, batch_size=32, lr=1e-3, device=None):\n",
    "    \"\"\"\n",
    "    Train the model on train_ds, validate on val_ds, and print losses + F1 each epoch.\n",
    "    Resizes all masks to `output_size` so that preds and targets match in spatial dims.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 1) Figure out the model’s output spatial size by pushing a dummy 128×128 patch.\n",
    "    model.eval()  # ensure BatchNorm uses running‐stats, not “batch” stats\n",
    "    with torch.no_grad():\n",
    "        dummy = torch.randn(1, 1, 128, 128).to(device)\n",
    "        out_dummy = model(dummy)\n",
    "        output_size = (out_dummy.shape[-2], out_dummy.shape[-1])  # e.g. (32,32) for your JSON\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=4, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=4, pin_memory=True)\n",
    "\n",
    "    criterion = ComboLossTF(bce_weight=0.0, dice_weight=0.0, focal_twersky_weight=1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                max_lr=lr,\n",
    "                                                steps_per_epoch=len(train_loader),\n",
    "                                                epochs=epochs,\n",
    "                                                pct_start=0.1,\n",
    "                                                anneal_strategy='cos')\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ——— Training ———\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        tp = fp = fn = 0\n",
    "        for batch_num, (imgs, masks) in enumerate(train_loader):\n",
    "            imgs = imgs.to(device)  # (B,1,128,128)\n",
    "\n",
    "            # Resize the ground‐truth masks to output_size (e.g. (32,32))\n",
    "            m_resized = reshape_masks(masks, new_size=output_size).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(imgs)              # (B,1, output_H, output_W)\n",
    "            loss = criterion(preds, m_resized)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            sched.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_bin = (preds > 0.5).float()\n",
    "                t = m_resized\n",
    "                tp += (pred_bin * t).sum().item()\n",
    "                fp += (pred_bin * (1 - t)).sum().item()\n",
    "                fn += ((1 - pred_bin) * t).sum().item()\n",
    "\n",
    "            prec = tp / (tp + fp + 1e-8)\n",
    "            rec  = tp / (tp + fn + 1e-8)\n",
    "            f1   = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "            print (f\"\\rEpoch {epoch:03d}  \"\n",
    "                   f\"Batch {batch_num+1:03d}/{len(train_loader)}  \"\n",
    "                   f\"Batch Loss: {loss.item():.4f}  \"\n",
    "                   f\"| train F1: {f1:.4f}  | train precision: {prec:.4f}  | train recall: {rec:.4f}\", end='\\r')\n",
    "\n",
    "        train_loss = running_loss / len(train_ds)\n",
    "        prec = tp / (tp + fp + 1e-8)\n",
    "        rec  = tp / (tp + fn + 1e-8)\n",
    "        f1   = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "\n",
    "        # ——— Validation ———\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        tp = fp = fn = 0\n",
    "        val_y = []\n",
    "        pred_val = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                m_resized = reshape_masks(masks, new_size=output_size).to(device)\n",
    "                preds = model(imgs)\n",
    "                loss = criterion(preds, m_resized)\n",
    "                val_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "                pred_bin = (preds > 0.5).float()\n",
    "                tp += (pred_bin * m_resized).sum().item()\n",
    "                fp += (pred_bin * (1 - m_resized)).sum().item()\n",
    "                fn += ((1 - pred_bin) * m_resized).sum().item()\n",
    "                val_y.append(m_resized.cpu().numpy())\n",
    "                pred_val.append(preds.cpu().numpy())\n",
    "        # Collect all validation masks for AUC calculation\n",
    "        val_y = np.concatenate(val_y, axis=0)\n",
    "        preds_val = np.concatenate(pred_val, axis=0)  # (N, 1, Hout, Wout)\n",
    "        val_loss = val_loss / len(val_ds)\n",
    "        prec = tp / (tp + fp + 1e-8)\n",
    "        rec  = tp / (tp + fn + 1e-8)\n",
    "        f1_val = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "        auc_val = sklearn.metrics.roc_auc_score(val_y.flatten(), preds_val.flatten() )\n",
    "\n",
    "        print(f\"Epoch {epoch:03d}  \"\n",
    "              f\"Train Loss: {train_loss:.4f}  \"\n",
    "              f\"| Val Loss: {val_loss:.4f}  \"\n",
    "              f\"| Train F1: {f1:.4f}  \"\n",
    "              f\"| Val F1: {f1_val:.4f}  \"\n",
    "              f\"| Val Prec: {prec:.4f}  \"\n",
    "              f\"| Val Rec: {rec:.4f}\"\n",
    "              f\"| Val AUC: {auc_val:.4f}\")\n",
    "\n",
    "    return model"
   ],
   "id": "b42c2e411098d4b5",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:38:56.029359Z",
     "start_time": "2025-06-10T19:37:41.424579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "npz_file = \"../DATA/train.npz\"\n",
    "x_tiles, y_tiles = build_datasets(npz_file, tile_size=128)\n",
    "train_ds, val_ds = split_train_val(x_tiles, y_tiles, train_frac=0.8, seed=42)\n",
    "del x_tiles, y_tiles"
   ],
   "id": "cdca56a2e5d4e6d2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-06-10T21:58:39.503754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "down_filters     = [32, 64, 128, 256, 512]\n",
    "down_activations = ['relu', 'sigmoid', 'relu', 'relu', 'relu']\n",
    "\n",
    "up_filters       = [512, 256, 128]\n",
    "up_activations   = ['relu', 'relu', 'relu']\n",
    "\n",
    "model = UNet(\n",
    "        down_filters=down_filters,\n",
    "        down_activations=down_activations,\n",
    "        up_filters=up_filters,\n",
    "        up_activations=up_activations,\n",
    "        bottleneck_transformer=False,\n",
    "        ASPP_blocks=False)\n",
    "\n",
    "\n",
    "trained_model = train_model(model,\n",
    "                            train_ds, val_ds,\n",
    "                            epochs=150,\n",
    "                            batch_size=128,\n",
    "                            lr=0.0015)"
   ],
   "id": "dbe140c0ff8133fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014  Train Loss: 0.5858  | Val Loss: 0.6368  | Train F1: 0.0663  | Val F1: 0.0323  | Val Prec: 0.0168  | Val Rec: 0.4643| Val AUC: 0.7108\n",
      "Epoch 015  Train Loss: 0.5706  | Val Loss: 0.5600  | Train F1: 0.0774  | Val F1: 0.1270  | Val Prec: 0.0810  | Val Rec: 0.2934| Val AUC: 0.6653\n",
      "Epoch 016  Train Loss: 0.5205  | Val Loss: 0.5386  | Train F1: 0.0971  | Val F1: 0.0926  | Val Prec: 0.0533  | Val Rec: 0.3516| Val AUC: 0.6945\n",
      "Epoch 017  Train Loss: 0.5214  | Val Loss: 0.5089  | Train F1: 0.1054  | Val F1: 0.1383  | Val Prec: 0.0871  | Val Rec: 0.3364| Val AUC: 0.6856\n",
      "Epoch 018  Train Loss: 0.4921  | Val Loss: 0.5418  | Train F1: 0.1157  | Val F1: 0.0654  | Val Prec: 0.0357  | Val Rec: 0.3838| Val AUC: 0.6825\n",
      "Epoch 019  Train Loss: 0.4944  | Val Loss: 0.5522  | Train F1: 0.1252  | Val F1: 0.1333  | Val Prec: 0.0854  | Val Rec: 0.3040| Val AUC: 0.6593\n",
      "Epoch 020  Train Loss: 0.5223  | Val Loss: 0.5140  | Train F1: 0.1028  | Val F1: 0.0961  | Val Prec: 0.0552  | Val Rec: 0.3695| Val AUC: 0.6858\n",
      "Epoch 021  Train Loss: 0.4840  | Val Loss: 0.5122  | Train F1: 0.1328  | Val F1: 0.1019  | Val Prec: 0.0589  | Val Rec: 0.3765| Val AUC: 0.6776\n",
      "Epoch 022  Train Loss: 0.4493  | Val Loss: 0.4917  | Train F1: 0.1462  | Val F1: 0.1010  | Val Prec: 0.0578  | Val Rec: 0.3998| Val AUC: 0.6854\n",
      "Epoch 023  Train Loss: 0.4548  | Val Loss: 0.4839  | Train F1: 0.1412  | Val F1: 0.1197  | Val Prec: 0.0710  | Val Rec: 0.3814| Val AUC: 0.6639\n",
      "Epoch 024  Train Loss: 0.4514  | Val Loss: 0.4644  | Train F1: 0.1503  | Val F1: 0.1549  | Val Prec: 0.0977  | Val Rec: 0.3733| Val AUC: 0.6855\n",
      "Epoch 025  Train Loss: 0.4444  | Val Loss: 0.4841  | Train F1: 0.1481  | Val F1: 0.2098  | Val Prec: 0.1518  | Val Rec: 0.3393| Val AUC: 0.6659\n",
      "Epoch 026  Train Loss: 0.4562  | Val Loss: 0.4850  | Train F1: 0.1521  | Val F1: 0.1707  | Val Prec: 0.1136  | Val Rec: 0.3424| Val AUC: 0.7077\n",
      "Epoch 027  Train Loss: 0.4385  | Val Loss: 0.5123  | Train F1: 0.1617  | Val F1: 0.2295  | Val Prec: 0.1869  | Val Rec: 0.2973| Val AUC: 0.6784\n",
      "Epoch 028  Train Loss: 0.4377  | Val Loss: 0.4532  | Train F1: 0.1632  | Val F1: 0.1796  | Val Prec: 0.1195  | Val Rec: 0.3614| Val AUC: 0.6896\n",
      "Epoch 029  Train Loss: 0.4316  | Val Loss: 0.4664  | Train F1: 0.1606  | Val F1: 0.1952  | Val Prec: 0.1338  | Val Rec: 0.3608| Val AUC: 0.6909\n",
      "Epoch 030  Train Loss: 0.4339  | Val Loss: 0.4638  | Train F1: 0.1452  | Val F1: 0.1946  | Val Prec: 0.1336  | Val Rec: 0.3581| Val AUC: 0.6815\n",
      "Epoch 031  Train Loss: 0.3878  | Val Loss: 0.5085  | Train F1: 0.1819  | Val F1: 0.0992  | Val Prec: 0.0572  | Val Rec: 0.3739| Val AUC: 0.6833\n",
      "Epoch 032  Train Loss: 0.4259  | Val Loss: 0.4793  | Train F1: 0.1612  | Val F1: 0.1395  | Val Prec: 0.0859  | Val Rec: 0.3714| Val AUC: 0.6726\n",
      "Epoch 033  Train Loss: 0.4368  | Val Loss: 0.5257  | Train F1: 0.1430  | Val F1: 0.0802  | Val Prec: 0.0448  | Val Rec: 0.3854| Val AUC: 0.6840\n",
      "Epoch 034  Train Loss: 0.4182  | Val Loss: 0.4744  | Train F1: 0.1626  | Val F1: 0.1659  | Val Prec: 0.1069  | Val Rec: 0.3700| Val AUC: 0.6837\n",
      "Epoch 035  Train Loss: 0.3991  | Val Loss: 0.4543  | Train F1: 0.1788  | Val F1: 0.1878  | Val Prec: 0.1264  | Val Rec: 0.3654| Val AUC: 0.6963\n",
      "Epoch 036  Train Loss: 0.4052  | Val Loss: 0.4402  | Train F1: 0.1841  | Val F1: 0.1789  | Val Prec: 0.1174  | Val Rec: 0.3753| Val AUC: 0.6846\n",
      "Epoch 037  Train Loss: 0.3984  | Val Loss: 0.4523  | Train F1: 0.1856  | Val F1: 0.1286  | Val Prec: 0.0764  | Val Rec: 0.4049| Val AUC: 0.7069\n",
      "Epoch 038  Train Loss: 0.4175  | Val Loss: 0.4437  | Train F1: 0.1569  | Val F1: 0.1793  | Val Prec: 0.1169  | Val Rec: 0.3851| Val AUC: 0.6799\n",
      "Epoch 039  Train Loss: 0.3836  | Val Loss: 0.4668  | Train F1: 0.1923  | Val F1: 0.2120  | Val Prec: 0.1501  | Val Rec: 0.3607| Val AUC: 0.6910\n",
      "Epoch 040  Train Loss: 0.3986  | Val Loss: 0.5349  | Train F1: 0.1972  | Val F1: 0.0701  | Val Prec: 0.0385  | Val Rec: 0.3910| Val AUC: 0.6862\n",
      "Epoch 041  Train Loss: 0.3953  | Val Loss: 0.4806  | Train F1: 0.1678  | Val F1: 0.1984  | Val Prec: 0.1397  | Val Rec: 0.3424| Val AUC: 0.6760\n",
      "Epoch 042  Train Loss: 0.3774  | Val Loss: 0.4607  | Train F1: 0.2045  | Val F1: 0.1474  | Val Prec: 0.0911  | Val Rec: 0.3854| Val AUC: 0.6979\n",
      "Epoch 043  Train Loss: 0.3695  | Val Loss: 0.4485  | Train F1: 0.2153  | Val F1: 0.2275  | Val Prec: 0.1643  | Val Rec: 0.3694| Val AUC: 0.6843\n",
      "Epoch 044  Train Loss: 0.3762  | Val Loss: 0.5031  | Train F1: 0.1832  | Val F1: 0.1625  | Val Prec: 0.1073  | Val Rec: 0.3344| Val AUC: 0.6770\n",
      "Epoch 045  Train Loss: 0.4027  | Val Loss: 0.4666  | Train F1: 0.1703  | Val F1: 0.1866  | Val Prec: 0.1273  | Val Rec: 0.3491| Val AUC: 0.6785\n",
      "Epoch 046  Train Loss: 0.3821  | Val Loss: 0.4428  | Train F1: 0.2111  | Val F1: 0.2138  | Val Prec: 0.1494  | Val Rec: 0.3757| Val AUC: 0.6683\n",
      "Epoch 047  Train Loss: 0.3719  | Val Loss: 0.4330  | Train F1: 0.2072  | Val F1: 0.2123  | Val Prec: 0.1466  | Val Rec: 0.3841| Val AUC: 0.6811\n",
      "Epoch 048  Train Loss: 0.3635  | Val Loss: 0.4612  | Train F1: 0.2312  | Val F1: 0.2554  | Val Prec: 0.2028  | Val Rec: 0.3448| Val AUC: 0.6672\n",
      "Epoch 049  Train Loss: 0.3947  | Val Loss: 0.4409  | Train F1: 0.1876  | Val F1: 0.2071  | Val Prec: 0.1441  | Val Rec: 0.3683| Val AUC: 0.6743\n",
      "Epoch 050  Train Loss: 0.3864  | Val Loss: 0.4409  | Train F1: 0.1812  | Val F1: 0.2238  | Val Prec: 0.1611  | Val Rec: 0.3663| Val AUC: 0.6789\n",
      "Epoch 051  Train Loss: 0.3663  | Val Loss: 0.5384  | Train F1: 0.2365  | Val F1: 0.1745  | Val Prec: 0.1248  | Val Rec: 0.2899| Val AUC: 0.6359\n",
      "Epoch 052  Train Loss: 0.3631  | Val Loss: 0.4441  | Train F1: 0.2122  | Val F1: 0.1911  | Val Prec: 0.1277  | Val Rec: 0.3798| Val AUC: 0.6747\n",
      "Epoch 053  Train Loss: 0.3663  | Val Loss: 0.4266  | Train F1: 0.2480  | Val F1: 0.2284  | Val Prec: 0.1626  | Val Rec: 0.3839| Val AUC: 0.6840\n",
      "Epoch 054  Train Loss: 0.3715  | Val Loss: 0.4687  | Train F1: 0.2432  | Val F1: 0.1147  | Val Prec: 0.0668  | Val Rec: 0.4055| Val AUC: 0.6961\n",
      "Epoch 055  Train Loss: 0.3522  | Val Loss: 0.4409  | Train F1: 0.2291  | Val F1: 0.2280  | Val Prec: 0.1654  | Val Rec: 0.3670| Val AUC: 0.6721\n",
      "Epoch 056  Train Loss: 0.3365  | Val Loss: 0.4567  | Train F1: 0.2686  | Val F1: 0.2347  | Val Prec: 0.1726  | Val Rec: 0.3667| Val AUC: 0.6721\n",
      "Epoch 057  Train Loss: 0.3526  | Val Loss: 0.4647  | Train F1: 0.2450  | Val F1: 0.1682  | Val Prec: 0.1083  | Val Rec: 0.3767| Val AUC: 0.6799\n",
      "Epoch 058  Train Loss: 0.3460  | Val Loss: 0.4330  | Train F1: 0.2195  | Val F1: 0.1869  | Val Prec: 0.1225  | Val Rec: 0.3935| Val AUC: 0.6932\n",
      "Epoch 059  Train Loss: 0.3397  | Val Loss: 0.4698  | Train F1: 0.2601  | Val F1: 0.1616  | Val Prec: 0.1037  | Val Rec: 0.3659| Val AUC: 0.6688\n",
      "Epoch 060  Train Loss: 0.3572  | Val Loss: 0.4593  | Train F1: 0.2303  | Val F1: 0.2903  | Val Prec: 0.2530  | Val Rec: 0.3405| Val AUC: 0.6784\n",
      "Epoch 061  Train Loss: 0.3300  | Val Loss: 0.4392  | Train F1: 0.2478  | Val F1: 0.2558  | Val Prec: 0.1968  | Val Rec: 0.3653| Val AUC: 0.6794\n",
      "Epoch 062  Train Loss: 0.3326  | Val Loss: 0.4476  | Train F1: 0.2742  | Val F1: 0.2066  | Val Prec: 0.1434  | Val Rec: 0.3690| Val AUC: 0.6792\n",
      "Epoch 063  Train Loss: 0.3439  | Val Loss: 0.4676  | Train F1: 0.2699  | Val F1: 0.2238  | Val Prec: 0.1645  | Val Rec: 0.3499| Val AUC: 0.6691\n",
      "Epoch 064  Train Loss: 0.3127  | Val Loss: 0.4471  | Train F1: 0.2933  | Val F1: 0.2281  | Val Prec: 0.1657  | Val Rec: 0.3656| Val AUC: 0.6756\n",
      "Epoch 065  Train Loss: 0.3202  | Val Loss: 0.4691  | Train F1: 0.2948  | Val F1: 0.1628  | Val Prec: 0.1042  | Val Rec: 0.3722| Val AUC: 0.6733\n",
      "Epoch 066  Train Loss: 0.3468  | Val Loss: 0.4811  | Train F1: 0.2713  | Val F1: 0.2012  | Val Prec: 0.1414  | Val Rec: 0.3484| Val AUC: 0.6834\n",
      "Epoch 067  Train Loss: 0.3091  | Val Loss: 0.4396  | Train F1: 0.2905  | Val F1: 0.1946  | Val Prec: 0.1314  | Val Rec: 0.3750| Val AUC: 0.6652\n",
      "Epoch 068  Train Loss: 0.3240  | Val Loss: 0.4514  | Train F1: 0.2688  | Val F1: 0.2235  | Val Prec: 0.1617  | Val Rec: 0.3617| Val AUC: 0.6808\n",
      "Epoch 069  Train Loss: 0.3085  | Val Loss: 0.4597  | Train F1: 0.3004  | Val F1: 0.1674  | Val Prec: 0.1074  | Val Rec: 0.3794| Val AUC: 0.6950\n",
      "Epoch 070  Train Loss: 0.2978  | Val Loss: 0.4464  | Train F1: 0.2947  | Val F1: 0.2667  | Val Prec: 0.2120  | Val Rec: 0.3594| Val AUC: 0.6758\n",
      "Epoch 071  Train Loss: 0.3215  | Val Loss: 0.4617  | Train F1: 0.2728  | Val F1: 0.2555  | Val Prec: 0.2000  | Val Rec: 0.3538| Val AUC: 0.6758\n",
      "Epoch 072  Train Loss: 0.3032  | Val Loss: 0.4457  | Train F1: 0.3094  | Val F1: 0.2718  | Val Prec: 0.2192  | Val Rec: 0.3575| Val AUC: 0.6748\n",
      "Epoch 073  Train Loss: 0.2942  | Val Loss: 0.4489  | Train F1: 0.3635  | Val F1: 0.2686  | Val Prec: 0.2149  | Val Rec: 0.3582| Val AUC: 0.6816\n",
      "Epoch 074  Train Loss: 0.3129  | Val Loss: 0.4397  | Train F1: 0.3215  | Val F1: 0.2472  | Val Prec: 0.1858  | Val Rec: 0.3691| Val AUC: 0.6813\n",
      "Epoch 075  Train Loss: 0.3288  | Val Loss: 0.4361  | Train F1: 0.2606  | Val F1: 0.2191  | Val Prec: 0.1532  | Val Rec: 0.3843| Val AUC: 0.6937\n",
      "Epoch 076  Train Loss: 0.2996  | Val Loss: 0.4425  | Train F1: 0.3117  | Val F1: 0.2786  | Val Prec: 0.2289  | Val Rec: 0.3560| Val AUC: 0.6847\n",
      "Epoch 077  Train Loss: 0.2943  | Val Loss: 0.4404  | Train F1: 0.3405  | Val F1: 0.2931  | Val Prec: 0.2480  | Val Rec: 0.3583| Val AUC: 0.6834\n",
      "Epoch 078  Train Loss: 0.3042  | Val Loss: 0.4361  | Train F1: 0.3197  | Val F1: 0.2724  | Val Prec: 0.2146  | Val Rec: 0.3727| Val AUC: 0.6975\n",
      "Epoch 079  Train Loss: 0.2928  | Val Loss: 0.4329  | Train F1: 0.3658  | Val F1: 0.2602  | Val Prec: 0.1997  | Val Rec: 0.3731| Val AUC: 0.6836\n",
      "Epoch 080  Train Loss: 0.2996  | Val Loss: 0.4508  | Train F1: 0.3166  | Val F1: 0.3149  | Val Prec: 0.2856  | Val Rec: 0.3509| Val AUC: 0.6776\n",
      "Epoch 081  Train Loss: 0.2926  | Val Loss: 0.4348  | Train F1: 0.3540  | Val F1: 0.1764  | Val Prec: 0.1132  | Val Rec: 0.3996| Val AUC: 0.6935\n",
      "Epoch 082  Train Loss: 0.2871  | Val Loss: 0.4595  | Train F1: 0.3640  | Val F1: 0.2734  | Val Prec: 0.2225  | Val Rec: 0.3545| Val AUC: 0.6820\n",
      "Epoch 083  Train Loss: 0.2777  | Val Loss: 0.4683  | Train F1: 0.3788  | Val F1: 0.3082  | Val Prec: 0.2815  | Val Rec: 0.3406| Val AUC: 0.6706\n",
      "Epoch 084  Train Loss: 0.2681  | Val Loss: 0.4793  | Train F1: 0.4117  | Val F1: 0.2488  | Val Prec: 0.1958  | Val Rec: 0.3411| Val AUC: 0.6681\n",
      "Epoch 085  Train Loss: 0.3011  | Val Loss: 0.4604  | Train F1: 0.3468  | Val F1: 0.2954  | Val Prec: 0.2561  | Val Rec: 0.3489| Val AUC: 0.6763\n",
      "Epoch 086  Train Loss: 0.2872  | Val Loss: 0.4567  | Train F1: 0.3400  | Val F1: 0.2798  | Val Prec: 0.2319  | Val Rec: 0.3528| Val AUC: 0.6806\n",
      "Epoch 087  Train Loss: 0.2929  | Val Loss: 0.4463  | Train F1: 0.3457  | Val F1: 0.2845  | Val Prec: 0.2400  | Val Rec: 0.3492| Val AUC: 0.6878\n",
      "Epoch 088  Train Loss: 0.2782  | Val Loss: 0.4653  | Train F1: 0.3828  | Val F1: 0.3091  | Val Prec: 0.2860  | Val Rec: 0.3364| Val AUC: 0.6813\n",
      "Epoch 089  Train Loss: 0.2780  | Val Loss: 0.4486  | Train F1: 0.4081  | Val F1: 0.2045  | Val Prec: 0.1404  | Val Rec: 0.3763| Val AUC: 0.6842\n",
      "Epoch 090  Train Loss: 0.2834  | Val Loss: 0.4567  | Train F1: 0.3768  | Val F1: 0.3116  | Val Prec: 0.2846  | Val Rec: 0.3442| Val AUC: 0.6814\n",
      "Epoch 091  Train Loss: 0.2896  | Val Loss: 0.4440  | Train F1: 0.3553  | Val F1: 0.2686  | Val Prec: 0.2149  | Val Rec: 0.3583| Val AUC: 0.6841\n",
      "Epoch 092  Train Loss: 0.2711  | Val Loss: 0.4429  | Train F1: 0.4028  | Val F1: 0.2780  | Val Prec: 0.2272  | Val Rec: 0.3581| Val AUC: 0.6899\n",
      "Epoch 093  Train Loss: 0.2594  | Val Loss: 0.4480  | Train F1: 0.4531  | Val F1: 0.2895  | Val Prec: 0.2457  | Val Rec: 0.3525| Val AUC: 0.6756\n",
      "Epoch 094  Train Loss: 0.2762  | Val Loss: 0.4813  | Train F1: 0.4266  | Val F1: 0.3280  | Val Prec: 0.3284  | Val Rec: 0.3276| Val AUC: 0.6775\n",
      "Epoch 095  Train Loss: 0.2555  | Val Loss: 0.4536  | Train F1: 0.4352  | Val F1: 0.3054  | Val Prec: 0.2701  | Val Rec: 0.3513| Val AUC: 0.6796\n",
      "Epoch 096  Train Loss: 0.2788  | Val Loss: 0.4796  | Train F1: 0.4115  | Val F1: 0.3350  | Val Prec: 0.3400  | Val Rec: 0.3302| Val AUC: 0.6773\n",
      "Epoch 097  Train Loss: 0.2596  | Val Loss: 0.4533  | Train F1: 0.4042  | Val F1: 0.3330  | Val Prec: 0.3218  | Val Rec: 0.3450| Val AUC: 0.6822\n",
      "Epoch 098  Train Loss: 0.2653  | Val Loss: 0.4559  | Train F1: 0.4495  | Val F1: 0.3320  | Val Prec: 0.3252  | Val Rec: 0.3391| Val AUC: 0.6838\n",
      "Epoch 099  Train Loss: 0.2720  | Val Loss: 0.4418  | Train F1: 0.4761  | Val F1: 0.2930  | Val Prec: 0.2503  | Val Rec: 0.3532| Val AUC: 0.6851\n",
      "Epoch 100  Train Loss: 0.2522  | Val Loss: 0.4664  | Train F1: 0.4540  | Val F1: 0.3267  | Val Prec: 0.3176  | Val Rec: 0.3365| Val AUC: 0.6780\n",
      "Epoch 101  Batch 042/647  Batch Loss: 0.1406  | train F1: 0.5573  | train precision: 0.5028  | train recall: 0.6249\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 16\u001B[39m\n\u001B[32m      5\u001B[39m up_activations   = [\u001B[33m'\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m      7\u001B[39m model = UNet(\n\u001B[32m      8\u001B[39m         down_filters=down_filters,\n\u001B[32m      9\u001B[39m         down_activations=down_activations,\n\u001B[32m   (...)\u001B[39m\u001B[32m     12\u001B[39m         bottleneck_transformer=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m     13\u001B[39m         ASPP_blocks=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m trained_model = train_model(model,\n\u001B[32m     17\u001B[39m                             train_ds, val_ds,\n\u001B[32m     18\u001B[39m                             epochs=\u001B[32m150\u001B[39m,\n\u001B[32m     19\u001B[39m                             batch_size=\u001B[32m128\u001B[39m,\n\u001B[32m     20\u001B[39m                             lr=\u001B[32m0.0015\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 51\u001B[39m, in \u001B[36mtrain_model\u001B[39m\u001B[34m(model, train_ds, val_ds, epochs, batch_size, lr, device)\u001B[39m\n\u001B[32m     48\u001B[39m sched.step()\n\u001B[32m     49\u001B[39m optimizer.zero_grad()\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m running_loss += loss.item() * imgs.size(\u001B[32m0\u001B[39m)\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m     54\u001B[39m     pred_bin = (preds > \u001B[32m0.5\u001B[39m).float()\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ],
   "id": "e7f5d5786ef9271",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:31:33.156259Z",
     "start_time": "2025-06-11T00:31:33.019371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_path = \"../DATA/unet_model3.pth\"\n",
    "torch.save(model.state_dict(), save_path)"
   ],
   "id": "754226ac719ba211",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m save_path = \u001B[33m\"\u001B[39m\u001B[33m../DATA/unet_model3.pth\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m torch.save(model.state_dict(), save_path)\n",
      "\u001B[31mNameError\u001B[39m: name 'torch' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "down_filters     = [32, 64, 128, 256, 512]\n",
    "down_activations = ['relu', 'relu', 'relu', 'relu', 'relu']\n",
    "\n",
    "up_filters       = [512, 256, 128]\n",
    "up_activations   = ['relu', 'relu', 'relu']\n",
    "\n",
    "model_loaded = UNet(\n",
    "    down_filters=down_filters,\n",
    "    down_activations=down_activations,\n",
    "    up_filters=up_filters,\n",
    "    up_activations=up_activations\n",
    ")\n",
    "\n",
    "# 2) Load the saved state_dict:\n",
    "checkpoint = torch.load(\"../DATA/unet_model3.pth\", map_location=\"cpu\")\n",
    "model_loaded.load_state_dict(checkpoint)\n",
    "\n",
    "# 3) Put into eval mode (if only doing inference):\n",
    "model_loaded.eval()\n"
   ],
   "id": "e4eaf1e38b6330f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:27:13.939850Z",
     "start_time": "2025-06-11T00:27:13.936935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(model, dataset, batch_size=32, device=None,\n",
    "                  return_probs: bool = True,  # if False, returns binary masks (0/1)\n",
    "                  threshold: float = 0.5      # threshold for binarization if return_probs=False\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Run inference on `dataset` using `model` and return all predictions.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): trained segmentation model (expects input shape (B,1,128,128) → output (B,1,Hout,Wout)).\n",
    "        dataset (torch.utils.data.Dataset): either\n",
    "            - A TensorDataset of (images, masks), or\n",
    "            - A Dataset that returns just `image` (no mask) if you only want predictions.\n",
    "        batch_size (int): batch size for DataLoader.\n",
    "        device (torch.device or str): 'cuda' or 'cpu'. If None, uses CUDA if available.\n",
    "        return_probs (bool):\n",
    "            - If True, returns the raw sigmoid‐probabilities of shape (N, 1, Hout, Wout).\n",
    "            - If False, thresholds those probabilities at `threshold` and returns binary masks (0/1).\n",
    "        threshold (float): cutoff for turning probability → 0/1 when return_probs=False.\n",
    "\n",
    "    Returns:\n",
    "        preds: numpy array of shape\n",
    "            - (N, 1, Hout, Wout) with float32 probs  in [0,1], if return_probs=True;\n",
    "            - (N, 1, Hout, Wout) with uint8 masks {0,1},       if return_probs=False.\n",
    "\n",
    "    Usage:\n",
    "        # 1) If you have (x_val, y_val) as a TensorDataset and want only predictions:\n",
    "        preds = predict_model(model, TensorDataset(torch.from_numpy(x_val).float(), torch.zeros(len(x_val),1,1,1)),\n",
    "                              batch_size=64, device='cuda', return_probs=False)\n",
    "\n",
    "        # 2) If your dataset yields only images (no masks):\n",
    "        preds = predict_model(model, test_dataset, batch_size=64, device='cuda', return_probs=True)\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # We don’t need real masks during inference, so DataLoader can silently ignore them.\n",
    "    # We'll detect whether dataset returns (img, mask) or just img.\n",
    "    def _collate_fn(batch):\n",
    "        # batch is a list of dataset[i] returns.\n",
    "        # If dataset[i] is a tuple (img, mask), take only img.\n",
    "        if isinstance(batch[0], (list, tuple)):\n",
    "            imgs = torch.stack([item[0] for item in batch], dim=0)\n",
    "        else:\n",
    "            imgs = torch.stack(batch, dim=0)\n",
    "        return imgs\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                        collate_fn=_collate_fn,\n",
    "                        num_workers=4, pin_memory=True)\n",
    "\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in loader:\n",
    "            imgs = imgs.to(device)                     # (B, 1, 128, 128) or similar\n",
    "            probs = model(imgs)                        # (B, 1, Hout, Wout), already in [0,1] due to final Sigmoid\n",
    "            if return_probs:\n",
    "                all_preds.append(probs.cpu())\n",
    "            else:\n",
    "                bin_masks = (probs > threshold).float()  # (B, 1, Hout, Wout) of 0.0 or 1.0\n",
    "                all_preds.append(bin_masks.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0)  # (N, 1, Hout, Wout)\n",
    "    if return_probs:\n",
    "        return all_preds.numpy().astype('float32')\n",
    "    else:\n",
    "        # convert to uint8 (0/1) for easier downstream use\n",
    "        return all_preds.numpy().astype('uint8')\n"
   ],
   "id": "14d55bcde18116e8",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:27:14.624021Z",
     "start_time": "2025-06-11T00:27:14.619996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dataset_to_numpy(dataset, batch_size=64, device=None):\n",
    "    \"\"\"\n",
    "    Given a Dataset that returns either:\n",
    "      - (image_tensor, mask_tensor),  or\n",
    "      - just image_tensor\n",
    "    this function will loop once through the dataset, gather everything,\n",
    "    and return NumPy arrays.\n",
    "\n",
    "    Returns:\n",
    "      If dataset[i] returns (img, mask) for each i, then\n",
    "        imgs_np: shape (N, C, H, W) or whatever\n",
    "        masks_np: shape (N, Cm, Hm, Wm) (e.g. (N,1,128,128))\n",
    "      If dataset[i] returns only img, then\n",
    "        imgs_np: shape (N, C, H, W)\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # We won’t actually move data to GPU here, just stack on CPU at the end.\n",
    "    # But if your dataset does expensive preprocessing on CPU, you can pin_memory=True.\n",
    "\n",
    "    def _collate_fn(batch):\n",
    "        # If each element is (img, mask), we stack only imgs and masks separately.\n",
    "        # But DataLoader collate_fn must return a single tensor; we’ll handle masks in the loop.\n",
    "        # Instead, we return the raw batch list and unpack in the loop below.\n",
    "        return batch\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=_collate_fn,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    imgs_list = []\n",
    "    masks_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            # batch is a list of length `batch_size` (or the remainder on the last batch).\n",
    "            # Each element is either (img, mask) or just img.\n",
    "            first_elem = batch[0]\n",
    "            if isinstance(first_elem, (tuple, list)) and len(first_elem) == 2:\n",
    "                # Dataset returns (img, mask)\n",
    "                imgs = torch.stack([item[0] for item in batch], dim=0)   # (B, C, H, W)\n",
    "                masks = torch.stack([item[1] for item in batch], dim=0)  # (B, Cm, Hm, Wm)\n",
    "                imgs_list.append(imgs.cpu().numpy())\n",
    "                masks_list.append(masks.cpu().numpy())\n",
    "            else:\n",
    "                # Dataset returns only img\n",
    "                imgs = torch.stack(batch, dim=0)  # (B, C, H, W)\n",
    "                imgs_list.append(imgs.cpu().numpy())\n",
    "\n",
    "    imgs_np = np.concatenate(imgs_list, axis=0)\n",
    "    if masks_list:\n",
    "        masks_np = np.concatenate(masks_list, axis=0)\n",
    "        return imgs_np, masks_np\n",
    "    else:\n",
    "        return imgs_np\n",
    "\n",
    "def f2_score_numpy(y_true, y_pred, threshold=0.5, eps=1e-8):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: arrays of the same shape, either (N,H,W) or (N,1,H,W).\n",
    "    threshold: cutoff on y_pred if it’s in [0,1]; if y_pred is already binary, set threshold<0 or skip binarize.\n",
    "    Returns one global F2 (scalar).\n",
    "    \"\"\"\n",
    "    # 1) Binarize predictions (if they’re probabilities)\n",
    "    if y_pred.dtype != np.uint8 and threshold >= 0:\n",
    "        p_bin = (y_pred > threshold).astype(np.uint8)\n",
    "    else:\n",
    "        p_bin = y_pred.astype(np.uint8)\n",
    "\n",
    "    # 2) Similarly ensure y_true is 0/1 uint8\n",
    "    y_bin = y_true.astype(np.uint8)\n",
    "\n",
    "    # 3) Flatten to 1D\n",
    "    if p_bin.ndim == 4 and p_bin.shape[1] == 1:\n",
    "        p_flat = p_bin.squeeze(1).ravel()\n",
    "        y_flat = y_bin.squeeze(1).ravel()\n",
    "    else:\n",
    "        p_flat = p_bin.ravel()\n",
    "        y_flat = y_bin.ravel()\n",
    "\n",
    "    # 4) Compute TP, FP, FN\n",
    "    TP = np.sum((p_flat == 1) & (y_flat == 1))\n",
    "    FP = np.sum((p_flat == 1) & (y_flat == 0))\n",
    "    FN = np.sum((p_flat == 0) & (y_flat == 1))\n",
    "\n",
    "    # 5) Precision = TP / (TP + FP), Recall = TP / (TP + FN)\n",
    "    prec = TP / (TP + FP + eps)\n",
    "    rec  = TP / (TP + FN + eps)\n",
    "\n",
    "    # 6) F2 = 5 * (prec * rec) / (4*prec + rec)\n",
    "    f2 = (1 + 2**2) * (prec * rec) / (2**2 * prec + rec + eps)\n",
    "    return f2"
   ],
   "id": "9025c0e112346b9a",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:27:41.868534Z",
     "start_time": "2025-06-11T00:27:22.829680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p = predict(model, val_ds, batch_size=128, device='cuda', return_probs=True)\n",
    "val_x, val_y = dataset_to_numpy(val_ds, batch_size=128)\n",
    "val_y = reshape_masks(torch.from_numpy(val_y).float(), new_size=(32, 32)).numpy()  # resize to match model output size\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(17, 5))\n",
    "\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(val_y.flatten(), p.flatten())\n",
    "auc_score = sklearn.metrics.auc(fpr, tpr)\n",
    "ax[0].plot(fpr, tpr, label=f'AUC = {auc_score:.4f}')\n",
    "ax[0].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax[0].set_xlabel('False positive rate')\n",
    "ax[0].set_ylabel('True positive rate')\n",
    "ax[0].legend()\n",
    "\n",
    "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(val_y.flatten(), p.flatten())\n",
    "ax[1].plot(precision, recall, label='Precision-Recall curve')\n",
    "ax[1].set_xlabel('Precision')\n",
    "ax[1].set_ylabel('Recall')\n",
    "ax[1].legend()\n",
    "ax[2].plot(thresholds, precision[1:], label='Precision')\n",
    "ax[2].plot(thresholds, recall[1:], label='Recall')\n",
    "ax[2].set_xlabel('Threshold')\n",
    "ax[2].set_ylabel('Score')\n",
    "ax[2].legend()\n",
    "print (f\"F2 score on validation set: {f2_score_numpy(val_y, p, threshold=0.5):.4f}\")"
   ],
   "id": "603238926fbca032",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score on validation set: 0.3296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1700x500 with 3 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T00:28:10.024752Z",
     "start_time": "2025-06-11T00:28:09.998408Z"
    }
   },
   "cell_type": "code",
   "source": "print (f\"F2 score on validation set: {f2_score_numpy(val_y, p, threshold=0.1):.4f}\")",
   "id": "e31f80100bf5ab3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score on validation set: 0.3296\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trained_model = train_model(model,\n",
    "                            train_ds, val_ds,\n",
    "                            epochs=150,\n",
    "                            batch_size=128,\n",
    "                            lr=1e-4)"
   ],
   "id": "29b3acb1925ba38a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "660ef874dd4ccc6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
