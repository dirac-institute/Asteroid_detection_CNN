{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T08:24:25.633612Z",
     "start_time": "2025-06-05T08:24:24.695640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import sklearn"
   ],
   "id": "c757f4099bf6030e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T08:24:25.681121Z",
     "start_time": "2025-06-05T08:24:25.670937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=8):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // ratio, kernel_size=1, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(in_channels // ratio, in_channels, kernel_size=1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.constant_(self.fc1.bias, 0)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, mode='fan_out', nonlinearity='linear')\n",
    "        nn.init.constant_(self.fc2.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.avg_pool(x)        # (B, C, 1, 1)\n",
    "        avg_out = self.fc1(avg_out)       # (B, C//ratio, 1, 1)\n",
    "        avg_out = self.relu(avg_out)\n",
    "        avg_out = self.fc2(avg_out)       # (B, C, 1, 1)\n",
    "\n",
    "        max_out = self.max_pool(x)        # (B, C, 1, 1)\n",
    "        max_out = self.fc1(max_out)       # (B, C//ratio, 1, 1)\n",
    "        max_out = self.relu(max_out)\n",
    "        max_out = self.fc2(max_out)       # (B, C, 1, 1)\n",
    "\n",
    "        out = avg_out + max_out           # (B, C, 1, 1)\n",
    "        scale = self.sigmoid(out)         # (B, C, 1, 1)\n",
    "        return x * scale                  # broadcast along H, W\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        assert kernel_size in (3, 7)\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        nn.init.kaiming_normal_(self.conv.weight, mode='fan_in', nonlinearity='sigmoid')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)     # (B, 1, H, W)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)   # (B, 1, H, W)\n",
    "        concat = torch.cat([avg_out, max_out], dim=1)    # (B, 2, H, W)\n",
    "        attn = self.conv(concat)                         # (B, 1, H, W)\n",
    "        attn = self.sigmoid(attn)\n",
    "        return x * attn                                  # broadcast across C\n",
    "\n",
    "class CBAMBlock(nn.Module):\n",
    "    def __init__(self, in_channels, ratio=8, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.channel_att = ChannelAttention(in_channels, ratio)\n",
    "        self.spatial_att = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.channel_att(x)\n",
    "        x = self.spatial_att(x)\n",
    "        return x\n",
    "\n",
    "class SepConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation, kernel_size, padding, dilation=1):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_ch, in_ch, kernel_size=kernel_size,\n",
    "            padding=padding, dilation=dilation,\n",
    "            groups=in_ch, bias=False\n",
    "        )\n",
    "        self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False)\n",
    "        self.norm = nn.BatchNorm2d(out_ch)\n",
    "        self.act = activation\n",
    "\n",
    "        nn.init.kaiming_normal_(self.depthwise.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.pointwise.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return self.act(self.norm(x))\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation):\n",
    "        super().__init__()\n",
    "        dilations = [1, 2, 3, 4]\n",
    "        kernels   = [1, 3, 5, 7]\n",
    "        self.branches = nn.ModuleList()\n",
    "        for d, k in zip(dilations, kernels):\n",
    "            pad = (k // 2) * d\n",
    "            self.branches.append(\n",
    "                SepConv(in_ch, out_ch, activation, kernel_size=k, padding=pad, dilation=d)\n",
    "            )\n",
    "        self.merge = nn.Sequential(\n",
    "            nn.Conv2d(len(dilations) * out_ch, out_ch, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.merge[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = [branch(x) for branch in self.branches]\n",
    "        x = torch.cat(outs, dim=1)\n",
    "        return self.merge(x)\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation,\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            activation\n",
    "        )\n",
    "        for m in self.block.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        # W_g projects gating signal\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # W_x projects skip connection\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # psi computes 1‐channel attention map\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        nn.init.kaiming_normal_(self.W_g[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.W_x[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.kaiming_normal_(self.psi[0].weight, mode='fan_out', nonlinearity='sigmoid')\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        \"\"\"\n",
    "        g: gating signal from decoder, shape (B, F_g, H, W)\n",
    "        x: skip connection from encoder, shape (B, F_l, H, W)\n",
    "        \"\"\"\n",
    "        g1 = self.W_g(g)   # (B, F_int, H, W)\n",
    "        x1 = self.W_x(x)   # (B, F_int, H, W)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)   # (B, 1, H, W)\n",
    "        return x * psi        # broadcast along channel\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, activation, dropout_prob=0.0, attention=True, pool=True):\n",
    "        super().__init__()\n",
    "        #self.double_conv = DoubleConv(in_ch, out_ch, activation)\n",
    "        self.aspp        = ASPP(in_ch, out_ch, activation)\n",
    "        self.cbam        = CBAMBlock(out_ch, ratio=8, kernel_size=7) if attention else nn.Identity()\n",
    "        self.dropout     = nn.Dropout2d(dropout_prob) if dropout_prob > 0 else nn.Identity()\n",
    "        self.pool        = pool\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.aspp(x)\n",
    "        x = self.cbam(x)\n",
    "        x = self.dropout(x)\n",
    "        skip = x.clone()\n",
    "        if self.pool:\n",
    "            x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        return x, skip\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_ch, skip_ch, out_ch, activation, dropout_prob=0.0, attention=True, upsample=True):\n",
    "        \"\"\"\n",
    "        in_ch:   channels from previous layer (bottleneck or previous decoder)\n",
    "        skip_ch: channels in the corresponding encoder skip\n",
    "        out_ch:  desired output channels for this decoder block\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        self.skip_ch = skip_ch\n",
    "\n",
    "        if self.upsample:\n",
    "            # ConvTranspose2d(in_ch → skip_ch) to match spatial & channel dims\n",
    "            self.up = nn.ConvTranspose2d(in_ch, skip_ch, kernel_size=3,\n",
    "                                         stride=2, padding=1, output_padding=1, bias=False)\n",
    "            nn.init.kaiming_normal_(self.up.weight, mode='fan_out', nonlinearity='relu')\n",
    "            self.bn_up = nn.BatchNorm2d(skip_ch)\n",
    "            self.act_up = activation\n",
    "            self.attention = AttentionGate(F_g=skip_ch, F_l=skip_ch, F_int=skip_ch // 2) if attention else nn.Identity()\n",
    "            in_double = skip_ch * 2\n",
    "        else:\n",
    "            self.up = None\n",
    "            self.bn_up = None\n",
    "            self.act_up = None\n",
    "            self.attention = AttentionGate(F_g=in_ch, F_l=in_ch, F_int=in_ch // 2) if attention else nn.Identity()\n",
    "            in_double = in_ch * 2 if attention else in_ch\n",
    "\n",
    "        #self.double_conv = DoubleConv(in_double, out_ch, activation)\n",
    "        self.aspp        = ASPP(in_ch, out_ch, activation)\n",
    "        self.cbam        = CBAMBlock(out_ch, ratio=8, kernel_size=7) if attention else nn.Identity()\n",
    "        self.dropout     = nn.Dropout2d(dropout_prob) if dropout_prob > 0 else nn.Identity()\n",
    "\n",
    "    def forward(self, x, skip=None):\n",
    "        if self.upsample:\n",
    "            x = self.up(x)       # (B, skip_ch, H*2, W*2)\n",
    "            x = self.bn_up(x)\n",
    "            x = self.act_up(x)\n",
    "        if skip is not None and not isinstance(self.attention, nn.Identity):\n",
    "            skip = self.attention(g=x, x=skip)\n",
    "            x = torch.cat([x, skip], dim=1)  # (B, 2*skip_ch, H*2, W*2)\n",
    "        x = self.aspp(x)\n",
    "        x = self.cbam(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleneckTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes a tensor of shape (B, C, H, W), flattens the H×W patches into tokens,\n",
    "    runs a small TransformerEncoder over them, then reshapes back to (B, C, H, W).\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, heads=8, depth=3, mlp_dim=None):\n",
    "        super().__init__()\n",
    "        mlp_dim = mlp_dim or dim * 4\n",
    "        # one TransformerEncoderLayer (or more, if depth>1)\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim,\n",
    "            nhead=heads,\n",
    "            dim_feedforward=mlp_dim,\n",
    "            activation='relu',\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(layer, num_layers=depth)\n",
    "        self.norm    = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W)\n",
    "        B, C, H, W = x.shape\n",
    "        # flatten spatial dims:\n",
    "        # → (B, C, H*W) then permute to (H*W, B, C) for PyTorch’s MHSA\n",
    "        tokens = x.flatten(2).permute(2, 0, 1)   # (H*W, B, C)\n",
    "        # run through TransformerEncoder\n",
    "        out   = self.encoder(tokens)             # (H*W, B, C)\n",
    "        # put back into (B, C, H, W) after a LayerNorm on each token\n",
    "        out   = out.permute(1, 2, 0).view(B, C, H, W)\n",
    "        return self.norm(out.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
    "        # explanation of the two permutes:\n",
    "        #  - out.permute(1,2,0)→(B, C, H*W) then .view(B, C, H, W)\n",
    "        #  - we want LN over the C‐dimension, so we permute to (B, H, W, C), apply LayerNorm,\n",
    "        #    then back to (B, C, H, W).\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=1,\n",
    "                 out_channels=1,\n",
    "                 down_filters=None,\n",
    "                 down_activations=None,\n",
    "                 up_filters=None,\n",
    "                 up_activations=None):\n",
    "        super().__init__()\n",
    "        assert len(down_filters) == len(down_activations)\n",
    "        assert len(up_filters)   == len(up_activations)\n",
    "\n",
    "        # Build Encoder path\n",
    "        self.encoders = nn.ModuleList()\n",
    "        prev_ch = in_channels\n",
    "        for i, out_ch in enumerate(down_filters):\n",
    "            act_str = down_activations[i].lower()\n",
    "            if act_str == 'relu':\n",
    "                act_fn = nn.ReLU(inplace=True)\n",
    "            elif act_str == 'sigmoid':\n",
    "                act_fn = nn.Sigmoid()\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported encoder activation: {act_str}\")\n",
    "\n",
    "            self.encoders.append(\n",
    "                EncoderBlock(in_ch=prev_ch,\n",
    "                             out_ch=out_ch,\n",
    "                             activation=act_fn,\n",
    "                             dropout_prob=0.1,\n",
    "                             attention=(i != 0),\n",
    "                             pool=True)\n",
    "            )\n",
    "            prev_ch = out_ch\n",
    "\n",
    "        # Bottleneck: DoubleConv(down_filters[-1] → down_filters[-1]*2)\n",
    "        #self.bottleneck = DoubleConv(down_filters[-1], down_filters[-1]*2, nn.ReLU(inplace=True))\n",
    "        self.bottleneck_aspp   = ASPP(down_filters[-1], down_filters[-1]*2, nn.ReLU(inplace=True))\n",
    "        self.bottleneck_trans  = BottleneckTransformer(dim=down_filters[-1]*2,\n",
    "                                                 heads=4,\n",
    "                                                 depth=4,\n",
    "                                                 mlp_dim=down_filters[-1] * 4\n",
    "                                                 )\n",
    "\n",
    "        # Build Decoder path\n",
    "        self.decoders = nn.ModuleList()\n",
    "        N = len(down_filters)\n",
    "        for i, out_ch in enumerate(up_filters):\n",
    "            act_str = up_activations[i].lower()\n",
    "            if act_str == 'relu':\n",
    "                act_fn = nn.ReLU(inplace=True)\n",
    "            elif act_str == 'sigmoid':\n",
    "                act_fn = nn.Sigmoid()\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported decoder activation: {act_str}\")\n",
    "            # Corresponding skip channels from encoder\n",
    "            skip_ch = down_filters[N - 1 - i]\n",
    "            # Input channels for this decoder block\n",
    "            in_ch_dec = (down_filters[-1] * 2) if (i == 0) else up_filters[i - 1]\n",
    "\n",
    "            self.decoders.append(\n",
    "                DecoderBlock(in_ch=in_ch_dec,\n",
    "                             skip_ch=skip_ch,\n",
    "                             out_ch=out_ch,\n",
    "                             activation=act_fn,\n",
    "                             dropout_prob=0.1,\n",
    "                             attention=True,\n",
    "                             upsample=True)\n",
    "            )\n",
    "\n",
    "        # Final 3×3 conv + Sigmoid → 1 channel\n",
    "        self.final_conv = nn.Conv2d(up_filters[-1], out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        nn.init.kaiming_normal_(self.final_conv.weight, mode='fan_out', nonlinearity='sigmoid')\n",
    "        self.final_sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, 128, 128)\n",
    "        skips = []\n",
    "        for enc in self.encoders:\n",
    "            x, skip = enc(x)\n",
    "            skips.append(skip)\n",
    "\n",
    "        #x = self.bottleneck(x)          # (B, 1024, 1, 1)\n",
    "        x = self.bottleneck_aspp(x)\n",
    "        x = self.bottleneck_trans(x)\n",
    "        skips = skips[::-1]              # reverse order for decoding\n",
    "\n",
    "        for i, dec in enumerate(self.decoders):\n",
    "            skip_feat = skips[i]\n",
    "            x = dec(x, skip_feat)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "        x = self.final_sigmoid(x)\n",
    "        return x  # (B, 1, 32, 32) in your JSON case"
   ],
   "id": "6b0ee8133ceb7c68",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T08:24:28.261571Z",
     "start_time": "2025-06-05T08:24:28.258672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        \"\"\"\n",
    "        preds:   Tensor (B,1,H,W) after Sigmoid\n",
    "        targets: Tensor (B,1,H,W) binary {0,1}\n",
    "        \"\"\"\n",
    "        p_flat = preds.view(-1)\n",
    "        t_flat = targets.view(-1)\n",
    "        intersection = (p_flat * t_flat).sum()\n",
    "        dice_coeff = (2. * intersection + self.smooth) / (p_flat.sum() + t_flat.sum() + self.smooth)\n",
    "        return 1 - dice_coeff\n",
    "\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.9, gamma=2.0, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha, self.gamma, self.eps = alpha, gamma, eps\n",
    "        self.beta = 1 - alpha  # Ensure alpha + beta = 1\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        preds = preds.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        TP = (preds * targets).sum()\n",
    "        FP = (preds * (1 - targets)).sum()\n",
    "        FN = ((1 - preds) * targets).sum()\n",
    "        tversky = (TP + self.eps) / (TP + self.alpha*FN + self.beta*FP + self.eps)\n",
    "        return torch.pow((1 - tversky), self.gamma)\n",
    "\n",
    "class ComboLossTF(nn.Module):\n",
    "    def __init__(self, bce_weight=0.33, dice_weight=0.33, focal_twersky_weight=0.33):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCELoss()\n",
    "        self.dice = DiceLoss(smooth=1e-6)\n",
    "        self.FW = FocalTverskyLoss (alpha = 0.99, gamma=2)\n",
    "        self.bw, self.dw, self.fw = bce_weight, dice_weight, focal_twersky_weight\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        # preds, targets both (B,1,H,W)\n",
    "        l_bce = self.bce(preds, targets)\n",
    "        l_dice = self.dice(preds, targets)\n",
    "        l_focal_tversky = self.FW(preds, targets)\n",
    "        return self.bw * l_bce + self.dw * l_dice + self.fw * l_focal_tversky"
   ],
   "id": "4668bc53416e595c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T08:24:29.120867Z",
     "start_time": "2025-06-05T08:24:29.117083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigzi(x, axis=None):\n",
    "    \"\"\"\n",
    "Compute the interquartile range (IQR) of x along the specified axis.\n",
    "    Args:\n",
    "        x: array-like, shape (P, H, W) or (H, W) or (N, C, H, W)\n",
    "        axis: axis along which to compute the IQR.\n",
    "              If None, computes over the flattened array.\n",
    "\n",
    "    Returns: float, the IQR of x.\n",
    "\n",
    "    \"\"\"\n",
    "    return 0.741 * (np.percentile(x, 75, axis=axis) - np.percentile(x, 25, axis=axis))\n",
    "\n",
    "def split_stack(arr, nrows, ncols):\n",
    "    \"\"\"\n",
    "    Split a stack of 2D panels into (nrows × ncols) tiles.\n",
    "    arr: ndarray, shape (P, H, W)\n",
    "    Returns: ndarray, shape (P * (H//nrows)*(W//ncols), nrows, ncols)\n",
    "    \"\"\"\n",
    "    P, H, W = arr.shape\n",
    "    pad_h = (-H) % nrows\n",
    "    pad_w = (-W) % ncols\n",
    "    if pad_h or pad_w:\n",
    "        arr = np.pad(arr,\n",
    "                     ((0, 0),\n",
    "                      (0, pad_h),\n",
    "                      (0, pad_w)),\n",
    "                     mode='constant',\n",
    "                     constant_values=0)\n",
    "    H2, W2 = arr.shape[1], arr.shape[2]\n",
    "    blocks = (arr\n",
    "              .reshape(P,\n",
    "                       H2 // nrows, nrows,\n",
    "                       W2 // ncols, ncols)\n",
    "              .swapaxes(2, 3))\n",
    "    P2, Hb, Wb, nr, nc = blocks.shape\n",
    "    out = blocks.reshape(P2 * Hb * Wb, nr, nc)\n",
    "    return out\n",
    "\n",
    "def build_datasets(npz_file, tile_size=128):\n",
    "    \"\"\"\n",
    "    Load data from .npz, clip exactly as TF did, split into tiles, return PyTorch tensors.\n",
    "      - Clips x to [-166.43, 169.96]\n",
    "      - Splits each large image into (tile_size × tile_size) patches\n",
    "      - Adds a channel dimension (→ shape (N, 1, tile_size, tile_size))\n",
    "    \"\"\"\n",
    "    data = np.load(npz_file)\n",
    "    x = data['x']  # shape (P, H, W)\n",
    "    y = data['y']\n",
    "\n",
    "    x = x/sigzi(x)  # normalize by interquartile range\n",
    "    x = np.clip(x, -5, 5) # clip to [-5, 5]\n",
    "\n",
    "    # Split into tiles (tile_size × tile_size)\n",
    "    x_tiles = split_stack(x, tile_size, tile_size)  # (N_tiles, tile_size, tile_size)\n",
    "    y_tiles = split_stack(y, tile_size, tile_size)\n",
    "\n",
    "    # Convert to FloatTensor and add channel dimension\n",
    "    x_tiles = torch.from_numpy(x_tiles).float().unsqueeze(1)  # (N, 1, tile_size, tile_size)\n",
    "    y_tiles = torch.from_numpy(y_tiles).float().unsqueeze(1)  # (N, 1, tile_size, tile_size)\n",
    "\n",
    "    return x_tiles, y_tiles\n",
    "\n",
    "def reshape_masks(masks, new_size):\n",
    "    \"\"\"\n",
    "    Resize binary masks (0/1) to `new_size`:\n",
    "      - Uses bilinear interpolation (same as TF’s tf.image.resize with bilinear)\n",
    "      - Applies torch.ceil(...) to recover {0,1} values exactly.\n",
    "    Input:\n",
    "      - masks: either a Tensor of shape (N, 1, H_orig, W_orig)\n",
    "               or a numpy array of shape (N, H_orig, W_orig)\n",
    "      - new_size: tuple (new_H, new_W)\n",
    "    Returns:\n",
    "      - Tensor of shape (N, 1, new_H, new_W), values in {0,1}\n",
    "    \"\"\"\n",
    "    if isinstance(masks, np.ndarray):\n",
    "        m = torch.from_numpy(masks).float().unsqueeze(1)  # → (N,1,H,W)\n",
    "    else:\n",
    "        m = masks  # assume already FloatTensor (N,1,H,W)\n",
    "    m_resized = F.interpolate(m, size=new_size, mode='bilinear', align_corners=False)\n",
    "    m_resized = torch.ceil(m_resized)\n",
    "    return m_resized.clamp(0, 1)\n",
    "\n",
    "def split_train_val(x_tiles, y_tiles, train_frac=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Shuffle and split x_tiles, y_tiles into two TensorDatasets: train (80%) and val (20%).\n",
    "    \"\"\"\n",
    "    n = x_tiles.shape[0]\n",
    "    idx = torch.randperm(n, generator=torch.Generator().manual_seed(seed))\n",
    "    split = int(train_frac * n)\n",
    "    train_idx = idx[:split]\n",
    "    val_idx   = idx[split:]\n",
    "    train_idx, val_idx = train_idx.sort().values, val_idx.sort().values\n",
    "    x_tr, y_tr = x_tiles[train_idx], y_tiles[train_idx]\n",
    "    x_val, y_val = x_tiles[val_idx], y_tiles[val_idx]\n",
    "    return TensorDataset(x_tr, y_tr), TensorDataset(x_val, y_val)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T08:24:29.854543Z",
     "start_time": "2025-06-05T08:24:29.849935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_ds, val_ds, epochs=100, batch_size=32, lr=1e-3, device=None):\n",
    "    \"\"\"\n",
    "    Train the model on train_ds, validate on val_ds, and print losses + F1 each epoch.\n",
    "    Resizes all masks to `output_size` so that preds and targets match in spatial dims.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 1) Figure out the model’s output spatial size by pushing a dummy 128×128 patch.\n",
    "    model.eval()  # ensure BatchNorm uses running‐stats, not “batch” stats\n",
    "    with torch.no_grad():\n",
    "        dummy = torch.randn(1, 1, 128, 128).to(device)\n",
    "        out_dummy = model(dummy)\n",
    "        output_size = (out_dummy.shape[-2], out_dummy.shape[-1])  # e.g. (32,32) for your JSON\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=4, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=4, pin_memory=True)\n",
    "\n",
    "    criterion = ComboLossTF(bce_weight=0.2, dice_weight=0.2, focal_twersky_weight=0.6)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                max_lr=lr,\n",
    "                                                steps_per_epoch=len(train_loader),\n",
    "                                                epochs=epochs,\n",
    "                                                pct_start=0.1,\n",
    "                                                anneal_strategy='cos')\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ——— Training ———\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        tp = fp = fn = 0\n",
    "        for batch_num, (imgs, masks) in enumerate(train_loader):\n",
    "            imgs = imgs.to(device)  # (B,1,128,128)\n",
    "\n",
    "            # Resize the ground‐truth masks to output_size (e.g. (32,32))\n",
    "            m_resized = reshape_masks(masks, new_size=output_size).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(imgs)              # (B,1, output_H, output_W)\n",
    "            loss = criterion(preds, m_resized)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            sched.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_bin = (preds > 0.5).float()\n",
    "                t = m_resized\n",
    "                tp += (pred_bin * t).sum().item()\n",
    "                fp += (pred_bin * (1 - t)).sum().item()\n",
    "                fn += ((1 - pred_bin) * t).sum().item()\n",
    "\n",
    "            prec = tp / (tp + fp + 1e-8)\n",
    "            rec  = tp / (tp + fn + 1e-8)\n",
    "            f1   = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "            print (f\"\\rEpoch {epoch:03d}  \"\n",
    "                   f\"Batch {batch_num+1:03d}/{len(train_loader)}  \"\n",
    "                   f\"Batch Loss: {loss.item():.4f}  \"\n",
    "                   f\"| train F1: {f1:.4f}  | train precision: {prec:.4f}  | train recall: {rec:.4f}\", end='\\r')\n",
    "\n",
    "        train_loss = running_loss / len(train_ds)\n",
    "        prec = tp / (tp + fp + 1e-8)\n",
    "        rec  = tp / (tp + fn + 1e-8)\n",
    "        f1   = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "\n",
    "        # ——— Validation ———\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        tp = fp = fn = 0\n",
    "        val_y = []\n",
    "        pred_val = []\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                m_resized = reshape_masks(masks, new_size=output_size).to(device)\n",
    "                preds = model(imgs)\n",
    "                loss = criterion(preds, m_resized)\n",
    "                val_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "                pred_bin = (preds > 0.5).float()\n",
    "                tp += (pred_bin * m_resized).sum().item()\n",
    "                fp += (pred_bin * (1 - m_resized)).sum().item()\n",
    "                fn += ((1 - pred_bin) * m_resized).sum().item()\n",
    "                val_y.append(m_resized.cpu().numpy())\n",
    "                pred_val.append(preds.cpu().numpy())\n",
    "        # Collect all validation masks for AUC calculation\n",
    "        val_y = np.concatenate(val_y, axis=0)\n",
    "        preds_val = np.concatenate(pred_val, axis=0)  # (N, 1, Hout, Wout)\n",
    "        val_loss = val_loss / len(val_ds)\n",
    "        prec = tp / (tp + fp + 1e-8)\n",
    "        rec  = tp / (tp + fn + 1e-8)\n",
    "        f1_val = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "        auc_val = sklearn.metrics.roc_auc_score(val_y.flatten(), preds_val.flatten() )\n",
    "\n",
    "        print(f\"Epoch {epoch:03d}  \"\n",
    "              f\"Train Loss: {train_loss:.4f}  \"\n",
    "              f\"| Val Loss: {val_loss:.4f}  \"\n",
    "              f\"| Train F1: {f1:.4f}  \"\n",
    "              f\"| Val F1: {f1_val:.4f}  \"\n",
    "              f\"| Val Prec: {prec:.4f}  \"\n",
    "              f\"| Val Rec: {rec:.4f}\"\n",
    "              f\"| Val AUC: {auc_val:.4f}\")\n",
    "\n",
    "    return model"
   ],
   "id": "b42c2e411098d4b5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T08:25:49.149386Z",
     "start_time": "2025-06-05T08:24:33.277380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "npz_file = \"../DATA/train.npz\"\n",
    "x_tiles, y_tiles = build_datasets(npz_file, tile_size=128)\n",
    "train_ds, val_ds = split_train_val(x_tiles, y_tiles, train_frac=0.8, seed=42)\n",
    "del x_tiles, y_tiles"
   ],
   "id": "cdca56a2e5d4e6d2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:19:56.198654Z",
     "start_time": "2025-06-05T08:28:08.071530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "down_filters     = [32, 64, 128, 256, 512]\n",
    "down_activations = ['relu', 'relu', 'relu', 'relu', 'relu']\n",
    "\n",
    "up_filters       = [512, 256, 128]\n",
    "up_activations   = ['relu', 'relu', 'relu']\n",
    "\n",
    "model = UNet(\n",
    "        down_filters=down_filters,\n",
    "        down_activations=down_activations,\n",
    "        up_filters=up_filters,\n",
    "        up_activations=up_activations)\n",
    "\n",
    "\n",
    "trained_model = train_model(model,\n",
    "                            train_ds, val_ds,\n",
    "                            epochs=20,\n",
    "                            batch_size=128,\n",
    "                            lr=3e-4)"
   ],
   "id": "dbe140c0ff8133fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001  Train Loss: 0.7161  | Val Loss: 0.6975  | Train F1: 0.0071  | Val F1: 0.0119  | Val Prec: 0.0063  | Val Rec: 0.1114| Val AUC: 0.5643\n",
      "Epoch 002  Train Loss: 0.6355  | Val Loss: 0.5893  | Train F1: 0.0193  | Val F1: 0.0267  | Val Prec: 0.0139  | Val Rec: 0.3658| Val AUC: 0.7020\n",
      "Epoch 003  Train Loss: 0.5684  | Val Loss: 0.5474  | Train F1: 0.0251  | Val F1: 0.0260  | Val Prec: 0.0134  | Val Rec: 0.5000| Val AUC: 0.7465\n",
      "Epoch 004  Train Loss: 0.5517  | Val Loss: 0.5406  | Train F1: 0.0266  | Val F1: 0.0265  | Val Prec: 0.0136  | Val Rec: 0.5109| Val AUC: 0.7496\n",
      "Epoch 005  Train Loss: 0.5373  | Val Loss: 0.5368  | Train F1: 0.0279  | Val F1: 0.0279  | Val Prec: 0.0144  | Val Rec: 0.4909| Val AUC: 0.7536\n",
      "Epoch 006  Train Loss: 0.5336  | Val Loss: 0.5304  | Train F1: 0.0279  | Val F1: 0.0288  | Val Prec: 0.0148  | Val Rec: 0.4992| Val AUC: 0.7718\n",
      "Epoch 007  Train Loss: 0.5349  | Val Loss: 0.5334  | Train F1: 0.0292  | Val F1: 0.0291  | Val Prec: 0.0150  | Val Rec: 0.4938| Val AUC: 0.7579\n",
      "Epoch 008  Train Loss: 0.5258  | Val Loss: 0.5359  | Train F1: 0.0307  | Val F1: 0.0278  | Val Prec: 0.0143  | Val Rec: 0.5095| Val AUC: 0.7598\n",
      "Epoch 009  Train Loss: 0.5129  | Val Loss: 0.5202  | Train F1: 0.0335  | Val F1: 0.0338  | Val Prec: 0.0175  | Val Rec: 0.4832| Val AUC: 0.7717\n",
      "Epoch 010  Train Loss: 0.5121  | Val Loss: 0.5181  | Train F1: 0.0343  | Val F1: 0.0359  | Val Prec: 0.0187  | Val Rec: 0.4742| Val AUC: 0.7741\n",
      "Epoch 011  Train Loss: 0.5008  | Val Loss: 0.5159  | Train F1: 0.0363  | Val F1: 0.0389  | Val Prec: 0.0203  | Val Rec: 0.4572| Val AUC: 0.7773\n",
      "Epoch 012  Train Loss: 0.5023  | Val Loss: 0.5088  | Train F1: 0.0389  | Val F1: 0.0394  | Val Prec: 0.0206  | Val Rec: 0.4751| Val AUC: 0.7802\n",
      "Epoch 013  Train Loss: 0.4906  | Val Loss: 0.5086  | Train F1: 0.0427  | Val F1: 0.0452  | Val Prec: 0.0238  | Val Rec: 0.4492| Val AUC: 0.7837\n",
      "Epoch 014  Train Loss: 0.4822  | Val Loss: 0.5096  | Train F1: 0.0462  | Val F1: 0.0489  | Val Prec: 0.0259  | Val Rec: 0.4290| Val AUC: 0.7809\n",
      "Epoch 015  Train Loss: 0.4806  | Val Loss: 0.5067  | Train F1: 0.0507  | Val F1: 0.0521  | Val Prec: 0.0278  | Val Rec: 0.4258| Val AUC: 0.7820\n",
      "Epoch 016  Train Loss: 0.4822  | Val Loss: 0.5058  | Train F1: 0.0518  | Val F1: 0.0500  | Val Prec: 0.0266  | Val Rec: 0.4324| Val AUC: 0.7821\n",
      "Epoch 017  Train Loss: 0.4746  | Val Loss: 0.5082  | Train F1: 0.0536  | Val F1: 0.0559  | Val Prec: 0.0300  | Val Rec: 0.4146| Val AUC: 0.7804\n",
      "Epoch 018  Train Loss: 0.4720  | Val Loss: 0.5065  | Train F1: 0.0548  | Val F1: 0.0527  | Val Prec: 0.0281  | Val Rec: 0.4270| Val AUC: 0.7804\n",
      "Epoch 019  Train Loss: 0.4630  | Val Loss: 0.5087  | Train F1: 0.0570  | Val F1: 0.0576  | Val Prec: 0.0310  | Val Rec: 0.4099| Val AUC: 0.7796\n",
      "Epoch 020  Train Loss: 0.4721  | Val Loss: 0.5075  | Train F1: 0.0584  | Val F1: 0.0554  | Val Prec: 0.0296  | Val Rec: 0.4185| Val AUC: 0.7798\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:45:54.774486Z",
     "start_time": "2025-06-04T19:45:53.852023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1) pip install torchinfo\n",
    "#    (if you haven’t already)\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "down_filters     = [128, 256, 512]\n",
    "down_activations = ['relu'] * len(down_filters)\n",
    "\n",
    "up_filters       = [512, 256]#down_filters[::-1]  # reverse the down_filters\n",
    "up_activations   = ['relu'] * len(up_filters)\n",
    "\n",
    "# 2) Re‐instantiate your UNet exactly as in your training code:\n",
    "model = UNet(\n",
    "        down_filters=down_filters,\n",
    "        down_activations=down_activations,\n",
    "        up_filters=up_filters,\n",
    "        up_activations=up_activations)\n",
    "\n",
    "# 3) Ask for a summary on a dummy (1×1×128×128) input:\n",
    "_ = summary(\n",
    "    model,\n",
    "    input_size=(128, 1, 128, 128),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    verbose=1\n",
    ")\n"
   ],
   "id": "ead34bf5eaaf1c3e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karlo/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================================================================\n",
      "Layer (type:depth-idx)                             Input Shape               Output Shape              Param #                   Trainable\n",
      "======================================================================================================================================================\n",
      "UNet                                               [128, 1, 128, 128]        [128, 1, 64, 64]          --                        True\n",
      "├─ModuleList: 1-1                                  --                        --                        --                        True\n",
      "│    └─EncoderBlock: 2-1                           [128, 1, 128, 128]        [128, 128, 64, 64]        --                        True\n",
      "│    │    └─ASPP: 3-1                              [128, 1, 128, 128]        [128, 128, 128, 128]      67,412                    True\n",
      "│    │    └─Identity: 3-2                          [128, 128, 128, 128]      [128, 128, 128, 128]      --                        --\n",
      "│    │    └─Dropout2d: 3-3                         [128, 128, 128, 128]      [128, 128, 128, 128]      --                        --\n",
      "│    └─EncoderBlock: 2-2                           [128, 128, 64, 64]        [128, 256, 32, 32]        --                        True\n",
      "│    │    └─ASPP: 3-4                              [128, 128, 64, 64]        [128, 256, 64, 64]        406,528                   True\n",
      "│    │    └─CBAMBlock: 3-5                         [128, 256, 64, 64]        [128, 256, 64, 64]        16,770                    True\n",
      "│    │    └─Dropout2d: 3-6                         [128, 256, 64, 64]        [128, 256, 64, 64]        --                        --\n",
      "│    └─EncoderBlock: 2-3                           [128, 256, 32, 32]        [128, 512, 16, 16]        --                        True\n",
      "│    │    └─ASPP: 3-7                              [128, 256, 32, 32]        [128, 512, 32, 32]        1,599,488                 True\n",
      "│    │    └─CBAMBlock: 3-8                         [128, 512, 32, 32]        [128, 512, 32, 32]        66,210                    True\n",
      "│    │    └─Dropout2d: 3-9                         [128, 512, 32, 32]        [128, 512, 32, 32]        --                        --\n",
      "├─ASPP: 1-2                                        [128, 512, 16, 16]        [128, 1024, 16, 16]       --                        True\n",
      "│    └─ModuleList: 2-10                            --                        --                        (recursive)               True\n",
      "│    │    └─SepConv: 3-10                          [128, 512, 16, 16]        [128, 1024, 16, 16]       526,848                   True\n",
      "│    └─Sequential: 2-11                            --                        --                        (recursive)               True\n",
      "│    │    └─ReLU: 3-11                             [128, 1024, 16, 16]       [128, 1024, 16, 16]       --                        --\n",
      "│    └─ModuleList: 2-10                            --                        --                        (recursive)               True\n",
      "│    │    └─SepConv: 3-12                          [128, 512, 16, 16]        [128, 1024, 16, 16]       530,944                   True\n",
      "│    └─Sequential: 2-11                            --                        --                        (recursive)               True\n",
      "│    │    └─ReLU: 3-13                             [128, 1024, 16, 16]       [128, 1024, 16, 16]       --                        --\n",
      "│    └─ModuleList: 2-10                            --                        --                        (recursive)               True\n",
      "│    │    └─SepConv: 3-14                          [128, 512, 16, 16]        [128, 1024, 16, 16]       539,136                   True\n",
      "│    └─Sequential: 2-11                            --                        --                        (recursive)               True\n",
      "│    │    └─ReLU: 3-15                             [128, 1024, 16, 16]       [128, 1024, 16, 16]       --                        --\n",
      "│    └─ModuleList: 2-10                            --                        --                        (recursive)               True\n",
      "│    │    └─SepConv: 3-16                          [128, 512, 16, 16]        [128, 1024, 16, 16]       551,424                   True\n",
      "│    └─Sequential: 2-11                            --                        --                        (recursive)               True\n",
      "│    │    └─ReLU: 3-17                             [128, 1024, 16, 16]       [128, 1024, 16, 16]       --                        --\n",
      "│    └─Sequential: 2-12                            [128, 4096, 16, 16]       [128, 1024, 16, 16]       --                        True\n",
      "│    │    └─Conv2d: 3-18                           [128, 4096, 16, 16]       [128, 1024, 16, 16]       4,194,304                 True\n",
      "│    │    └─BatchNorm2d: 3-19                      [128, 1024, 16, 16]       [128, 1024, 16, 16]       2,048                     True\n",
      "│    │    └─ReLU: 3-20                             [128, 1024, 16, 16]       [128, 1024, 16, 16]       --                        --\n",
      "├─BottleneckTransformer: 1-3                       [128, 1024, 16, 16]       [128, 1024, 16, 16]       --                        True\n",
      "│    └─TransformerEncoder: 2-13                    [256, 128, 1024]          [256, 128, 1024]          --                        True\n",
      "│    │    └─ModuleList: 3-21                       --                        --                        33,599,488                True\n",
      "│    └─LayerNorm: 2-14                             [128, 16, 16, 1024]       [128, 16, 16, 1024]       2,048                     True\n",
      "├─ModuleList: 1-4                                  --                        --                        --                        True\n",
      "│    └─DecoderBlock: 2-15                          [128, 1024, 16, 16]       [128, 512, 32, 32]        --                        True\n",
      "│    │    └─ConvTranspose2d: 3-22                  [128, 1024, 16, 16]       [128, 512, 32, 32]        4,718,592                 True\n",
      "│    │    └─BatchNorm2d: 3-23                      [128, 512, 32, 32]        [128, 512, 32, 32]        1,024                     True\n",
      "│    │    └─ASPP: 3-24                             --                        --                        (recursive)               True\n",
      "│    │    └─AttentionGate: 3-25                    --                        [128, 512, 32, 32]        263,424                   True\n",
      "│    │    └─ASPP: 3-26                             [128, 1024, 32, 32]       [128, 512, 32, 32]        3,236,864                 True\n",
      "│    │    └─CBAMBlock: 3-27                        [128, 512, 32, 32]        [128, 512, 32, 32]        66,210                    True\n",
      "│    │    └─Dropout2d: 3-28                        [128, 512, 32, 32]        [128, 512, 32, 32]        --                        --\n",
      "│    └─DecoderBlock: 2-16                          [128, 512, 32, 32]        [128, 256, 64, 64]        --                        True\n",
      "│    │    └─ConvTranspose2d: 3-29                  [128, 512, 32, 32]        [128, 256, 64, 64]        1,179,648                 True\n",
      "│    │    └─BatchNorm2d: 3-30                      [128, 256, 64, 64]        [128, 256, 64, 64]        512                       True\n",
      "│    │    └─ASPP: 3-31                             --                        --                        (recursive)               True\n",
      "│    │    └─AttentionGate: 3-32                    --                        [128, 256, 64, 64]        66,176                    True\n",
      "│    │    └─ASPP: 3-33                             [128, 512, 64, 64]        [128, 256, 64, 64]        832,000                   True\n",
      "│    │    └─CBAMBlock: 3-34                        [128, 256, 64, 64]        [128, 256, 64, 64]        16,770                    True\n",
      "│    │    └─Dropout2d: 3-35                        [128, 256, 64, 64]        [128, 256, 64, 64]        --                        --\n",
      "├─Conv2d: 1-5                                      [128, 256, 64, 64]        [128, 1, 64, 64]          2,304                     True\n",
      "├─Sigmoid: 1-6                                     [128, 1, 64, 64]          [128, 1, 64, 64]          --                        --\n",
      "======================================================================================================================================================\n",
      "Total params: 52,486,172\n",
      "Trainable params: 52,486,172\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.TERABYTES): 2.94\n",
      "======================================================================================================================================================\n",
      "Input size (MB): 8.39\n",
      "Forward/backward pass size (MB): 85184.61\n",
      "Params size (MB): 142.77\n",
      "Estimated Total Size (MB): 85335.77\n",
      "======================================================================================================================================================\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:44:54.281738Z",
     "start_time": "2025-06-04T19:44:54.186491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "\n"
   ],
   "id": "e7f5d5786ef9271",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_path = \"../DATA/unet_model2.pth\"\n",
    "torch.save(model.state_dict(), save_path)"
   ],
   "id": "754226ac719ba211",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:25:24.738280511Z",
     "start_time": "2025-06-04T07:56:07.478589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_loaded = UNet(\n",
    "    down_filters=[32, 64, 64, 128, 256, 512],\n",
    "    down_activations=['relu', 'sigmoid', 'relu', 'relu', 'sigmoid', 'relu'],\n",
    "    up_filters=[512, 256, 128, 64],\n",
    "    up_activations=['relu', 'sigmoid', 'relu', 'relu'],\n",
    ")\n",
    "\n",
    "# 2) Load the saved state_dict:\n",
    "checkpoint = torch.load(\"../DATA/unet_model2.pth\", map_location=\"cpu\")\n",
    "model_loaded.load_state_dict(checkpoint)\n",
    "\n",
    "# 3) Put into eval mode (if only doing inference):\n",
    "model_loaded.eval()\n"
   ],
   "id": "e4eaf1e38b6330f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (encoders): ModuleList(\n",
       "    (0): EncoderBlock(\n",
       "      (aspp): ASPP(\n",
       "        (branches): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (depthwise): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (pointwise): Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (depthwise): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "            (pointwise): Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (depthwise): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(6, 6), dilation=(3, 3), bias=False)\n",
       "            (pointwise): Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (depthwise): Conv2d(1, 1, kernel_size=(7, 7), stride=(1, 1), padding=(12, 12), dilation=(4, 4), bias=False)\n",
       "            (pointwise): Conv2d(1, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (merge): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): Identity()\n",
       "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): EncoderBlock(\n",
       "      (aspp): ASPP(\n",
       "        (branches): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32, bias=False)\n",
       "            (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Sigmoid()\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=32, bias=False)\n",
       "            (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Sigmoid()\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (depthwise): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(6, 6), dilation=(3, 3), groups=32, bias=False)\n",
       "            (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Sigmoid()\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (depthwise): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(12, 12), dilation=(4, 4), groups=32, bias=False)\n",
       "            (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (merge): Sequential(\n",
       "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): EncoderBlock(\n",
       "      (aspp): ASPP(\n",
       "        (branches): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (depthwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), groups=64, bias=False)\n",
       "            (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=64, bias=False)\n",
       "            (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (depthwise): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(6, 6), dilation=(3, 3), groups=64, bias=False)\n",
       "            (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (depthwise): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(12, 12), dilation=(4, 4), groups=64, bias=False)\n",
       "            (pointwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (merge): Sequential(\n",
       "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): EncoderBlock(\n",
       "      (aspp): ASPP(\n",
       "        (branches): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (depthwise): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), groups=64, bias=False)\n",
       "            (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=64, bias=False)\n",
       "            (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (depthwise): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(6, 6), dilation=(3, 3), groups=64, bias=False)\n",
       "            (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (depthwise): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(12, 12), dilation=(4, 4), groups=64, bias=False)\n",
       "            (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (merge): Sequential(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): EncoderBlock(\n",
       "      (aspp): ASPP(\n",
       "        (branches): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (depthwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), groups=128, bias=False)\n",
       "            (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Sigmoid()\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=128, bias=False)\n",
       "            (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Sigmoid()\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (depthwise): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(6, 6), dilation=(3, 3), groups=128, bias=False)\n",
       "            (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Sigmoid()\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (depthwise): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(12, 12), dilation=(4, 4), groups=128, bias=False)\n",
       "            (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (merge): Sequential(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): EncoderBlock(\n",
       "      (aspp): ASPP(\n",
       "        (branches): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (depthwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256, bias=False)\n",
       "            (pointwise): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=256, bias=False)\n",
       "            (pointwise): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (depthwise): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(6, 6), dilation=(3, 3), groups=256, bias=False)\n",
       "            (pointwise): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (depthwise): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(12, 12), dilation=(4, 4), groups=256, bias=False)\n",
       "            (pointwise): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (merge): Sequential(\n",
       "          (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (bottleneck_aspp): ASPP(\n",
       "    (branches): ModuleList(\n",
       "      (0): SepConv(\n",
       "        (depthwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), groups=512, bias=False)\n",
       "        (pointwise): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): SepConv(\n",
       "        (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=512, bias=False)\n",
       "        (pointwise): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): SepConv(\n",
       "        (depthwise): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(6, 6), dilation=(3, 3), groups=512, bias=False)\n",
       "        (pointwise): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): SepConv(\n",
       "        (depthwise): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(12, 12), dilation=(4, 4), groups=512, bias=False)\n",
       "        (pointwise): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (merge): Sequential(\n",
       "      (0): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (bottleneck_trans): BottleneckTransformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoders): ModuleList(\n",
       "    (0): DecoderBlock(\n",
       "      (up): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (bn_up): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_up): ReLU(inplace=True)\n",
       "      (attention): AttentionGate(\n",
       "        (W_g): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (W_x): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (psi): Sequential(\n",
       "          (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (aspp): ASPP(\n",
       "        (branches): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (depthwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), groups=1024, bias=False)\n",
       "            (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1024, bias=False)\n",
       "            (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (depthwise): Conv2d(1024, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(6, 6), dilation=(3, 3), groups=1024, bias=False)\n",
       "            (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (depthwise): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(12, 12), dilation=(4, 4), groups=1024, bias=False)\n",
       "            (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (merge): Sequential(\n",
       "          (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): DecoderBlock(\n",
       "      (up): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (bn_up): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_up): Sigmoid()\n",
       "      (attention): AttentionGate(\n",
       "        (W_g): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (W_x): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (psi): Sequential(\n",
       "          (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (aspp): ASPP(\n",
       "        (branches): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (depthwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), groups=512, bias=False)\n",
       "            (pointwise): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Sigmoid()\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=512, bias=False)\n",
       "            (pointwise): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Sigmoid()\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (depthwise): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(6, 6), dilation=(3, 3), groups=512, bias=False)\n",
       "            (pointwise): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Sigmoid()\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (depthwise): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(12, 12), dilation=(4, 4), groups=512, bias=False)\n",
       "            (pointwise): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (merge): Sequential(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): DecoderBlock(\n",
       "      (up): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (bn_up): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_up): ReLU(inplace=True)\n",
       "      (attention): AttentionGate(\n",
       "        (W_g): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (W_x): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (psi): Sequential(\n",
       "          (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (aspp): ASPP(\n",
       "        (branches): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (depthwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), groups=256, bias=False)\n",
       "            (pointwise): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=256, bias=False)\n",
       "            (pointwise): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (depthwise): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(6, 6), dilation=(3, 3), groups=256, bias=False)\n",
       "            (pointwise): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (depthwise): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(12, 12), dilation=(4, 4), groups=256, bias=False)\n",
       "            (pointwise): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (merge): Sequential(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): DecoderBlock(\n",
       "      (up): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (bn_up): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act_up): ReLU(inplace=True)\n",
       "      (attention): AttentionGate(\n",
       "        (W_g): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (W_x): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (psi): Sequential(\n",
       "          (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (aspp): ASPP(\n",
       "        (branches): ModuleList(\n",
       "          (0): SepConv(\n",
       "            (depthwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), groups=128, bias=False)\n",
       "            (pointwise): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): SepConv(\n",
       "            (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=128, bias=False)\n",
       "            (pointwise): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SepConv(\n",
       "            (depthwise): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(6, 6), dilation=(3, 3), groups=128, bias=False)\n",
       "            (pointwise): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): SepConv(\n",
       "            (depthwise): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(12, 12), dilation=(4, 4), groups=128, bias=False)\n",
       "            (pointwise): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (merge): Sequential(\n",
       "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cbam): CBAMBlock(\n",
       "        (channel_att): ChannelAttention(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
       "          (fc1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (spatial_att): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (final_sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:22:47.899540Z",
     "start_time": "2025-06-05T09:22:47.896318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(model, dataset, batch_size=32, device=None,\n",
    "                  return_probs: bool = True,  # if False, returns binary masks (0/1)\n",
    "                  threshold: float = 0.5      # threshold for binarization if return_probs=False\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Run inference on `dataset` using `model` and return all predictions.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): trained segmentation model (expects input shape (B,1,128,128) → output (B,1,Hout,Wout)).\n",
    "        dataset (torch.utils.data.Dataset): either\n",
    "            - A TensorDataset of (images, masks), or\n",
    "            - A Dataset that returns just `image` (no mask) if you only want predictions.\n",
    "        batch_size (int): batch size for DataLoader.\n",
    "        device (torch.device or str): 'cuda' or 'cpu'. If None, uses CUDA if available.\n",
    "        return_probs (bool):\n",
    "            - If True, returns the raw sigmoid‐probabilities of shape (N, 1, Hout, Wout).\n",
    "            - If False, thresholds those probabilities at `threshold` and returns binary masks (0/1).\n",
    "        threshold (float): cutoff for turning probability → 0/1 when return_probs=False.\n",
    "\n",
    "    Returns:\n",
    "        preds: numpy array of shape\n",
    "            - (N, 1, Hout, Wout) with float32 probs  in [0,1], if return_probs=True;\n",
    "            - (N, 1, Hout, Wout) with uint8 masks {0,1},       if return_probs=False.\n",
    "\n",
    "    Usage:\n",
    "        # 1) If you have (x_val, y_val) as a TensorDataset and want only predictions:\n",
    "        preds = predict_model(model, TensorDataset(torch.from_numpy(x_val).float(), torch.zeros(len(x_val),1,1,1)),\n",
    "                              batch_size=64, device='cuda', return_probs=False)\n",
    "\n",
    "        # 2) If your dataset yields only images (no masks):\n",
    "        preds = predict_model(model, test_dataset, batch_size=64, device='cuda', return_probs=True)\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # We don’t need real masks during inference, so DataLoader can silently ignore them.\n",
    "    # We'll detect whether dataset returns (img, mask) or just img.\n",
    "    def _collate_fn(batch):\n",
    "        # batch is a list of dataset[i] returns.\n",
    "        # If dataset[i] is a tuple (img, mask), take only img.\n",
    "        if isinstance(batch[0], (list, tuple)):\n",
    "            imgs = torch.stack([item[0] for item in batch], dim=0)\n",
    "        else:\n",
    "            imgs = torch.stack(batch, dim=0)\n",
    "        return imgs\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                        collate_fn=_collate_fn,\n",
    "                        num_workers=4, pin_memory=True)\n",
    "\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in loader:\n",
    "            imgs = imgs.to(device)                     # (B, 1, 128, 128) or similar\n",
    "            probs = model(imgs)                        # (B, 1, Hout, Wout), already in [0,1] due to final Sigmoid\n",
    "            if return_probs:\n",
    "                all_preds.append(probs.cpu())\n",
    "            else:\n",
    "                bin_masks = (probs > threshold).float()  # (B, 1, Hout, Wout) of 0.0 or 1.0\n",
    "                all_preds.append(bin_masks.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0)  # (N, 1, Hout, Wout)\n",
    "    if return_probs:\n",
    "        return all_preds.numpy().astype('float32')\n",
    "    else:\n",
    "        # convert to uint8 (0/1) for easier downstream use\n",
    "        return all_preds.numpy().astype('uint8')\n"
   ],
   "id": "14d55bcde18116e8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:22:48.274208Z",
     "start_time": "2025-06-05T09:22:48.270488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dataset_to_numpy(dataset, batch_size=64, device=None):\n",
    "    \"\"\"\n",
    "    Given a Dataset that returns either:\n",
    "      - (image_tensor, mask_tensor),  or\n",
    "      - just image_tensor\n",
    "    this function will loop once through the dataset, gather everything,\n",
    "    and return NumPy arrays.\n",
    "\n",
    "    Returns:\n",
    "      If dataset[i] returns (img, mask) for each i, then\n",
    "        imgs_np: shape (N, C, H, W) or whatever\n",
    "        masks_np: shape (N, Cm, Hm, Wm) (e.g. (N,1,128,128))\n",
    "      If dataset[i] returns only img, then\n",
    "        imgs_np: shape (N, C, H, W)\n",
    "    \"\"\"\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # We won’t actually move data to GPU here, just stack on CPU at the end.\n",
    "    # But if your dataset does expensive preprocessing on CPU, you can pin_memory=True.\n",
    "\n",
    "    def _collate_fn(batch):\n",
    "        # If each element is (img, mask), we stack only imgs and masks separately.\n",
    "        # But DataLoader collate_fn must return a single tensor; we’ll handle masks in the loop.\n",
    "        # Instead, we return the raw batch list and unpack in the loop below.\n",
    "        return batch\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=_collate_fn,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    imgs_list = []\n",
    "    masks_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            # batch is a list of length `batch_size` (or the remainder on the last batch).\n",
    "            # Each element is either (img, mask) or just img.\n",
    "            first_elem = batch[0]\n",
    "            if isinstance(first_elem, (tuple, list)) and len(first_elem) == 2:\n",
    "                # Dataset returns (img, mask)\n",
    "                imgs = torch.stack([item[0] for item in batch], dim=0)   # (B, C, H, W)\n",
    "                masks = torch.stack([item[1] for item in batch], dim=0)  # (B, Cm, Hm, Wm)\n",
    "                imgs_list.append(imgs.cpu().numpy())\n",
    "                masks_list.append(masks.cpu().numpy())\n",
    "            else:\n",
    "                # Dataset returns only img\n",
    "                imgs = torch.stack(batch, dim=0)  # (B, C, H, W)\n",
    "                imgs_list.append(imgs.cpu().numpy())\n",
    "\n",
    "    imgs_np = np.concatenate(imgs_list, axis=0)\n",
    "    if masks_list:\n",
    "        masks_np = np.concatenate(masks_list, axis=0)\n",
    "        return imgs_np, masks_np\n",
    "    else:\n",
    "        return imgs_np\n",
    "\n",
    "def f2_score_numpy(y_true, y_pred, threshold=0.5, eps=1e-8):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: arrays of the same shape, either (N,H,W) or (N,1,H,W).\n",
    "    threshold: cutoff on y_pred if it’s in [0,1]; if y_pred is already binary, set threshold<0 or skip binarize.\n",
    "    Returns one global F2 (scalar).\n",
    "    \"\"\"\n",
    "    # 1) Binarize predictions (if they’re probabilities)\n",
    "    if y_pred.dtype != np.uint8 and threshold >= 0:\n",
    "        p_bin = (y_pred > threshold).astype(np.uint8)\n",
    "    else:\n",
    "        p_bin = y_pred.astype(np.uint8)\n",
    "\n",
    "    # 2) Similarly ensure y_true is 0/1 uint8\n",
    "    y_bin = y_true.astype(np.uint8)\n",
    "\n",
    "    # 3) Flatten to 1D\n",
    "    if p_bin.ndim == 4 and p_bin.shape[1] == 1:\n",
    "        p_flat = p_bin.squeeze(1).ravel()\n",
    "        y_flat = y_bin.squeeze(1).ravel()\n",
    "    else:\n",
    "        p_flat = p_bin.ravel()\n",
    "        y_flat = y_bin.ravel()\n",
    "\n",
    "    # 4) Compute TP, FP, FN\n",
    "    TP = np.sum((p_flat == 1) & (y_flat == 1))\n",
    "    FP = np.sum((p_flat == 1) & (y_flat == 0))\n",
    "    FN = np.sum((p_flat == 0) & (y_flat == 1))\n",
    "\n",
    "    # 5) Precision = TP / (TP + FP), Recall = TP / (TP + FN)\n",
    "    prec = TP / (TP + FP + eps)\n",
    "    rec  = TP / (TP + FN + eps)\n",
    "\n",
    "    # 6) F2 = 5 * (prec * rec) / (4*prec + rec)\n",
    "    f2 = (1 + 2**2) * (prec * rec) / (2**2 * prec + rec + eps)\n",
    "    return f2"
   ],
   "id": "9025c0e112346b9a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T09:24:03.757514Z",
     "start_time": "2025-06-05T09:22:54.615797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p = predict(model, val_ds, batch_size=128, device='cuda', return_probs=True)\n",
    "val_x, val_y = dataset_to_numpy(val_ds, batch_size=128)\n",
    "val_y = reshape_masks(torch.from_numpy(val_y).float(), new_size=(32, 32)).numpy()  # resize to match model output size\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(17, 5))\n",
    "\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(val_y.flatten(), p.flatten())\n",
    "auc_score = sklearn.metrics.auc(fpr, tpr)\n",
    "ax[0].plot(fpr, tpr, label=f'AUC = {auc_score:.4f}')\n",
    "ax[0].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax[0].set_xlabel('False positive rate')\n",
    "ax[0].set_ylabel('True positive rate')\n",
    "ax[0].legend()\n",
    "\n",
    "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(val_y.flatten(), p.flatten())\n",
    "ax[1].plot(precision, recall, label='Precision-Recall curve')\n",
    "ax[1].set_xlabel('Precision')\n",
    "ax[1].set_ylabel('Recall')\n",
    "ax[1].legend()\n",
    "ax[2].plot(thresholds, precision[1:], label='Precision')\n",
    "ax[2].plot(thresholds, recall[1:], label='Recall')\n",
    "ax[2].set_xlabel('Threshold')\n",
    "ax[2].set_ylabel('Score')\n",
    "ax[2].legend()\n",
    "print (f\"F2 score on validation set: {f2_score_numpy(val_y, p, threshold=0.5):.4f}\")"
   ],
   "id": "603238926fbca032",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score on validation set: 0.1155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karlo/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/IPython/core/events.py:82: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args, **kwargs)\n",
      "/home/karlo/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/IPython/core/pylabtools.py:170: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1700x500 with 3 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T19:25:24.747073652Z",
     "start_time": "2025-06-04T13:29:19.917984Z"
    }
   },
   "cell_type": "code",
   "source": "print (f\"F2 score on validation set: {f2_score_numpy(val_y, p, threshold=0.4):.4f}\")",
   "id": "e31f80100bf5ab3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score on validation set: 0.2971\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T11:22:24.882811Z",
     "start_time": "2025-06-05T09:25:27.055579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trained_model = train_model(model,\n",
    "                            train_ds, val_ds,\n",
    "                            epochs=150,\n",
    "                            batch_size=128,\n",
    "                            lr=1e-4)"
   ],
   "id": "29b3acb1925ba38a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001  Train Loss: 0.4637  | Val Loss: 0.5076  | Train F1: 0.0592  | Val F1: 0.0561  | Val Prec: 0.0301  | Val Rec: 0.4162| Val AUC: 0.7794\n",
      "Epoch 002  Train Loss: 0.4613  | Val Loss: 0.5085  | Train F1: 0.0595  | Val F1: 0.0571  | Val Prec: 0.0307  | Val Rec: 0.4123| Val AUC: 0.7798\n",
      "Epoch 003  Train Loss: 0.4612  | Val Loss: 0.5113  | Train F1: 0.0597  | Val F1: 0.0620  | Val Prec: 0.0336  | Val Rec: 0.3972| Val AUC: 0.7790\n",
      "Epoch 004  Train Loss: 0.4653  | Val Loss: 0.5105  | Train F1: 0.0611  | Val F1: 0.0595  | Val Prec: 0.0321  | Val Rec: 0.4038| Val AUC: 0.7788\n",
      "Epoch 005  Train Loss: 0.4615  | Val Loss: 0.5079  | Train F1: 0.0594  | Val F1: 0.0582  | Val Prec: 0.0313  | Val Rec: 0.4102| Val AUC: 0.7791\n",
      "Epoch 006  Train Loss: 0.4703  | Val Loss: 0.5087  | Train F1: 0.0618  | Val F1: 0.0576  | Val Prec: 0.0310  | Val Rec: 0.4112| Val AUC: 0.7773\n",
      "Epoch 007  Train Loss: 0.4637  | Val Loss: 0.5080  | Train F1: 0.0618  | Val F1: 0.0588  | Val Prec: 0.0317  | Val Rec: 0.4109| Val AUC: 0.7790\n",
      "Epoch 008  Train Loss: 0.4637  | Val Loss: 0.5103  | Train F1: 0.0628  | Val F1: 0.0575  | Val Prec: 0.0309  | Val Rec: 0.4089| Val AUC: 0.7786\n",
      "Epoch 009  Train Loss: 0.4578  | Val Loss: 0.5096  | Train F1: 0.0627  | Val F1: 0.0579  | Val Prec: 0.0312  | Val Rec: 0.4084| Val AUC: 0.7795\n",
      "Epoch 010  Train Loss: 0.4615  | Val Loss: 0.5125  | Train F1: 0.0660  | Val F1: 0.0450  | Val Prec: 0.0237  | Val Rec: 0.4506| Val AUC: 0.7794\n",
      "Epoch 011  Train Loss: 0.4624  | Val Loss: 0.5091  | Train F1: 0.0654  | Val F1: 0.0547  | Val Prec: 0.0293  | Val Rec: 0.4216| Val AUC: 0.7801\n",
      "Epoch 012  Train Loss: 0.4519  | Val Loss: 0.5099  | Train F1: 0.0681  | Val F1: 0.0538  | Val Prec: 0.0287  | Val Rec: 0.4251| Val AUC: 0.7787\n",
      "Epoch 013  Train Loss: 0.4507  | Val Loss: 0.5351  | Train F1: 0.0695  | Val F1: 0.0887  | Val Prec: 0.0514  | Val Rec: 0.3256| Val AUC: 0.7676\n",
      "Epoch 014  Train Loss: 0.4520  | Val Loss: 0.5086  | Train F1: 0.0696  | Val F1: 0.0485  | Val Prec: 0.0257  | Val Rec: 0.4419| Val AUC: 0.7820\n",
      "Epoch 015  Train Loss: 0.4534  | Val Loss: 0.5128  | Train F1: 0.0688  | Val F1: 0.0414  | Val Prec: 0.0216  | Val Rec: 0.4683| Val AUC: 0.7760\n",
      "Epoch 016  Train Loss: 0.4441  | Val Loss: 0.5117  | Train F1: 0.0765  | Val F1: 0.0503  | Val Prec: 0.0268  | Val Rec: 0.4233| Val AUC: 0.7768\n",
      "Epoch 017  Train Loss: 0.4373  | Val Loss: 0.5271  | Train F1: 0.0762  | Val F1: 0.0843  | Val Prec: 0.0479  | Val Rec: 0.3506| Val AUC: 0.7679\n",
      "Epoch 018  Train Loss: 0.4442  | Val Loss: 0.5185  | Train F1: 0.0763  | Val F1: 0.0576  | Val Prec: 0.0310  | Val Rec: 0.4051| Val AUC: 0.7756\n",
      "Epoch 019  Train Loss: 0.4339  | Val Loss: 0.5209  | Train F1: 0.0793  | Val F1: 0.0663  | Val Prec: 0.0364  | Val Rec: 0.3782| Val AUC: 0.7736\n",
      "Epoch 020  Train Loss: 0.4321  | Val Loss: 0.5259  | Train F1: 0.0822  | Val F1: 0.0708  | Val Prec: 0.0392  | Val Rec: 0.3635| Val AUC: 0.7735\n",
      "Epoch 021  Train Loss: 0.4352  | Val Loss: 0.5292  | Train F1: 0.0825  | Val F1: 0.0802  | Val Prec: 0.0453  | Val Rec: 0.3490| Val AUC: 0.7712\n",
      "Epoch 022  Train Loss: 0.4302  | Val Loss: 0.5197  | Train F1: 0.0878  | Val F1: 0.0653  | Val Prec: 0.0357  | Val Rec: 0.3856| Val AUC: 0.7682\n",
      "Epoch 023  Train Loss: 0.4262  | Val Loss: 0.5273  | Train F1: 0.0922  | Val F1: 0.0783  | Val Prec: 0.0440  | Val Rec: 0.3538| Val AUC: 0.7687\n",
      "Epoch 024  Train Loss: 0.4201  | Val Loss: 0.5248  | Train F1: 0.0915  | Val F1: 0.0630  | Val Prec: 0.0344  | Val Rec: 0.3810| Val AUC: 0.7646\n",
      "Epoch 025  Train Loss: 0.4226  | Val Loss: 0.5241  | Train F1: 0.0956  | Val F1: 0.0594  | Val Prec: 0.0321  | Val Rec: 0.3924| Val AUC: 0.7610\n",
      "Epoch 026  Train Loss: 0.4168  | Val Loss: 0.5445  | Train F1: 0.1013  | Val F1: 0.0898  | Val Prec: 0.0521  | Val Rec: 0.3263| Val AUC: 0.7585\n",
      "Epoch 027  Train Loss: 0.4151  | Val Loss: 0.5436  | Train F1: 0.1003  | Val F1: 0.0909  | Val Prec: 0.0527  | Val Rec: 0.3305| Val AUC: 0.7562\n",
      "Epoch 028  Train Loss: 0.4010  | Val Loss: 0.5309  | Train F1: 0.1110  | Val F1: 0.0676  | Val Prec: 0.0372  | Val Rec: 0.3713| Val AUC: 0.7557\n",
      "Epoch 029  Train Loss: 0.4057  | Val Loss: 0.5395  | Train F1: 0.1076  | Val F1: 0.0861  | Val Prec: 0.0494  | Val Rec: 0.3331| Val AUC: 0.7500\n",
      "Epoch 030  Train Loss: 0.3963  | Val Loss: 0.5557  | Train F1: 0.1160  | Val F1: 0.0937  | Val Prec: 0.0552  | Val Rec: 0.3085| Val AUC: 0.7473\n",
      "Epoch 031  Train Loss: 0.3938  | Val Loss: 0.5369  | Train F1: 0.1215  | Val F1: 0.0788  | Val Prec: 0.0444  | Val Rec: 0.3504| Val AUC: 0.7547\n",
      "Epoch 032  Train Loss: 0.3986  | Val Loss: 0.5438  | Train F1: 0.1127  | Val F1: 0.0930  | Val Prec: 0.0544  | Val Rec: 0.3199| Val AUC: 0.7540\n",
      "Epoch 033  Train Loss: 0.4001  | Val Loss: 0.5543  | Train F1: 0.1227  | Val F1: 0.1020  | Val Prec: 0.0613  | Val Rec: 0.3033| Val AUC: 0.7389\n",
      "Epoch 034  Train Loss: 0.3873  | Val Loss: 0.5408  | Train F1: 0.1290  | Val F1: 0.0903  | Val Prec: 0.0523  | Val Rec: 0.3281| Val AUC: 0.7421\n",
      "Epoch 035  Train Loss: 0.3848  | Val Loss: 0.5500  | Train F1: 0.1310  | Val F1: 0.1022  | Val Prec: 0.0613  | Val Rec: 0.3068| Val AUC: 0.7411\n",
      "Epoch 036  Train Loss: 0.3804  | Val Loss: 0.5422  | Train F1: 0.1400  | Val F1: 0.0835  | Val Prec: 0.0477  | Val Rec: 0.3361| Val AUC: 0.7433\n",
      "Epoch 037  Train Loss: 0.3773  | Val Loss: 0.5361  | Train F1: 0.1321  | Val F1: 0.0656  | Val Prec: 0.0360  | Val Rec: 0.3720| Val AUC: 0.7462\n",
      "Epoch 038  Train Loss: 0.3807  | Val Loss: 0.5899  | Train F1: 0.1395  | Val F1: 0.1322  | Val Prec: 0.0908  | Val Rec: 0.2429| Val AUC: 0.7177\n",
      "Epoch 039  Train Loss: 0.3690  | Val Loss: 0.5534  | Train F1: 0.1473  | Val F1: 0.0905  | Val Prec: 0.0530  | Val Rec: 0.3094| Val AUC: 0.7424\n",
      "Epoch 040  Train Loss: 0.3642  | Val Loss: 0.5499  | Train F1: 0.1573  | Val F1: 0.0895  | Val Prec: 0.0519  | Val Rec: 0.3240| Val AUC: 0.7297\n",
      "Epoch 041  Train Loss: 0.3778  | Val Loss: 0.5559  | Train F1: 0.1451  | Val F1: 0.0930  | Val Prec: 0.0547  | Val Rec: 0.3123| Val AUC: 0.7317\n",
      "Epoch 042  Train Loss: 0.3607  | Val Loss: 0.5802  | Train F1: 0.1555  | Val F1: 0.1214  | Val Prec: 0.0784  | Val Rec: 0.2685| Val AUC: 0.7288\n",
      "Epoch 043  Train Loss: 0.3636  | Val Loss: 0.5579  | Train F1: 0.1613  | Val F1: 0.1032  | Val Prec: 0.0622  | Val Rec: 0.3031| Val AUC: 0.7255\n",
      "Epoch 044  Train Loss: 0.3659  | Val Loss: 0.5640  | Train F1: 0.1564  | Val F1: 0.1058  | Val Prec: 0.0645  | Val Rec: 0.2940| Val AUC: 0.7266\n",
      "Epoch 045  Train Loss: 0.3616  | Val Loss: 0.5476  | Train F1: 0.1692  | Val F1: 0.0857  | Val Prec: 0.0493  | Val Rec: 0.3253| Val AUC: 0.7438\n",
      "Epoch 046  Batch 403/647  Batch Loss: 0.1461  | train F1: 0.1788  | train precision: 0.1040  | train recall: 0.6357\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m trained_model = train_model(model,\n\u001B[32m      2\u001B[39m                             train_ds, val_ds,\n\u001B[32m      3\u001B[39m                             epochs=\u001B[32m150\u001B[39m,\n\u001B[32m      4\u001B[39m                             batch_size=\u001B[32m128\u001B[39m,\n\u001B[32m      5\u001B[39m                             lr=\u001B[32m1e-4\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 45\u001B[39m, in \u001B[36mtrain_model\u001B[39m\u001B[34m(model, train_ds, val_ds, epochs, batch_size, lr, device)\u001B[39m\n\u001B[32m     43\u001B[39m preds = model(imgs)              \u001B[38;5;66;03m# (B,1, output_H, output_W)\u001B[39;00m\n\u001B[32m     44\u001B[39m loss = criterion(preds, m_resized)\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m loss.backward()\n\u001B[32m     47\u001B[39m optimizer.step()\n\u001B[32m     48\u001B[39m sched.step()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    638\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m torch.autograd.backward(\n\u001B[32m    649\u001B[39m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs=inputs\n\u001B[32m    650\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    348\u001B[39m     retain_graph = create_graph\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m _engine_run_backward(\n\u001B[32m    354\u001B[39m     tensors,\n\u001B[32m    355\u001B[39m     grad_tensors_,\n\u001B[32m    356\u001B[39m     retain_graph,\n\u001B[32m    357\u001B[39m     create_graph,\n\u001B[32m    358\u001B[39m     inputs,\n\u001B[32m    359\u001B[39m     allow_unreachable=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    360\u001B[39m     accumulate_grad=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    361\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/Asteroid_detection_CNN/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable._execution_engine.run_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    825\u001B[39m         t_outputs, *args, **kwargs\n\u001B[32m    826\u001B[39m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    828\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "660ef874dd4ccc6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
