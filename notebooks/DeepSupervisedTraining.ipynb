{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e083fc",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append(\"../train\")\n",
    "sys.path.append(\"..\")\n",
    "import tools\n",
    "import main as m\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import json\n",
    "from tensorflow.keras import backend as K\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d608877",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def parse_function(img_shape=(128, 128, 1), test=False, deep_outputs=1):\n",
    "    def parsing(example_proto):\n",
    "        keys_to_features = {'x':tf.io.FixedLenFeature(shape=img_shape, dtype=tf.float32),\n",
    "                        'y': tf.io.FixedLenFeature(shape=img_shape, dtype=tf.int64)}\n",
    "        parsed_features = tf.io.parse_single_example(example_proto, keys_to_features)\n",
    "        parsed_features['y'] = tf.cast(parsed_features['y'], tf.float32)\n",
    "        parsed_features['x'] = tf.clip_by_value(parsed_features['x'], -100, 100)\n",
    "        if test:\n",
    "            return parsed_features['x']\n",
    "        else:\n",
    "            targets = tuple([])\n",
    "            for i in range(deep_outputs):\n",
    "                exponent=deep_outputs-i-1\n",
    "                targets=targets+(parsed_features['y'][::2**exponent,::2**exponent],)\n",
    "            return parsed_features['x'], targets\n",
    "    return parsing\n",
    "\n",
    "def get_shape_of_quadratic_image_tfrecord(raw_dataset):\n",
    "    keys_to_features = {'x': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "                        'y': tf.io.VarLenFeature(dtype=tf.int64)}\n",
    "    for i in raw_dataset.take(1):\n",
    "        parsed_features = tf.io.parse_single_example(i, keys_to_features)\n",
    "        return (int(np.sqrt(parsed_features[\"x\"].shape[0])), int(np.sqrt(parsed_features[\"x\"].shape[0])), 1)\n",
    "\n",
    "\n",
    "def custom_loss_sum(losses):\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        loss = 0\n",
    "        for i, l in enumerate(losses):\n",
    "            loss += l(y_true, y_pred)\n",
    "        return loss\n",
    "    return custom_loss\n",
    "\n",
    "class F1_Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.f1 = self.add_weight(name='f1', initializer='zeros')\n",
    "        self.counter = self.add_weight(name='counter', initializer='zeros')\n",
    "        self.precision_fn = tf.keras.metrics.Precision(thresholds=0.5)\n",
    "        self.recall_fn = tf.keras.metrics.Recall(thresholds=0.5)\n",
    "        self.count = self.add_weight(name='F1ScoreCount', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision_fn.reset_state()\n",
    "        self.recall_fn.reset_state()\n",
    "        p = self.precision_fn(y_true, y_pred)\n",
    "        r = self.recall_fn(y_true, y_pred)\n",
    "        self.f1.assign_add(2 * ((p * r) / (p + r + 1e-6)))\n",
    "        self.count.assign_add(1)\n",
    "\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1/self.count\n",
    "\n",
    "    def reset_state(self):\n",
    "        # we also need to reset the state of the precision and recall objects\n",
    "        self.precision_fn.reset_state()\n",
    "        self.recall_fn.reset_state()\n",
    "        self.f1.assign(0)\n",
    "        self.count.assign(0)\n",
    "\n",
    "def get_architecture_from_model(model):\n",
    "    \"\"\"\n",
    "    Extracts the architecture of a model and returns it as a dictionary.\n",
    "    :param model: tensorflow model\n",
    "    :return: dictionary with the architecture\n",
    "    \"\"\"\n",
    "    architecture = {\n",
    "        \"downFilters\":[],\n",
    "        \"downActivation\": [],\n",
    "        \"downDropout\": [],\n",
    "        \"downMaxPool\": [],\n",
    "        \"upFilters\": [],\n",
    "        \"upActivation\": [],\n",
    "        \"upDropout\": []}\n",
    "    for layer in model.layers:\n",
    "        if (\"block\" in layer.name.lower()) and (\"conv1\" in layer.name.lower()):\n",
    "            if layer.name.lower()[0]==\"e\":\n",
    "                architecture[\"downFilters\"].append(layer.filters)\n",
    "                architecture[\"downActivation\"].append(layer.activation.__name__)\n",
    "            elif layer.name.lower()[0]==\"d\":\n",
    "                architecture[\"upFilters\"].append(layer.filters)\n",
    "                architecture[\"upActivation\"].append(layer.activation.__name__)\n",
    "        elif (\"block\" in layer.name.lower()) and (\"drop\" in layer.name.lower()):\n",
    "            if layer.name.lower()[0]==\"e\":\n",
    "                architecture[\"downDropout\"].append(layer.rate)\n",
    "            elif layer.name.lower()[0]==\"d\":\n",
    "                architecture[\"upDropout\"].append(layer.rate)\n",
    "        elif (\"eblock\" in layer.name.lower()) and (\"pool\" in layer.name.lower()):\n",
    "            current_layer = int(layer.name.lower()[6])\n",
    "            if len(architecture[\"downMaxPool\"])<current_layer:\n",
    "                for i in range(current_layer-len(architecture[\"downMaxPool\"])):\n",
    "                    architecture[\"downMaxPool\"].append(False)\n",
    "            architecture[\"downMaxPool\"].append(True)\n",
    "    return architecture\n",
    "def encoder_mini_block(inputs, n_filters=32, activation=\"relu\", dropout_prob=0.3, max_pooling=True, name=\"\"):\n",
    "    \"\"\"\n",
    "    Encoder mini block for U-Net architecture. It consists of two convolutional layers with the same activation function\n",
    "    and number of filters. Optionally, a dropout layer can be added after the second convolutional layer. If max_pooling\n",
    "    is set to True, a max pooling layer is added at the end of the block. The skip connection is the output of the second\n",
    "    convolutional layer.\n",
    "\n",
    "    :param inputs: Input tensor to the block\n",
    "    :param n_filters: Number of filters for the convolutional layers\n",
    "    :param activation: Activation function for the convolutional layers\n",
    "    :param dropout_prob: Dropout probability for the dropout layer (0 means no dropout)\n",
    "    :param max_pooling: Boolean to add a max pooling layer at the end of the block\n",
    "    :param name: Name of the block (Optional)\n",
    "    :return: The output tensor of the block and the skip connection tensor\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.BatchNormalization(name=\"eblock\" + name + \"norm\") (inputs)\n",
    "    conv = tf.keras.layers.Conv2D(n_filters,\n",
    "                                  3,  # filter size\n",
    "                                  activation=activation,\n",
    "                                  padding='same',\n",
    "                                  kernel_initializer='HeNormal',\n",
    "                                  name=\"eblock\" + name + \"conv1\")(inputs)\n",
    "    if dropout_prob > 0:\n",
    "        conv = tf.keras.layers.Dropout(dropout_prob, name=\"eblock\" + name + \"drop\")(conv)\n",
    "    if max_pooling:\n",
    "        next_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name=\"eblock\" + name + \"pool\")(conv)\n",
    "    else:\n",
    "        next_layer = conv\n",
    "    skip_connection = conv\n",
    "    return next_layer, skip_connection\n",
    "\n",
    "\n",
    "def decoder_mini_block(prev_layer_input, skip_layer_input, n_filters=32, activation=\"relu\", dropout_prob=0.3,\n",
    "                       max_pooling=True, name=\"\"):\n",
    "    \"\"\"\n",
    "    Decoder mini block for U-Net architecture that consists of a transposed convolutional layer followed by two\n",
    "    convolutional layers. The skip connection is the concatenation of the transposed convolutional layer and the\n",
    "    corresponding encoder skip connection.\n",
    "\n",
    "    :param prev_layer_input: Input tensor to the block from the previous layer\n",
    "    :param skip_layer_input: Input tensor to the block from the corresponding encoder skip connection\n",
    "    :param n_filters: Number of filters for the convolutional layers\n",
    "    :param activation: Activation function for the convolutional layers\n",
    "    :param name: Name of the block (Optional)\n",
    "    :return: The output tensor of the block\n",
    "    \"\"\"\n",
    "    if max_pooling:\n",
    "        prev_layer_input = tf.keras.layers.Conv2DTranspose(n_filters,\n",
    "                                         (3, 3),\n",
    "                                         strides=(2, 2),\n",
    "                                         padding='same',\n",
    "                                         name=\"dblock\" + name + \"convT\")(prev_layer_input)\n",
    "    merge = tf.keras.layers.concatenate([prev_layer_input, skip_layer_input], axis=-1, name=\"dblock\" + name + \"concat\")\n",
    "    conv = tf.keras.layers.BatchNormalization(name=\"dblock\" + name + \"norm\")(merge)\n",
    "    conv = tf.keras.layers.Conv2D(n_filters,\n",
    "                                  3,  # filter size\n",
    "                                  activation=activation,\n",
    "                                  padding='same',\n",
    "                                  kernel_initializer='HeNormal',\n",
    "                                  name=\"dblock\" + name + \"conv1\")(conv)\n",
    "    if dropout_prob > 0:\n",
    "        conv = tf.keras.layers.Dropout(dropout_prob, name=\"dblock\" + name + \"drop\")(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "def unet_model(input_size, arhitecture, deepSupervised=True):\n",
    "    \"\"\"\n",
    "    U-Net model for semantic segmentation. The model consists of an encoder and a decoder. The encoder downsamples the\n",
    "    input image and extracts features. The decoder upsamples the features and generates the segmentation mask. Skip\n",
    "    connections are used to concatenate the encoder features with the decoder features. The model is created from the\n",
    "    architecture dictionary that contains the number of filters, activation functions, dropout probabilities, and max\n",
    "    pooling for each mini block.\n",
    "\n",
    "    :param input_size: Size of the input image\n",
    "    :param arhitecture: Dictionary containing the architecture of the U-Net model\n",
    "    :return: U-Net model\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.layers.Input(input_size, name=\"input\")\n",
    "    skip_connections = []\n",
    "    layer = inputs\n",
    "    # Encoder\n",
    "    for i in range(len(arhitecture[\"downFilters\"])):\n",
    "        layer, skip = encoder_mini_block(layer,\n",
    "                                         n_filters=arhitecture[\"downFilters\"][i],\n",
    "                                         activation=arhitecture[\"downActivation\"][i],\n",
    "                                         dropout_prob=arhitecture[\"downDropout\"][i],\n",
    "                                         max_pooling=arhitecture[\"downMaxPool\"][i],\n",
    "                                         name=str(i))\n",
    "        skip_connections.append(skip)\n",
    "\n",
    "    # Decoder\n",
    "    outputs=[]\n",
    "    for i in range(len(arhitecture[\"upFilters\"])):\n",
    "        layer = decoder_mini_block(layer,\n",
    "                                   skip_connections[len(arhitecture[\"upFilters\"])-1-i],\n",
    "                                   n_filters=arhitecture[\"upFilters\"][i],\n",
    "                                   activation=arhitecture[\"upActivation\"][i],\n",
    "                                   dropout_prob=arhitecture[\"upDropout\"][i],\n",
    "                                   max_pooling=arhitecture[\"downMaxPool\"][len(arhitecture[\"upFilters\"])-1-i],\n",
    "                                   name=str(len(arhitecture[\"upFilters\"])-1-i))\n",
    "        if deepSupervised:\n",
    "            outputs.append(tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid', name=\"output\"+str(i))(layer))\n",
    "    if not deepSupervised:\n",
    "        outputs = [tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid', name=\"output\")(layer)]\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=outputs, name=\"AsteroidNET\")\n",
    "    return model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84fbf13d",
   "metadata": {},
   "source": [
    "epsilon = 1e-5\n",
    "smooth = 1\n",
    "\n",
    "def tversky(y_true, y_pred):\n",
    "    y_true_pos = K.flatten(y_true)\n",
    "    y_pred_pos = K.flatten(y_pred)\n",
    "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
    "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
    "    alpha = 0.7\n",
    "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true,y_pred)\n",
    "\n",
    "def focal_tversky(y_true,y_pred):\n",
    "    pt_1 = tversky(y_true, y_pred)\n",
    "    gamma = 0.75\n",
    "    return K.pow((1-pt_1), gamma)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdf9fea2",
   "metadata": {},
   "source": [
    "def main (args):\n",
    "    with open(args.arhitecture) as f:\n",
    "        arhitecture = json.load(f)\n",
    "    if \"0\" in arhitecture.keys():\n",
    "        arhitecture = arhitecture[\"0\"]\n",
    "    dataset_train = tf.data.TFRecordDataset([args.train_dataset_path])\n",
    "    tfrecord_shape = tools.model.get_shape_of_quadratic_image_tfrecord(dataset_train)\n",
    "    dataset_train = dataset_train.map(parse_function(img_shape=tfrecord_shape, test=False, \n",
    "                                                                 deep_outputs=len(arhitecture[\"upFilters\"])))\n",
    "    dataset_train = dataset_train.shuffle(5*args.batch_size).batch(args.batch_size).prefetch(2)\n",
    "    dataset_val = tf.data.TFRecordDataset([args.test_dataset_path])\n",
    "    dataset_val = dataset_val.map(parse_function(img_shape=tfrecord_shape, test=False, \n",
    "                                                 deep_outputs=len(arhitecture[\"upFilters\"])))\n",
    "    dataset_val = dataset_val.batch(args.batch_size).prefetch(2)\n",
    "\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    FT = focal_tversky\n",
    "    with mirrored_strategy.scope():\n",
    "        model = unet_model((128, 128, 1), arhitecture)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=args.start_lr), loss=FT,\n",
    "                      metrics=[\"Precision\", \"Recall\", tools.model.F1_Score()])\n",
    "    earlystopping_kb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5*args.decay_lr_patience, verbose=1,\n",
    "                                                        restore_best_weights=True)\n",
    "    terminateonnan_kb = tf.keras.callbacks.TerminateOnNaN()\n",
    "    reducelronplateau_kb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=args.decay_lr_rate,\n",
    "                                                                patience=args.decay_lr_patience, verbose=1)\n",
    "    try:\n",
    "        results = model.fit(dataset_train, epochs=args.epochs, validation_data=dataset_val,\n",
    "                            callbacks=[earlystopping_kb, terminateonnan_kb, reducelronplateau_kb], verbose=1)\n",
    "    except KeyboardInterrupt:\n",
    "        #model.save(args.model_destination)\n",
    "        #print (\"Model saved\")\n",
    "        return model\n",
    "    model.save(args.model_destination)\n",
    "    return model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b90cec41",
   "metadata": {},
   "source": [
    "def parse_arguments(args):\n",
    "    \"\"\"Parse command line arguments.\n",
    "    Args:\n",
    "        args (list): Command line arguments.\n",
    "    Returns:\n",
    "        args (Namespace): Parsed command line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train_dataset_path', type=str,\n",
    "                        default='../DATA/train1.tfrecord',\n",
    "                        help='Path to training dataset.')\n",
    "    parser.add_argument('--test_dataset_path', type=str,\n",
    "                        default='../DATA/test1.tfrecord',\n",
    "                        help='Path to test dataset.')\n",
    "    parser.add_argument('--arhitecture', type=str,\n",
    "                        default=\"../DATA/arhitecture_tuned.json\",\n",
    "                        help='Path to a JSON containing definition of an arhitecture.')\n",
    "    parser.add_argument('--model_destination', type=str,\n",
    "                        default=\"../DATA/Trained_model3\",\n",
    "                        help='Path where to save the model once trained.')\n",
    "    parser.add_argument('--epochs', type=int,\n",
    "                        default=64,\n",
    "                        help='Number of epochs.')\n",
    "    parser.add_argument('--batch_size', type=int,\n",
    "                        default=256,\n",
    "                        help='Batch size.')\n",
    "    parser.add_argument('--class_balancing_alpha', type=float,\n",
    "                        default=0.95,\n",
    "                        help='How much to weight the positive class in the loss function.')\n",
    "    parser.add_argument('--start_lr', type=float,\n",
    "                        default=0.00005,\n",
    "                        help='Initial learning rate.')\n",
    "    parser.add_argument('--decay_lr_rate', type=float,\n",
    "                        default=0.5,\n",
    "                        help='Rate at which to decay the learning rate upon reaching the plateau.')\n",
    "    parser.add_argument('--decay_lr_patience', type=float,\n",
    "                        default=2,\n",
    "                        help='Number of iteration to wait upon reaching the plataeau.')\n",
    "    return parser.parse_args(args)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "132b19ff",
   "metadata": {},
   "source": [
    "args = parse_arguments([])\n",
    "model=main(args)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3640075a",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "model.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89da2a8e",
   "metadata": {},
   "source": [
    "!nvidia-smi"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c77dee75",
   "metadata": {},
   "source": [
    "!ps -up `nvidia-smi -q -x | grep pid | sed -e 's/<pid>//g' -e 's/<\\/pid>//g' -e 's/^[[:space:]]*//'`"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886a065",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST pipeline",
   "language": "python",
   "name": "kmrakovc_lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
