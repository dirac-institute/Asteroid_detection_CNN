{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e083fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append(\"../train\")\n",
    "sys.path.append(\"..\")\n",
    "import tools\n",
    "import main as m\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import json\n",
    "from tensorflow.keras import backend as K\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d608877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def parse_function(img_shape=(128, 128, 1), test=False, deep_outputs=1):\n",
    "    def parsing(example_proto):\n",
    "        keys_to_features = {'x':tf.io.FixedLenFeature(shape=img_shape, dtype=tf.float32),\n",
    "                        'y': tf.io.FixedLenFeature(shape=img_shape, dtype=tf.int64)}\n",
    "        parsed_features = tf.io.parse_single_example(example_proto, keys_to_features)\n",
    "        parsed_features['y'] = tf.cast(parsed_features['y'], tf.float32)\n",
    "        parsed_features['x'] = tf.clip_by_value(parsed_features['x'], -100, 100)\n",
    "        if test:\n",
    "            return parsed_features['x']\n",
    "        else:\n",
    "            targets = tuple([])\n",
    "            for i in range(deep_outputs):\n",
    "                exponent=deep_outputs-i-1\n",
    "                targets=targets+(parsed_features['y'][::2**exponent,::2**exponent],)\n",
    "            return parsed_features['x'], targets\n",
    "    return parsing\n",
    "\n",
    "def get_shape_of_quadratic_image_tfrecord(raw_dataset):\n",
    "    keys_to_features = {'x': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "                        'y': tf.io.VarLenFeature(dtype=tf.int64)}\n",
    "    for i in raw_dataset.take(1):\n",
    "        parsed_features = tf.io.parse_single_example(i, keys_to_features)\n",
    "        return (int(np.sqrt(parsed_features[\"x\"].shape[0])), int(np.sqrt(parsed_features[\"x\"].shape[0])), 1)\n",
    "\n",
    "\n",
    "def custom_loss_sum(losses):\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        loss = 0\n",
    "        for i, l in enumerate(losses):\n",
    "            loss += l(y_true, y_pred)\n",
    "        return loss\n",
    "    return custom_loss\n",
    "\n",
    "class F1_Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.f1 = self.add_weight(name='f1', initializer='zeros')\n",
    "        self.counter = self.add_weight(name='counter', initializer='zeros')\n",
    "        self.precision_fn = tf.keras.metrics.Precision(thresholds=0.5)\n",
    "        self.recall_fn = tf.keras.metrics.Recall(thresholds=0.5)\n",
    "        self.count = self.add_weight(name='F1ScoreCount', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision_fn.reset_state()\n",
    "        self.recall_fn.reset_state()\n",
    "        p = self.precision_fn(y_true, y_pred)\n",
    "        r = self.recall_fn(y_true, y_pred)\n",
    "        self.f1.assign_add(2 * ((p * r) / (p + r + 1e-6)))\n",
    "        self.count.assign_add(1)\n",
    "\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1/self.count\n",
    "\n",
    "    def reset_state(self):\n",
    "        # we also need to reset the state of the precision and recall objects\n",
    "        self.precision_fn.reset_state()\n",
    "        self.recall_fn.reset_state()\n",
    "        self.f1.assign(0)\n",
    "        self.count.assign(0)\n",
    "\n",
    "def get_architecture_from_model(model):\n",
    "    \"\"\"\n",
    "    Extracts the architecture of a model and returns it as a dictionary.\n",
    "    :param model: tensorflow model\n",
    "    :return: dictionary with the architecture\n",
    "    \"\"\"\n",
    "    architecture = {\n",
    "        \"downFilters\":[],\n",
    "        \"downActivation\": [],\n",
    "        \"downDropout\": [],\n",
    "        \"downMaxPool\": [],\n",
    "        \"upFilters\": [],\n",
    "        \"upActivation\": [],\n",
    "        \"upDropout\": []}\n",
    "    for layer in model.layers:\n",
    "        if (\"block\" in layer.name.lower()) and (\"conv1\" in layer.name.lower()):\n",
    "            if layer.name.lower()[0]==\"e\":\n",
    "                architecture[\"downFilters\"].append(layer.filters)\n",
    "                architecture[\"downActivation\"].append(layer.activation.__name__)\n",
    "            elif layer.name.lower()[0]==\"d\":\n",
    "                architecture[\"upFilters\"].append(layer.filters)\n",
    "                architecture[\"upActivation\"].append(layer.activation.__name__)\n",
    "        elif (\"block\" in layer.name.lower()) and (\"drop\" in layer.name.lower()):\n",
    "            if layer.name.lower()[0]==\"e\":\n",
    "                architecture[\"downDropout\"].append(layer.rate)\n",
    "            elif layer.name.lower()[0]==\"d\":\n",
    "                architecture[\"upDropout\"].append(layer.rate)\n",
    "        elif (\"eblock\" in layer.name.lower()) and (\"pool\" in layer.name.lower()):\n",
    "            current_layer = int(layer.name.lower()[6])\n",
    "            if len(architecture[\"downMaxPool\"])<current_layer:\n",
    "                for i in range(current_layer-len(architecture[\"downMaxPool\"])):\n",
    "                    architecture[\"downMaxPool\"].append(False)\n",
    "            architecture[\"downMaxPool\"].append(True)\n",
    "    return architecture\n",
    "def encoder_mini_block(inputs, n_filters=32, activation=\"relu\", dropout_prob=0.3, max_pooling=True, name=\"\"):\n",
    "    \"\"\"\n",
    "    Encoder mini block for U-Net architecture. It consists of two convolutional layers with the same activation function\n",
    "    and number of filters. Optionally, a dropout layer can be added after the second convolutional layer. If max_pooling\n",
    "    is set to True, a max pooling layer is added at the end of the block. The skip connection is the output of the second\n",
    "    convolutional layer.\n",
    "\n",
    "    :param inputs: Input tensor to the block\n",
    "    :param n_filters: Number of filters for the convolutional layers\n",
    "    :param activation: Activation function for the convolutional layers\n",
    "    :param dropout_prob: Dropout probability for the dropout layer (0 means no dropout)\n",
    "    :param max_pooling: Boolean to add a max pooling layer at the end of the block\n",
    "    :param name: Name of the block (Optional)\n",
    "    :return: The output tensor of the block and the skip connection tensor\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.BatchNormalization(name=\"eblock\" + name + \"norm\") (inputs)\n",
    "    conv = tf.keras.layers.Conv2D(n_filters,\n",
    "                                  3,  # filter size\n",
    "                                  activation=activation,\n",
    "                                  padding='same',\n",
    "                                  kernel_initializer='HeNormal',\n",
    "                                  name=\"eblock\" + name + \"conv1\")(inputs)\n",
    "    if dropout_prob > 0:\n",
    "        conv = tf.keras.layers.Dropout(dropout_prob, name=\"eblock\" + name + \"drop\")(conv)\n",
    "    if max_pooling:\n",
    "        next_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name=\"eblock\" + name + \"pool\")(conv)\n",
    "    else:\n",
    "        next_layer = conv\n",
    "    skip_connection = conv\n",
    "    return next_layer, skip_connection\n",
    "\n",
    "\n",
    "def decoder_mini_block(prev_layer_input, skip_layer_input, n_filters=32, activation=\"relu\", dropout_prob=0.3,\n",
    "                       max_pooling=True, name=\"\"):\n",
    "    \"\"\"\n",
    "    Decoder mini block for U-Net architecture that consists of a transposed convolutional layer followed by two\n",
    "    convolutional layers. The skip connection is the concatenation of the transposed convolutional layer and the\n",
    "    corresponding encoder skip connection.\n",
    "\n",
    "    :param prev_layer_input: Input tensor to the block from the previous layer\n",
    "    :param skip_layer_input: Input tensor to the block from the corresponding encoder skip connection\n",
    "    :param n_filters: Number of filters for the convolutional layers\n",
    "    :param activation: Activation function for the convolutional layers\n",
    "    :param name: Name of the block (Optional)\n",
    "    :return: The output tensor of the block\n",
    "    \"\"\"\n",
    "    if max_pooling:\n",
    "        prev_layer_input = tf.keras.layers.Conv2DTranspose(n_filters,\n",
    "                                         (3, 3),\n",
    "                                         strides=(2, 2),\n",
    "                                         padding='same',\n",
    "                                         name=\"dblock\" + name + \"convT\")(prev_layer_input)\n",
    "    merge = tf.keras.layers.concatenate([prev_layer_input, skip_layer_input], axis=-1, name=\"dblock\" + name + \"concat\")\n",
    "    conv = tf.keras.layers.BatchNormalization(name=\"dblock\" + name + \"norm\")(merge)\n",
    "    conv = tf.keras.layers.Conv2D(n_filters,\n",
    "                                  3,  # filter size\n",
    "                                  activation=activation,\n",
    "                                  padding='same',\n",
    "                                  kernel_initializer='HeNormal',\n",
    "                                  name=\"dblock\" + name + \"conv1\")(conv)\n",
    "    if dropout_prob > 0:\n",
    "        conv = tf.keras.layers.Dropout(dropout_prob, name=\"dblock\" + name + \"drop\")(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "def unet_model(input_size, arhitecture, deepSupervised=True):\n",
    "    \"\"\"\n",
    "    U-Net model for semantic segmentation. The model consists of an encoder and a decoder. The encoder downsamples the\n",
    "    input image and extracts features. The decoder upsamples the features and generates the segmentation mask. Skip\n",
    "    connections are used to concatenate the encoder features with the decoder features. The model is created from the\n",
    "    architecture dictionary that contains the number of filters, activation functions, dropout probabilities, and max\n",
    "    pooling for each mini block.\n",
    "\n",
    "    :param input_size: Size of the input image\n",
    "    :param arhitecture: Dictionary containing the architecture of the U-Net model\n",
    "    :return: U-Net model\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.layers.Input(input_size, name=\"input\")\n",
    "    skip_connections = []\n",
    "    layer = inputs\n",
    "    # Encoder\n",
    "    for i in range(len(arhitecture[\"downFilters\"])):\n",
    "        layer, skip = encoder_mini_block(layer,\n",
    "                                         n_filters=arhitecture[\"downFilters\"][i],\n",
    "                                         activation=arhitecture[\"downActivation\"][i],\n",
    "                                         dropout_prob=arhitecture[\"downDropout\"][i],\n",
    "                                         max_pooling=arhitecture[\"downMaxPool\"][i],\n",
    "                                         name=str(i))\n",
    "        skip_connections.append(skip)\n",
    "\n",
    "    # Decoder\n",
    "    outputs=[]\n",
    "    for i in range(len(arhitecture[\"upFilters\"])):\n",
    "        layer = decoder_mini_block(layer,\n",
    "                                   skip_connections[len(arhitecture[\"upFilters\"])-1-i],\n",
    "                                   n_filters=arhitecture[\"upFilters\"][i],\n",
    "                                   activation=arhitecture[\"upActivation\"][i],\n",
    "                                   dropout_prob=arhitecture[\"upDropout\"][i],\n",
    "                                   max_pooling=arhitecture[\"downMaxPool\"][len(arhitecture[\"upFilters\"])-1-i],\n",
    "                                   name=str(len(arhitecture[\"upFilters\"])-1-i))\n",
    "        if deepSupervised:\n",
    "            outputs.append(tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid', name=\"output\"+str(i))(layer))\n",
    "    if not deepSupervised:\n",
    "        outputs = [tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid', name=\"output\")(layer)]\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=outputs, name=\"AsteroidNET\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84fbf13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-5\n",
    "smooth = 1\n",
    "\n",
    "def tversky(y_true, y_pred):\n",
    "    y_true_pos = K.flatten(y_true)\n",
    "    y_pred_pos = K.flatten(y_pred)\n",
    "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
    "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
    "    alpha = 0.7\n",
    "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true,y_pred)\n",
    "\n",
    "def focal_tversky(y_true,y_pred):\n",
    "    pt_1 = tversky(y_true, y_pred)\n",
    "    gamma = 0.75\n",
    "    return K.pow((1-pt_1), gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdf9fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main (args):\n",
    "    with open(args.arhitecture) as f:\n",
    "        arhitecture = json.load(f)\n",
    "    if \"0\" in arhitecture.keys():\n",
    "        arhitecture = arhitecture[\"0\"]\n",
    "    dataset_train = tf.data.TFRecordDataset([args.train_dataset_path])\n",
    "    tfrecord_shape = tools.model.get_shape_of_quadratic_image_tfrecord(dataset_train)\n",
    "    dataset_train = dataset_train.map(parse_function(img_shape=tfrecord_shape, test=False, \n",
    "                                                                 deep_outputs=len(arhitecture[\"upFilters\"])))\n",
    "    dataset_train = dataset_train.shuffle(5*args.batch_size).batch(args.batch_size).prefetch(2)\n",
    "    dataset_val = tf.data.TFRecordDataset([args.test_dataset_path])\n",
    "    dataset_val = dataset_val.map(parse_function(img_shape=tfrecord_shape, test=False, \n",
    "                                                 deep_outputs=len(arhitecture[\"upFilters\"])))\n",
    "    dataset_val = dataset_val.batch(args.batch_size).prefetch(2)\n",
    "\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    FT = focal_tversky\n",
    "    with mirrored_strategy.scope():\n",
    "        model = unet_model((128, 128, 1), arhitecture)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=args.start_lr), loss=FT,\n",
    "                      metrics=[\"Precision\", \"Recall\", tools.model.F1_Score()])\n",
    "    earlystopping_kb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5*args.decay_lr_patience, verbose=1,\n",
    "                                                        restore_best_weights=True)\n",
    "    terminateonnan_kb = tf.keras.callbacks.TerminateOnNaN()\n",
    "    reducelronplateau_kb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=args.decay_lr_rate,\n",
    "                                                                patience=args.decay_lr_patience, verbose=1)\n",
    "    try:\n",
    "        results = model.fit(dataset_train, epochs=args.epochs, validation_data=dataset_val,\n",
    "                            callbacks=[earlystopping_kb, terminateonnan_kb, reducelronplateau_kb], verbose=1)\n",
    "    except KeyboardInterrupt:\n",
    "        #model.save(args.model_destination)\n",
    "        #print (\"Model saved\")\n",
    "        return model\n",
    "    model.save(args.model_destination)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b90cec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments(args):\n",
    "    \"\"\"Parse command line arguments.\n",
    "    Args:\n",
    "        args (list): Command line arguments.\n",
    "    Returns:\n",
    "        args (Namespace): Parsed command line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--train_dataset_path', type=str,\n",
    "                        default='../DATA/train1.tfrecord',\n",
    "                        help='Path to training dataset.')\n",
    "    parser.add_argument('--test_dataset_path', type=str,\n",
    "                        default='../DATA/test1.tfrecord',\n",
    "                        help='Path to test dataset.')\n",
    "    parser.add_argument('--arhitecture', type=str,\n",
    "                        default=\"../DATA/arhitecture_tuned.json\",\n",
    "                        help='Path to a JSON containing definition of an arhitecture.')\n",
    "    parser.add_argument('--model_destination', type=str,\n",
    "                        default=\"../DATA/Trained_model3\",\n",
    "                        help='Path where to save the model once trained.')\n",
    "    parser.add_argument('--epochs', type=int,\n",
    "                        default=64,\n",
    "                        help='Number of epochs.')\n",
    "    parser.add_argument('--batch_size', type=int,\n",
    "                        default=256,\n",
    "                        help='Batch size.')\n",
    "    parser.add_argument('--class_balancing_alpha', type=float,\n",
    "                        default=0.95,\n",
    "                        help='How much to weight the positive class in the loss function.')\n",
    "    parser.add_argument('--start_lr', type=float,\n",
    "                        default=0.00005,\n",
    "                        help='Initial learning rate.')\n",
    "    parser.add_argument('--decay_lr_rate', type=float,\n",
    "                        default=0.5,\n",
    "                        help='Rate at which to decay the learning rate upon reaching the plateau.')\n",
    "    parser.add_argument('--decay_lr_patience', type=float,\n",
    "                        default=2,\n",
    "                        help='Number of iteration to wait upon reaching the plataeau.')\n",
    "    return parser.parse_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "132b19ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "INFO:tensorflow:Collective all_reduce tensors: 60 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Collective all_reduce tensors: 60 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Collective all_reduce tensors: 60 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Collective all_reduce tensors: 60 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 148s 375ms/step - loss: 4.9742 - output0_loss: 0.9980 - output1_loss: 0.9863 - output2_loss: 0.9991 - output3_loss: 0.9942 - output4_loss: 0.9965 - output0_precision_5: 4.9008e-04 - output0_recall_5: 0.5279 - output0_f1_score: 0.0011 - output1_precision_6: 0.0011 - output1_recall_6: 0.5093 - output1_f1_score: 0.0044 - output2_precision_7: 0.0014 - output2_recall_7: 0.4784 - output2_f1_score: 0.0032 - output3_precision_8: 9.8154e-04 - output3_recall_8: 0.7218 - output3_f1_score: 0.0059 - output4_precision_9: 0.0037 - output4_recall_9: 0.5360 - output4_f1_score: 0.0068 - val_loss: 4.8924 - val_output0_loss: 0.9913 - val_output1_loss: 0.9195 - val_output2_loss: 0.9992 - val_output3_loss: 0.9880 - val_output4_loss: 0.9944 - val_output0_precision_5: 3.4908e-04 - val_output0_recall_5: 0.0213 - val_output0_f1_score: 6.1668e-04 - val_output1_precision_6: 0.0000e+00 - val_output1_recall_6: 0.0000e+00 - val_output1_f1_score: 0.0000e+00 - val_output2_precision_7: 0.0076 - val_output2_recall_7: 0.1895 - val_output2_f1_score: 0.0144 - val_output3_precision_8: 0.0068 - val_output3_recall_8: 0.5811 - val_output3_f1_score: 0.0145 - val_output4_precision_9: 0.0043 - val_output4_recall_9: 0.6681 - val_output4_f1_score: 0.0093 - lr: 5.0000e-05\n",
      "Epoch 2/64\n",
      "363/363 [==============================] - 162s 446ms/step - loss: 4.8146 - output0_loss: 0.9963 - output1_loss: 0.8827 - output2_loss: 0.9991 - output3_loss: 0.9436 - output4_loss: 0.9928 - output0_precision_5: 6.7560e-04 - output0_recall_5: 0.1230 - output0_f1_score: 0.0013 - output1_precision_6: 0.0000e+00 - output1_recall_6: 0.0000e+00 - output1_f1_score: 0.0000e+00 - output2_precision_7: 0.0045 - output2_recall_7: 0.3249 - output2_f1_score: 0.0090 - output3_precision_8: 0.0274 - output3_recall_8: 0.2204 - output3_f1_score: 0.0651 - output4_precision_9: 0.0063 - output4_recall_9: 0.5404 - output4_f1_score: 0.0150 - val_loss: 4.6918 - val_output0_loss: 0.9856 - val_output1_loss: 0.8666 - val_output2_loss: 0.9991 - val_output3_loss: 0.8594 - val_output4_loss: 0.9810 - val_output0_precision_5: 0.0000e+00 - val_output0_recall_5: 0.0000e+00 - val_output0_f1_score: 0.0000e+00 - val_output1_precision_6: 0.0000e+00 - val_output1_recall_6: 0.0000e+00 - val_output1_f1_score: 0.0000e+00 - val_output2_precision_7: 0.0543 - val_output2_recall_7: 0.2694 - val_output2_f1_score: 0.0895 - val_output3_precision_8: 0.4389 - val_output3_recall_8: 0.1545 - val_output3_f1_score: 0.2033 - val_output4_precision_9: 0.0295 - val_output4_recall_9: 0.3852 - val_output4_f1_score: 0.0565 - lr: 5.0000e-05\n",
      "Epoch 3/64\n",
      "363/363 [==============================] - 179s 492ms/step - loss: 4.6668 - output0_loss: 0.9942 - output1_loss: 0.8780 - output2_loss: 0.9991 - output3_loss: 0.8406 - output4_loss: 0.9549 - output0_precision_5: 0.0011 - output0_recall_5: 0.0974 - output0_f1_score: 0.0023 - output1_precision_6: 0.0000e+00 - output1_recall_6: 0.0000e+00 - output1_f1_score: 0.0000e+00 - output2_precision_7: 0.0055 - output2_recall_7: 0.2856 - output2_f1_score: 0.0111 - output3_precision_8: 0.1883 - output3_recall_8: 0.2515 - output3_f1_score: 0.2094 - output4_precision_9: 0.0632 - output4_recall_9: 0.3257 - output4_f1_score: 0.1466 - val_loss: 4.5107 - val_output0_loss: 0.9479 - val_output1_loss: 0.8673 - val_output2_loss: 0.9991 - val_output3_loss: 0.8017 - val_output4_loss: 0.8946 - val_output0_precision_5: 0.0000e+00 - val_output0_recall_5: 0.0000e+00 - val_output0_f1_score: 0.0000e+00 - val_output1_precision_6: 0.0000e+00 - val_output1_recall_6: 0.0000e+00 - val_output1_f1_score: 0.0000e+00 - val_output2_precision_7: 0.0869 - val_output2_recall_7: 0.2886 - val_output2_f1_score: 0.1304 - val_output3_precision_8: 0.4166 - val_output3_recall_8: 0.2361 - val_output3_f1_score: 0.2740 - val_output4_precision_9: 0.3017 - val_output4_recall_9: 0.2855 - val_output4_f1_score: 0.2734 - lr: 5.0000e-05\n",
      "Epoch 4/64\n",
      "363/363 [==============================] - 187s 516ms/step - loss: 4.5569 - output0_loss: 0.9901 - output1_loss: 0.8797 - output2_loss: 0.9991 - output3_loss: 0.8044 - output4_loss: 0.8836 - output0_precision_5: 0.0032 - output0_recall_5: 0.1501 - output0_f1_score: 0.0061 - output1_precision_6: 1.0000 - output1_recall_6: 1.3473e-04 - output1_f1_score: 2.8998e-04 - output2_precision_7: 0.0087 - output2_recall_7: 0.2818 - output2_f1_score: 0.0174 - output3_precision_8: 0.2458 - output3_recall_8: 0.2924 - output3_f1_score: 0.2534 - output4_precision_9: 0.1904 - output4_recall_9: 0.3180 - output4_f1_score: 0.2310 - val_loss: 4.3562 - val_output0_loss: 0.8400 - val_output1_loss: 0.8862 - val_output2_loss: 0.9991 - val_output3_loss: 0.7819 - val_output4_loss: 0.8489 - val_output0_precision_5: 0.0000e+00 - val_output0_recall_5: 0.0000e+00 - val_output0_f1_score: 0.0000e+00 - val_output1_precision_6: 0.0000e+00 - val_output1_recall_6: 0.0000e+00 - val_output1_f1_score: 0.0000e+00 - val_output2_precision_7: 0.1339 - val_output2_recall_7: 0.2798 - val_output2_f1_score: 0.1729 - val_output3_precision_8: 0.4509 - val_output3_recall_8: 0.2573 - val_output3_f1_score: 0.3034 - val_output4_precision_9: 0.3697 - val_output4_recall_9: 0.2886 - val_output4_f1_score: 0.3037 - lr: 5.0000e-05\n",
      "Epoch 5/64\n",
      "363/363 [==============================] - 186s 513ms/step - loss: 4.4885 - output0_loss: 0.9832 - output1_loss: 0.8784 - output2_loss: 0.9991 - output3_loss: 0.7840 - output4_loss: 0.8437 - output0_precision_5: 0.0057 - output0_recall_5: 0.1610 - output0_f1_score: 0.0116 - output1_precision_6: 0.2955 - output1_recall_6: 0.0018 - output1_f1_score: 0.0031 - output2_precision_7: 0.0121 - output2_recall_7: 0.2898 - output2_f1_score: 0.0237 - output3_precision_8: 0.2717 - output3_recall_8: 0.3176 - output3_f1_score: 0.2787 - output4_precision_9: 0.2297 - output4_recall_9: 0.3356 - output4_f1_score: 0.2621 - val_loss: 4.1873 - val_output0_loss: 0.7186 - val_output1_loss: 0.8816 - val_output2_loss: 0.9991 - val_output3_loss: 0.7671 - val_output4_loss: 0.8209 - val_output0_precision_5: 0.0000e+00 - val_output0_recall_5: 0.0000e+00 - val_output0_f1_score: 0.0000e+00 - val_output1_precision_6: 0.0000e+00 - val_output1_recall_6: 0.0000e+00 - val_output1_f1_score: 0.0000e+00 - val_output2_precision_7: 0.1540 - val_output2_recall_7: 0.2965 - val_output2_f1_score: 0.1945 - val_output3_precision_8: 0.4454 - val_output3_recall_8: 0.2778 - val_output3_f1_score: 0.3192 - val_output4_precision_9: 0.3821 - val_output4_recall_9: 0.3027 - val_output4_f1_score: 0.3190 - lr: 5.0000e-05\n",
      "Epoch 6/64\n",
      "363/363 [==============================] - 185s 509ms/step - loss: 4.4013 - output0_loss: 0.9726 - output1_loss: 0.8416 - output2_loss: 0.9991 - output3_loss: 0.7702 - output4_loss: 0.8178 - output0_precision_5: 0.0089 - output0_recall_5: 0.1459 - output0_f1_score: 0.0186 - output1_precision_6: 0.2255 - output1_recall_6: 0.0780 - output1_f1_score: 0.0977 - output2_precision_7: 0.0152 - output2_recall_7: 0.2958 - output2_f1_score: 0.0293 - output3_precision_8: 0.2946 - output3_recall_8: 0.3317 - output3_f1_score: 0.2976 - output4_precision_9: 0.2545 - output4_recall_9: 0.3496 - output4_f1_score: 0.2838 - val_loss: 4.0666 - val_output0_loss: 0.6408 - val_output1_loss: 0.8734 - val_output2_loss: 0.9991 - val_output3_loss: 0.7530 - val_output4_loss: 0.8003 - val_output0_precision_5: 0.0000e+00 - val_output0_recall_5: 0.0000e+00 - val_output0_f1_score: 0.0000e+00 - val_output1_precision_6: 0.5259 - val_output1_recall_6: 0.0294 - val_output1_f1_score: 0.0502 - val_output2_precision_7: 0.1749 - val_output2_recall_7: 0.3111 - val_output2_f1_score: 0.2135 - val_output3_precision_8: 0.4628 - val_output3_recall_8: 0.2950 - val_output3_f1_score: 0.3378 - val_output4_precision_9: 0.4134 - val_output4_recall_9: 0.3113 - val_output4_f1_score: 0.3350 - lr: 5.0000e-05\n",
      "Epoch 7/64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 184s 507ms/step - loss: 4.3378 - output0_loss: 0.9491 - output1_loss: 0.8291 - output2_loss: 0.9991 - output3_loss: 0.7604 - output4_loss: 0.8001 - output0_precision_5: 0.0186 - output0_recall_5: 0.1073 - output0_f1_score: 0.0308 - output1_precision_6: 0.2217 - output1_recall_6: 0.1109 - output1_f1_score: 0.1322 - output2_precision_7: 0.0195 - output2_recall_7: 0.3046 - output2_f1_score: 0.0367 - output3_precision_8: 0.2971 - output3_recall_8: 0.3512 - output3_f1_score: 0.3092 - output4_precision_9: 0.2668 - output4_recall_9: 0.3653 - output4_f1_score: 0.2985 - val_loss: 4.0192 - val_output0_loss: 0.6179 - val_output1_loss: 0.8642 - val_output2_loss: 0.9991 - val_output3_loss: 0.7489 - val_output4_loss: 0.7891 - val_output0_precision_5: 0.0000e+00 - val_output0_recall_5: 0.0000e+00 - val_output0_f1_score: 0.0000e+00 - val_output1_precision_6: 0.5049 - val_output1_recall_6: 0.0427 - val_output1_f1_score: 0.0694 - val_output2_precision_7: 0.2134 - val_output2_recall_7: 0.2963 - val_output2_f1_score: 0.2351 - val_output3_precision_8: 0.5020 - val_output3_recall_8: 0.2914 - val_output3_f1_score: 0.3488 - val_output4_precision_9: 0.4599 - val_output4_recall_9: 0.3042 - val_output4_f1_score: 0.3482 - lr: 5.0000e-05\n",
      "Epoch 8/64\n",
      "363/363 [==============================] - 183s 505ms/step - loss: 4.2573 - output0_loss: 0.9137 - output1_loss: 0.8140 - output2_loss: 0.9991 - output3_loss: 0.7480 - output4_loss: 0.7825 - output0_precision_5: 0.0320 - output0_recall_5: 0.0803 - output0_f1_score: 0.0388 - output1_precision_6: 0.2564 - output1_recall_6: 0.1300 - output1_f1_score: 0.1537 - output2_precision_7: 0.0242 - output2_recall_7: 0.3014 - output2_f1_score: 0.0452 - output3_precision_8: 0.3169 - output3_recall_8: 0.3608 - output3_f1_score: 0.3228 - output4_precision_9: 0.2895 - output4_recall_9: 0.3726 - output4_f1_score: 0.3140 - val_loss: 4.0057 - val_output0_loss: 0.6142 - val_output1_loss: 0.8597 - val_output2_loss: 0.9991 - val_output3_loss: 0.7498 - val_output4_loss: 0.7830 - val_output0_precision_5: 0.0000e+00 - val_output0_recall_5: 0.0000e+00 - val_output0_f1_score: 0.0000e+00 - val_output1_precision_6: 0.5347 - val_output1_recall_6: 0.0448 - val_output1_f1_score: 0.0751 - val_output2_precision_7: 0.2705 - val_output2_recall_7: 0.2738 - val_output2_f1_score: 0.2534 - val_output3_precision_8: 0.5302 - val_output3_recall_8: 0.2851 - val_output3_f1_score: 0.3510 - val_output4_precision_9: 0.4916 - val_output4_recall_9: 0.2973 - val_output4_f1_score: 0.3526 - lr: 5.0000e-05\n",
      "Epoch 9/64\n",
      "363/363 [==============================] - 186s 511ms/step - loss: 4.1971 - output0_loss: 0.8816 - output1_loss: 0.8050 - output2_loss: 0.9991 - output3_loss: 0.7408 - output4_loss: 0.7706 - output0_precision_5: 0.0557 - output0_recall_5: 0.0730 - output0_f1_score: 0.0497 - output1_precision_6: 0.2569 - output1_recall_6: 0.1397 - output1_f1_score: 0.1594 - output2_precision_7: 0.0301 - output2_recall_7: 0.2954 - output2_f1_score: 0.0543 - output3_precision_8: 0.3276 - output3_recall_8: 0.3723 - output3_f1_score: 0.3316 - output4_precision_9: 0.3013 - output4_recall_9: 0.3843 - output4_f1_score: 0.3235 - val_loss: 3.9831 - val_output0_loss: 0.6138 - val_output1_loss: 0.8480 - val_output2_loss: 0.9991 - val_output3_loss: 0.7472 - val_output4_loss: 0.7751 - val_output0_precision_5: 0.0000e+00 - val_output0_recall_5: 0.0000e+00 - val_output0_f1_score: 0.0000e+00 - val_output1_precision_6: 0.5885 - val_output1_recall_6: 0.0469 - val_output1_f1_score: 0.0785 - val_output2_precision_7: 0.2864 - val_output2_recall_7: 0.2681 - val_output2_f1_score: 0.2573 - val_output3_precision_8: 0.5424 - val_output3_recall_8: 0.2868 - val_output3_f1_score: 0.3552 - val_output4_precision_9: 0.5076 - val_output4_recall_9: 0.2992 - val_output4_f1_score: 0.3583 - lr: 5.0000e-05\n",
      "Epoch 10/64\n",
      "363/363 [==============================] - 183s 504ms/step - loss: 4.1492 - output0_loss: 0.8626 - output1_loss: 0.7974 - output2_loss: 0.9991 - output3_loss: 0.7315 - output4_loss: 0.7587 - output0_precision_5: 0.0759 - output0_recall_5: 0.0677 - output0_f1_score: 0.0576 - output1_precision_6: 0.2630 - output1_recall_6: 0.1578 - output1_f1_score: 0.1795 - output2_precision_7: 0.0362 - output2_recall_7: 0.2980 - output2_f1_score: 0.0640 - output3_precision_8: 0.3403 - output3_recall_8: 0.3806 - output3_f1_score: 0.3418 - output4_precision_9: 0.3201 - output4_recall_9: 0.3878 - output4_f1_score: 0.3343 - val_loss: 3.9563 - val_output0_loss: 0.6137 - val_output1_loss: 0.8418 - val_output2_loss: 0.9991 - val_output3_loss: 0.7372 - val_output4_loss: 0.7646 - val_output0_precision_5: 0.0000e+00 - val_output0_recall_5: 0.0000e+00 - val_output0_f1_score: 0.0000e+00 - val_output1_precision_6: 0.4951 - val_output1_recall_6: 0.0626 - val_output1_f1_score: 0.1009 - val_output2_precision_7: 0.2969 - val_output2_recall_7: 0.2772 - val_output2_f1_score: 0.2663 - val_output3_precision_8: 0.5356 - val_output3_recall_8: 0.3016 - val_output3_f1_score: 0.3654 - val_output4_precision_9: 0.5124 - val_output4_recall_9: 0.3093 - val_output4_f1_score: 0.3662 - lr: 5.0000e-05\n",
      "Epoch 11/64\n",
      " 29/363 [=>............................] - ETA: 2:30 - loss: 4.1722 - output0_loss: 0.8664 - output1_loss: 0.8093 - output2_loss: 0.9991 - output3_loss: 0.7357 - output4_loss: 0.7618 - output0_precision_5: 0.0500 - output0_recall_5: 0.0633 - output0_f1_score: 0.0504 - output1_precision_6: 0.2895 - output1_recall_6: 0.1337 - output1_f1_score: 0.1564 - output2_precision_7: 0.0392 - output2_recall_7: 0.2835 - output2_f1_score: 0.0688 - output3_precision_8: 0.3785 - output3_recall_8: 0.3700 - output3_f1_score: 0.3399 - output4_precision_9: 0.3389 - output4_recall_9: 0.3845 - output4_f1_score: 0.3268"
     ]
    }
   ],
   "source": [
    "args = parse_arguments([])\n",
    "model=main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3640075a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"AsteroidNET\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input (InputLayer)          [(None, 128, 128, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " eblock0norm (BatchNormaliz  (None, 128, 128, 1)          4         ['input[0][0]']               \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " eblock0conv1 (Conv2D)       (None, 128, 128, 25)         250       ['eblock0norm[0][0]']         \n",
      "                                                                                                  \n",
      " eblock0drop (Dropout)       (None, 128, 128, 25)         0         ['eblock0conv1[0][0]']        \n",
      "                                                                                                  \n",
      " eblock0pool (MaxPooling2D)  (None, 64, 64, 25)           0         ['eblock0drop[0][0]']         \n",
      "                                                                                                  \n",
      " eblock1norm (BatchNormaliz  (None, 64, 64, 25)           100       ['eblock0pool[0][0]']         \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " eblock1conv1 (Conv2D)       (None, 64, 64, 55)           12430     ['eblock1norm[0][0]']         \n",
      "                                                                                                  \n",
      " eblock1drop (Dropout)       (None, 64, 64, 55)           0         ['eblock1conv1[0][0]']        \n",
      "                                                                                                  \n",
      " eblock1pool (MaxPooling2D)  (None, 32, 32, 55)           0         ['eblock1drop[0][0]']         \n",
      "                                                                                                  \n",
      " eblock2norm (BatchNormaliz  (None, 32, 32, 55)           220       ['eblock1pool[0][0]']         \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " eblock2conv1 (Conv2D)       (None, 32, 32, 32)           15872     ['eblock2norm[0][0]']         \n",
      "                                                                                                  \n",
      " eblock2drop (Dropout)       (None, 32, 32, 32)           0         ['eblock2conv1[0][0]']        \n",
      "                                                                                                  \n",
      " eblock2pool (MaxPooling2D)  (None, 16, 16, 32)           0         ['eblock2drop[0][0]']         \n",
      "                                                                                                  \n",
      " eblock3norm (BatchNormaliz  (None, 16, 16, 32)           128       ['eblock2pool[0][0]']         \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " eblock3conv1 (Conv2D)       (None, 16, 16, 60)           17340     ['eblock3norm[0][0]']         \n",
      "                                                                                                  \n",
      " eblock3drop (Dropout)       (None, 16, 16, 60)           0         ['eblock3conv1[0][0]']        \n",
      "                                                                                                  \n",
      " eblock3pool (MaxPooling2D)  (None, 8, 8, 60)             0         ['eblock3drop[0][0]']         \n",
      "                                                                                                  \n",
      " eblock4norm (BatchNormaliz  (None, 8, 8, 60)             240       ['eblock3pool[0][0]']         \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " eblock4conv1 (Conv2D)       (None, 8, 8, 23)             12443     ['eblock4norm[0][0]']         \n",
      "                                                                                                  \n",
      " eblock4drop (Dropout)       (None, 8, 8, 23)             0         ['eblock4conv1[0][0]']        \n",
      "                                                                                                  \n",
      " eblock4pool (MaxPooling2D)  (None, 4, 4, 23)             0         ['eblock4drop[0][0]']         \n",
      "                                                                                                  \n",
      " dblock4convT (Conv2DTransp  (None, 8, 8, 14)             2912      ['eblock4pool[0][0]']         \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " dblock4concat (Concatenate  (None, 8, 8, 37)             0         ['dblock4convT[0][0]',        \n",
      " )                                                                   'eblock4drop[0][0]']         \n",
      "                                                                                                  \n",
      " dblock4norm (BatchNormaliz  (None, 8, 8, 37)             148       ['dblock4concat[0][0]']       \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dblock4conv1 (Conv2D)       (None, 8, 8, 14)             4676      ['dblock4norm[0][0]']         \n",
      "                                                                                                  \n",
      " dblock4drop (Dropout)       (None, 8, 8, 14)             0         ['dblock4conv1[0][0]']        \n",
      "                                                                                                  \n",
      " dblock3convT (Conv2DTransp  (None, 16, 16, 62)           7874      ['dblock4drop[0][0]']         \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " dblock3concat (Concatenate  (None, 16, 16, 122)          0         ['dblock3convT[0][0]',        \n",
      " )                                                                   'eblock3drop[0][0]']         \n",
      "                                                                                                  \n",
      " dblock3norm (BatchNormaliz  (None, 16, 16, 122)          488       ['dblock3concat[0][0]']       \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dblock3conv1 (Conv2D)       (None, 16, 16, 62)           68138     ['dblock3norm[0][0]']         \n",
      "                                                                                                  \n",
      " dblock3drop (Dropout)       (None, 16, 16, 62)           0         ['dblock3conv1[0][0]']        \n",
      "                                                                                                  \n",
      " dblock2convT (Conv2DTransp  (None, 32, 32, 32)           17888     ['dblock3drop[0][0]']         \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " dblock2concat (Concatenate  (None, 32, 32, 64)           0         ['dblock2convT[0][0]',        \n",
      " )                                                                   'eblock2drop[0][0]']         \n",
      "                                                                                                  \n",
      " dblock2norm (BatchNormaliz  (None, 32, 32, 64)           256       ['dblock2concat[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dblock2conv1 (Conv2D)       (None, 32, 32, 32)           18464     ['dblock2norm[0][0]']         \n",
      "                                                                                                  \n",
      " dblock2drop (Dropout)       (None, 32, 32, 32)           0         ['dblock2conv1[0][0]']        \n",
      "                                                                                                  \n",
      " dblock1convT (Conv2DTransp  (None, 64, 64, 52)           15028     ['dblock2drop[0][0]']         \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " dblock1concat (Concatenate  (None, 64, 64, 107)          0         ['dblock1convT[0][0]',        \n",
      " )                                                                   'eblock1drop[0][0]']         \n",
      "                                                                                                  \n",
      " dblock1norm (BatchNormaliz  (None, 64, 64, 107)          428       ['dblock1concat[0][0]']       \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dblock1conv1 (Conv2D)       (None, 64, 64, 52)           50128     ['dblock1norm[0][0]']         \n",
      "                                                                                                  \n",
      " dblock1drop (Dropout)       (None, 64, 64, 52)           0         ['dblock1conv1[0][0]']        \n",
      "                                                                                                  \n",
      " dblock0convT (Conv2DTransp  (None, 128, 128, 37)         17353     ['dblock1drop[0][0]']         \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " dblock0concat (Concatenate  (None, 128, 128, 62)         0         ['dblock0convT[0][0]',        \n",
      " )                                                                   'eblock0drop[0][0]']         \n",
      "                                                                                                  \n",
      " dblock0norm (BatchNormaliz  (None, 128, 128, 62)         248       ['dblock0concat[0][0]']       \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " dblock0conv1 (Conv2D)       (None, 128, 128, 37)         20683     ['dblock0norm[0][0]']         \n",
      "                                                                                                  \n",
      " dblock0drop (Dropout)       (None, 128, 128, 37)         0         ['dblock0conv1[0][0]']        \n",
      "                                                                                                  \n",
      " output0 (Conv2D)            (None, 8, 8, 1)              15        ['dblock4drop[0][0]']         \n",
      "                                                                                                  \n",
      " output1 (Conv2D)            (None, 16, 16, 1)            63        ['dblock3drop[0][0]']         \n",
      "                                                                                                  \n",
      " output2 (Conv2D)            (None, 32, 32, 1)            33        ['dblock2drop[0][0]']         \n",
      "                                                                                                  \n",
      " output3 (Conv2D)            (None, 64, 64, 1)            53        ['dblock1drop[0][0]']         \n",
      "                                                                                                  \n",
      " output4 (Conv2D)            (None, 128, 128, 1)          38        ['dblock0drop[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 283941 (1.08 MB)\n",
      "Trainable params: 282811 (1.08 MB)\n",
      "Non-trainable params: 1130 (4.41 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89da2a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  6 08:49:44 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 545.23.06              Driver Version: 545.23.06    CUDA Version: 12.3     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:21:00.0  On |                  N/A |\r\n",
      "| 32%   37C    P8              20W / 260W |     55MiB / 11264MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:48:00.0 Off |                  N/A |\r\n",
      "| 26%   29C    P8              13W / 260W |      1MiB / 11264MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      2357      G   /usr/bin/X                                   39MiB |\r\n",
      "|    0   N/A  N/A      2996      G   /usr/bin/gnome-shell                         13MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c77dee75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\r\n",
      "root       2357  0.0  0.0 25485608 40260 tty1   Ssl+ Apr24   0:38 /usr/bin/X :0 \r\n",
      "gdm        2996  0.0  0.0 7869304 153940 ?      Sl   Apr24   6:24 /usr/bin/gnome\r\n"
     ]
    }
   ],
   "source": [
    "!ps -up `nvidia-smi -q -x | grep pid | sed -e 's/<pid>//g' -e 's/<\\/pid>//g' -e 's/^[[:space:]]*//'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886a065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST pipeline",
   "language": "python",
   "name": "kmrakovc_lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
