{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a697db36",
   "metadata": {},
   "source": [
    "import argparse\n",
    "import sys, os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "sys.path.append(\"../\")\n",
    "import tools.model\n",
    "import json\n",
    "multiple_results = []"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d80eac",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "def parse_function(img_shape=(128, 128, 1), test=False):\n",
    "    def parsing(example_proto):\n",
    "        keys_to_features = {'x': tf.io.FixedLenFeature(shape=img_shape, dtype=tf.float32),\n",
    "                            'y': tf.io.FixedLenFeature(shape=img_shape, dtype=tf.int64)}\n",
    "        parsed_features = tf.io.parse_single_example(example_proto, keys_to_features)\n",
    "        parsed_features['y'] = tf.cast(parsed_features['y'], tf.float32)\n",
    "        parsed_features['x'] = tf.clip_by_value(parsed_features['x'], -100, 100)\n",
    "        if test:\n",
    "            return parsed_features['x']\n",
    "        else:\n",
    "            return parsed_features['x'], parsed_features['y']\n",
    "\n",
    "    return parsing\n",
    "\n",
    "\n",
    "def reshape_outputs(img_shape=(32, 32)):\n",
    "    def reshaping(inputs, targets):\n",
    "        targets = tf.image.resize(targets, img_shape)\n",
    "        targets = tf.math.ceil(targets)\n",
    "        return inputs, targets\n",
    "\n",
    "    return reshaping\n",
    "\n",
    "\n",
    "def get_shape_of_quadratic_image_tfrecord(raw_dataset):\n",
    "    keys_to_features = {'x': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "                        'y': tf.io.VarLenFeature(dtype=tf.int64)}\n",
    "    for i in raw_dataset.take(1):\n",
    "        parsed_features = tf.io.parse_single_example(i, keys_to_features)\n",
    "        return int(np.sqrt(parsed_features[\"x\"].shape[0])), int(np.sqrt(parsed_features[\"x\"].shape[0])), 1\n",
    "\n",
    "\n",
    "def get_architecture_from_model(model):\n",
    "    \"\"\"\n",
    "    Extracts the architecture of a model and returns it as a dictionary.\n",
    "    :param model: tensorflow model\n",
    "    :return: dictionary with the architecture\n",
    "    \"\"\"\n",
    "    architecture = {\n",
    "        \"downFilters\": [],\n",
    "        \"downActivation\": [],\n",
    "        \"downDropout\": [],\n",
    "        \"downMaxPool\": [],\n",
    "        \"upFilters\": [],\n",
    "        \"upActivation\": [],\n",
    "        \"upDropout\": [],}\n",
    "    for layer in model.layers:\n",
    "        if (\"block\" in layer.name.lower()) and (\"conv1\" in layer.name.lower()):\n",
    "            if layer.name.lower()[0] == \"e\":\n",
    "                architecture[\"downFilters\"].append(layer.filters)\n",
    "                architecture[\"downActivation\"].append(layer.activation.__name__)\n",
    "            elif layer.name.lower()[0] == \"d\":\n",
    "                architecture[\"upFilters\"].append(layer.filters)\n",
    "                architecture[\"upActivation\"].append(layer.activation.__name__)\n",
    "        elif (\"block\" in layer.name.lower()) and (\"drop\" in layer.name.lower()):\n",
    "            if layer.name.lower()[0] == \"e\":\n",
    "                architecture[\"downDropout\"].append(layer.rate)\n",
    "            elif layer.name.lower()[0] == \"d\":\n",
    "                architecture[\"upDropout\"].append(layer.rate)\n",
    "        elif (\"eblock\" in layer.name.lower()) and (\"pool\" in layer.name.lower()):\n",
    "            current_layer = int(layer.name.lower()[6])\n",
    "            if len(architecture[\"downMaxPool\"]) < current_layer:\n",
    "                for i in range(current_layer - len(architecture[\"downMaxPool\"])):\n",
    "                    architecture[\"downMaxPool\"].append(False)\n",
    "            architecture[\"downMaxPool\"].append(True)\n",
    "    return architecture\n",
    "\n",
    "\n",
    "def attention_gate(g, s, num_filters):\n",
    "    wg = tf.keras.layers.Conv2D(num_filters, 1, padding=\"same\")(g)\n",
    "    wg = tf.keras.layers.BatchNormalization()(wg)\n",
    "\n",
    "    ws = tf.keras.layers.Conv2D(num_filters, 1, padding=\"same\")(s)\n",
    "    ws = tf.keras.layers.BatchNormalization()(ws)\n",
    "\n",
    "    out = tf.keras.layers.Activation(\"relu\")(wg + ws)\n",
    "    out = tf.keras.layers.Conv2D(num_filters, 1, padding=\"same\")(out)\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(out)\n",
    "\n",
    "    return out * s\n",
    "\n",
    "\n",
    "def encoder_mini_block(inputs, n_filters=32, activation=\"relu\", dropout_prob=0.3, max_pooling=True, name=\"\"):\n",
    "    \"\"\"\n",
    "    Encoder mini block for U-Net architecture. It consists of two convolutional layers with the same activation function\n",
    "    and number of filters. Optionally, a dropout layer can be added after the second convolutional layer. If max_pooling\n",
    "    is set to True, a max pooling layer is added at the end of the block. The skip connection is the output of the second\n",
    "    convolutional layer.\n",
    "\n",
    "    :param inputs: Input tensor to the block\n",
    "    :param n_filters: Number of filters for the convolutional layers\n",
    "    :param activation: Activation function for the convolutional layers\n",
    "    :param dropout_prob: Dropout probability for the dropout layer (0 means no dropout)\n",
    "    :param max_pooling: Boolean to add a max pooling layer at the end of the block\n",
    "    :param name: Name of the block (Optional)\n",
    "    :return: The output tensor of the block and the skip connection tensor\n",
    "    \"\"\"\n",
    "\n",
    "    conv = tf.keras.layers.Conv2D(n_filters,\n",
    "                                  5,  # filter size\n",
    "                                  activation=\"linear\",\n",
    "                                  padding='same',\n",
    "                                  kernel_initializer='HeNormal',\n",
    "                                  name=\"eblock\" + name + \"conv1\")(inputs)\n",
    "\n",
    "    conv = tf.keras.layers.BatchNormalization(name=\"eblock\" + name + \"norm1\")(conv)\n",
    "    conv = tf.keras.layers.Activation(activation=activation, name=\"eblock\" + name + activation + \"1\")(conv)\n",
    "\n",
    "    conv = tf.keras.layers.Conv2D(n_filters,\n",
    "                                  5,  # filter size\n",
    "                                  activation=\"linear\",\n",
    "                                  padding='same',\n",
    "                                  kernel_initializer='HeNormal',\n",
    "                                  name=\"eblock\" + name + \"conv2\")(conv)\n",
    "    conv = tf.keras.layers.BatchNormalization(name=\"eblock\" + name + \"norm2\")(conv)\n",
    "    conv = tf.keras.layers.Activation(activation=activation, name=\"eblock\" + name + activation + \"2\")(conv)\n",
    "\n",
    "    if dropout_prob > 0:\n",
    "        conv = tf.keras.layers.Dropout(dropout_prob, name=\"eblock\" + name + \"drop\")(conv)\n",
    "    if max_pooling:\n",
    "        next_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), name=\"eblock\" + name + \"pool\")(conv)\n",
    "    else:\n",
    "        next_layer = conv\n",
    "    skip_connection = conv\n",
    "    return next_layer, skip_connection\n",
    "\n",
    "\n",
    "def decoder_mini_block(prev_layer_input, skip_layer_input, n_filters=32, activation=\"relu\", dropout_prob=0.3,\n",
    "                       max_pooling=True, attention=True, name=\"\"):\n",
    "    \"\"\"\n",
    "    Decoder mini block for U-Net architecture that consists of a transposed convolutional layer followed by two\n",
    "    convolutional layers. The skip connection is the concatenation of the transposed convolutional layer and the\n",
    "    corresponding encoder skip connection.\n",
    "\n",
    "    :param prev_layer_input: Input tensor to the block from the previous layer\n",
    "    :param skip_layer_input: Input tensor to the block from the corresponding encoder skip connection\n",
    "    :param n_filters: Number of filters for the convolutional layers\n",
    "    :param activation: Activation function for the convolutional layers\n",
    "    :param name: Name of the block (Optional)\n",
    "    :return: The output tensor of the block\n",
    "    \"\"\"\n",
    "\n",
    "    if max_pooling:\n",
    "        prev_layer_input = tf.keras.layers.UpSampling2D(interpolation=\"bilinear\")(prev_layer_input)\n",
    "    if attention and max_pooling:\n",
    "        skip_layer_input = attention_gate(prev_layer_input, skip_layer_input, n_filters)\n",
    "    merge = tf.keras.layers.concatenate([prev_layer_input, skip_layer_input], name=\"dblock\" + name + \"concat\")\n",
    "    conv = tf.keras.layers.Conv2D(n_filters,\n",
    "                                  5,  # filter size\n",
    "                                  activation=\"linear\",\n",
    "                                  padding='same',\n",
    "                                  kernel_initializer='HeNormal',\n",
    "                                  name=\"dblock\" + name + \"conv1\")(merge)\n",
    "    conv = tf.keras.layers.BatchNormalization(name=\"dblock\" + name + \"norm1\")(conv)\n",
    "    conv = tf.keras.layers.Activation(activation=activation, name=\"dblock\" + name + activation + \"1\")(conv)\n",
    "\n",
    "    conv = tf.keras.layers.Conv2D(n_filters,\n",
    "                                  5,  # filter size\n",
    "                                  activation=\"linear\",\n",
    "                                  padding='same',\n",
    "                                  kernel_initializer='HeNormal',\n",
    "                                  name=\"dblock\" + name + \"conv2\")(conv)\n",
    "    conv = tf.keras.layers.BatchNormalization(name=\"dblock\" + name + \"norm2\")(conv)\n",
    "    conv = tf.keras.layers.Activation(activation=activation, name=\"dblock\" + name + activation + \"2\")(conv)\n",
    "    if dropout_prob > 0:\n",
    "        conv = tf.keras.layers.Dropout(dropout_prob, name=\"dblock\" + name + \"drop\")(conv)\n",
    "\n",
    "    return conv\n",
    "\n",
    "\n",
    "def unet_model(input_size, arhitecture):\n",
    "    \"\"\"\n",
    "    U-Net model for semantic segmentation. The model consists of an encoder and a decoder. The encoder downsamples the\n",
    "    input image and extracts features. The decoder upsamples the features and generates the segmentation mask. Skip\n",
    "    connections are used to concatenate the encoder features with the decoder features. The model is created from the\n",
    "    architecture dictionary that contains the number of filters, activation functions, dropout probabilities, and max\n",
    "    pooling for each mini block.\n",
    "\n",
    "    :param input_size: Size of the input image\n",
    "    :param arhitecture: Dictionary containing the architecture of the U-Net model\n",
    "    :return: U-Net model\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.layers.Input(input_size, name=\"input\")\n",
    "    inputs = tf.keras.layers.BatchNormalization(name=\"inputNormalisation\")(inputs)\n",
    "    skip_connections = []\n",
    "    layer = inputs\n",
    "    if not \"attention\" in arhitecture.keys():\n",
    "        arhitecture[\"attention\"] = [False for i in arhitecture[\"upFilters\"]]\n",
    "    # Encoder\n",
    "    for i in range(len(arhitecture[\"downFilters\"])):\n",
    "        layer, skip = encoder_mini_block(layer,\n",
    "                                         n_filters=arhitecture[\"downFilters\"][i],\n",
    "                                         activation=arhitecture[\"downActivation\"][i],\n",
    "                                         dropout_prob=arhitecture[\"downDropout\"][i],\n",
    "                                         max_pooling=arhitecture[\"downMaxPool\"][i],\n",
    "                                         name=str(i))\n",
    "        skip_connections.append(skip)\n",
    "        # Decoder\n",
    "    for i in range(len(arhitecture[\"upFilters\"])):\n",
    "        skip_con = skip_connections[len(skip_connections) - 1 - i]\n",
    "        layer = decoder_mini_block(layer,\n",
    "                                   skip_con,\n",
    "                                   n_filters=arhitecture[\"upFilters\"][i],\n",
    "                                   activation=arhitecture[\"upActivation\"][i],\n",
    "                                   attention=arhitecture[\"attention\"][i],\n",
    "                                   dropout_prob=arhitecture[\"upDropout\"][i],\n",
    "                                   max_pooling=arhitecture[\"downMaxPool\"][len(arhitecture[\"upFilters\"]) - 1 - i],\n",
    "                                   name=str(len(arhitecture[\"upFilters\"]) - 1 - i))\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid', name=\"output\")(layer)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs], name=\"AsteroidNET\")\n",
    "    return model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e43a8c2e",
   "metadata": {},
   "source": [
    "train_dataset_path = '../DATA/train1.tfrecord'\n",
    "test_dataset_path = '../DATA/test1.tfrecord'\n",
    "batch_size = 128\n",
    "decay_lr_rate = 0.75\n",
    "decay_lr_patience = 2\n",
    "arhitecture = {\n",
    "    \"downFilters\": [32, 64, 128, 256, 512, 1024, 2048],\n",
    "    \"downActivation\": [\"relu\", \"sigmoid\", \"relu\", \"sigmoid\", \"relu\", \"sigmoid\"],\n",
    "    \"downDropout\": [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "    \"downMaxPool\": [True, True, True, True, True, True],\n",
    "    \"upFilters\": [2048, 1024, 512, 256, 128],\n",
    "    \"upActivation\": [\"sigmoid\", \"relu\", \"sigmoid\", \"relu\"],\n",
    "    \"upDropout\": [0.1, 0.1, 0.1, 0.1],\n",
    "    \"attention\": [True, True, True, True]}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ff4dc4",
   "metadata": {},
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()   \n",
    "dataset_train = tf.data.TFRecordDataset([train_dataset_path])\n",
    "tfrecord_shape = tools.model.get_shape_of_quadratic_image_tfrecord(dataset_train)\n",
    "dataset_train = dataset_train.map(tools.model.parse_function(img_shape=tfrecord_shape, test=False))\n",
    "dataset_val = tf.data.TFRecordDataset([test_dataset_path])\n",
    "dataset_val = dataset_val.map(tools.model.parse_function(img_shape=tfrecord_shape, test=False))\n",
    "\n",
    "terminateonnan_kb = tf.keras.callbacks.TerminateOnNaN()\n",
    "reducelronplateau_kb = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=decay_lr_rate,\n",
    "                                                            patience=2*decay_lr_patience,\n",
    "                                                            cooldown=decay_lr_patience,\n",
    "                                                            verbose=1)\n",
    "kb = [terminateonnan_kb, reducelronplateau_kb]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccbeeab5",
   "metadata": {},
   "source": [
    "alpha = 0.9\n",
    "gamma = 1.5\n",
    "start_lr = 0.001"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3244b76f",
   "metadata": {},
   "source": [
    "with mirrored_strategy.scope():\n",
    "        model = unet_model(tfrecord_shape, arhitecture)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=start_lr),\n",
    "                      loss=tools.metrics.FocalTversky(alpha=alpha, gamma=gamma),\n",
    "                      metrics=[\"Precision\", \"Recall\", tools.metrics.F1_Score()])\n",
    "dataset_train1 = dataset_train.map(tools.model.reshape_outputs(img_shape=tuple(model.outputs[0].shape[1:-1])))\n",
    "dataset_val1 = dataset_val.map(tools.model.reshape_outputs(img_shape=tuple(model.outputs[0].shape[1:-1])))\n",
    "dataset_train1 = dataset_train1.shuffle(200 * batch_size).batch(batch_size).prefetch(2)\n",
    "dataset_val1 = dataset_val1.batch(batch_size).prefetch(2)\n",
    "\n",
    "results = model.fit(dataset_train1, epochs=16, validation_data=dataset_val1,\n",
    "                        callbacks=kb, verbose=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9839ba",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Karlo's LSST Stack",
   "language": "python",
   "name": "kmrakovcic_lsststack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
